*Note: This is llms-full.txt is not complete, please enter a Firecrawl API key to get the entire llms-full.txt at llmstxt.firecrawl.dev or you can access llms.txt via API with curl -X GET 'http://llmstxt.firecrawl.dev/https://docs.dify.ai/?FIRECRAWL_API_KEY=YOUR_API_KEY' or llms-full.txt via API with curl -X GET 'http://llmstxt.firecrawl.dev/https://docs.dify.ai//full?FIRECRAWL_API_KEY=YOUR_API_KEY'

# https://docs.dify.ai/ llms-full.txt

### [Direct link to heading](\#basic-introduction)    Basic Introduction

Workflows reduce system complexity by breaking down complex tasks into smaller steps (nodes), reducing reliance on prompt engineering and model inference capabilities, and enhancing the performance of LLM applications for complex tasks. This also improves the system's interpretability, stability, and fault tolerance.

Dify workflows are divided into two types:

- **Chatflow**: Designed for conversational scenarios, including customer service, semantic search, and other conversational applications that require multi-step logic in response construction.

- **Workflow**: Geared towards automation and batch processing scenarios, suitable for high-quality translation, data analysis, content generation, email automation, and more.


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-4f2d7dda319a85417891fea4f0f582f5714ddd16%252Fimage%2520%28156%29.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=43e79a69&sv=2)

To address the complexity of user intent recognition in natural language input, Chatflow provides question understanding nodes. Compared to Workflow, it adds support for Chatbot features such as conversation history (Memory), annotated replies, and Answer nodes.

To handle complex business logic in automation and batch processing scenarios, Workflow offers a variety of logic nodes, such as code nodes, IF/ELSE nodes, template transformation, iteration nodes, and more. Additionally, it provides capabilities for timed and event-triggered actions, facilitating the construction of automated processes.

### [Direct link to heading](\#common-use-cases)    Common Use Cases

- Customer Service


By integrating LLM into your customer service system, you can automate responses to common questions, reducing the workload of your support team. LLM can understand the context and intent of customer queries and generate helpful and accurate answers in real-time.

- Content Generation


Whether you need to create blog posts, product descriptions, or marketing materials, LLM can assist by generating high-quality content. Simply provide an outline or topic, and LLM will use its extensive knowledge base to produce engaging, informative, and well-structured content.

- Task Automation


LLM can be integrated with various task management systems like Trello, Slack, and Lark to automate project and task management. Using natural language processing, LLM can understand and interpret user input, create tasks, update statuses, and assign priorities without manual intervention.

- Data Analysis and Reporting


LLM can analyze large datasets and generate reports or summaries. By providing relevant information to LLM, it can identify trends, patterns, and insights, transforming raw data into actionable intelligence. This is particularly valuable for businesses looking to make data-driven decisions.

- Email Automation


LLM can be used to draft emails, social media updates, and other forms of communication. By providing a brief outline or key points, LLM can generate well-structured, coherent, and contextually relevant messages. This saves significant time and ensures your responses are clear and professional.

### [Direct link to heading](\#how-to-get-started)    How to Get Started

- Start by building a workflow from scratch or use system templates to help you get started.

- Get familiar with basic operations, including creating nodes on the canvas, connecting and configuring nodes, debugging workflows, and viewing run history.

- Save and publish a workflow.

- Run the published application or call the workflow through an API.


[PreviousModeration Tool](/guides/application-orchestrate/app-toolkits/moderation-tool) [NextKey Concepts](/guides/workflow/key-concepts)

Last updated 6 months ago

This site uses cookies to deliver its service and to analyse traffic. By browsing this site, you accept the [privacy policy](https://dify.ai/privacy).

AcceptReject**Workflow** and **Chatflow** Application are composed of independent nodes. Most nodes have input and output items, but the input and output information for each node is not consistent and dynamic.

**How to use a fixed symbol to refer dynamically changing content?** Variables, as dynamic data containers, can store and transmit unfixed content, being referenced mutually within different nodes, providing flexible information mobility between nodes.

### [Direct link to heading](\#system-variables)    System Variables

System variables refer to pre-set system-level parameters within Chatflow / Workflow App that can be globally read by other nodes. All system-level variables begin with `sys.`

#### [Direct link to heading](\#workflow)    Workflow

Workflow type application provides the system variables below:

Variables name

Data Type

Description

Remark

`sys.files`

`[LEGACY]`

Array\[File\]

File Parameter: Stores images uploaded by users

The image upload function needs to be enabled in the 'Features' section in the upper right corner of the application orchestration page

`sys.user_id`

String

User ID: A unique identifier automatically assigned by the system to each user when they use a workflow application. It is used to distinguish different users

`sys.app_id`

String

App ID: A unique identifier automatically assigned by the system to each App. This parameter is used to record the basic information of the current application.

This parameter is used to differentiate and locate distinct Workflow applications for users with development capabilities

`sys.workflow_id`

String

Workflow ID: This parameter records information about all nodes information in the current Workflow application.

This parameter can be used by users with development capabilities to track and record information about the nodes contained within a Workflow

`sys.workflow_run_id`

String

Workflow Run ID: Used to record the runtime status and execution logs of a Workflow application.

This parameter can be used by users with development capabilities to track the application's historical execution records

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252F3cMP1qIEQToqw46Gi0ug%252Fimage.png%3Falt%3Dmedia%26token%3Da1ef8a33-ccb3-4dd8-aa89-96bd4d4c5e39&width=768&dpr=4&quality=100&sign=845abf63&sv=2)

Workflow App System Variables

#### [Direct link to heading](\#chatflow)    Chatflow

Chatflow type application provides the following system variables:

Variables name

Data Type

Description

Remark

`sys.query`

String

Content entered by the user in the chatting box.

`sys.files`

Array\[File\]

File Parameter: Stores images uploaded by users

The image upload function needs to be enabled in the 'Features' section in the upper right corner of the application orchestration page

`sys.dialogue_count`

Number

The number of conversations turns during the user's interaction with a Chatflow application. The count automatically increases by one after each chat round and can be combined with if-else nodes to create rich branching logic.

For example, LLM will review the conversation history at the X conversation turn and automatically provide an analysis.

`sys.conversation_id`

String

A unique ID for the chatting box interaction session, grouping all related messages into the same conversation, ensuring that the LLM continues the chatting on the same topic and context.

`sys.user_id`

String

A unique ID is assigned for each application user to distinguish different conversation users.

`sys.workflow_id`

String

Workflow ID: This parameter records information about all nodes information in the current Workflow application.

This parameter can be used by users with development capabilities to track and record information about the nodes contained within a Workflow

`sys.workflow_run_id`

String

Workflow Run ID: Used to record the runtime status and execution logs of a Workflow application.

This parameter can be used by users with development capabilities to track the application's historical execution records

![chatflow app system variables](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252FipdTChVcZw6K8v8dPb2Z%252Fimage.png%3Falt%3Dmedia%26token%3D38454d2b-af58-455d-b420-528637dadfde&width=768&dpr=4&quality=100&sign=e70472d2&sv=2)

Chatflow App System Variables

### [Direct link to heading](\#environment-variables)    Environment Variables

**Environment variables are used to protect sensitive information involved in workflows**, such as API keys and database passwords used when running workflows. They are stored in the workflow rather than in the code, allowing them to be shared across different environments.

![Environment Variables](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-17ff1126522047667eb9054c0343ab9ecbfdc369%252Fen-env-variable.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=825197c8&sv=2)

Environment Variables

Supports the following 3 data types:

- String

- Number

- Secret


Environmental variables have the following characteristics:

- Environment variables can be globally referenced within most nodes;

- Environment variable names cannot be duplicated;

- Output variables of nodes are generally read-only and cannot be written to.


* * *

### [Direct link to heading](\#conversation-variables)    Conversation Variables

> Conversation variables are only applicable to [Chatflow](/guides/workflow/variables#chatflow-and-workflow) App.

**Conversation variables allow application developers to specify particular information that needs to be temporarily stored within the same Chatflow session, ensuring that this information can be referenced across multiple rounds of chatting within the current chatflow**. This can include context, files uploaded to the chatting box(coming soon), user preferences input during the conversation, etc. It's like providing a "memo" for the LLM that can be checked at any time, avoiding information bias caused by LLM memory errors.

For example, you can store the language preference input by the user in the first round of chatting in a conversation variable. The LLM will refer to the information in the conversation variable when answering and use the specified language to reply to the user in subsequent chats.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-ce334a339d57e44067caf8447adfc8831a656881%252Fconversation-var.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=6a58da9d&sv=2)

Conversation Variable

**Conversation variables** support the following six data types:

- String

- Number

- Object

- Array\[string\]

- Array\[number\]

- Array\[object\]


**Conversation variables** have the following features:

- Conversation variables can be referenced globally within most nodes in the same Chatflow App;

- Writing to conversation variables requires using the [Variable Assigner](https://docs.dify.ai/guides/workflow/node/variable-assignment) node;

- Conversation variables are read-write variables;


About how to use conversation variables with the Variable Assigner node, please refer to the [Variable Assigner](https://github.com/langgenius/dify-docs/blob/main/en/guides/workflow/node/variable-assignment.md).

To track changes in conversation variable values during debugging the application, click the conversation variable icon at the top of the Chatflow application preview page.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F11%2Fcc8067fa4c96436f037f8210ebe3f65c.png&width=768&dpr=4&quality=100&sign=eb8856a9&sv=2)

### [Direct link to heading](\#notice)    Notice

- To avoid variable name duplication, node naming must not be repeated

- The output variables of nodes are generally fixed variables and cannot be edited


[PreviousKey Concepts](/guides/workflow/key-concepts) [NextNode Description](/guides/workflow/node)

Last updated 1 month agoDify is a development platform for AI application based on LLM Apps, when you are using Dify for the first time, you need to go to **Settings --> Model Providers** to add and configure the LLM you are going to use.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252FmLjz8IL4l1Ae4z5BJJ2a%252Fimage.png%3Falt%3Dmedia%26token%3Dee9ddc14-3e88-4a45-a7b4-3c1ac9d25f14&width=768&dpr=4&quality=100&sign=dcebe7ec&sv=2)

Settings - Model Provider

Dify supports major model providers like OpenAI's GPT series and Anthropic's Claude series. Each model's capabilities and parameters differ, so select a model provider that suits your application's needs. **Obtain the API key from the model provider's official website before using it in Dify.**

## [Direct link to heading](\#model-types-in-dify)    Model Types in Dify

Dify classifies models into 4 types, each for different uses:

1. **System Inference Models:** Used in applications for tasks like chat, name generation, and suggesting follow-up questions.



> Providers include [OpenAI](https://platform.openai.com/account/api-keys)、 [Azure OpenAI Service](https://azure.microsoft.com/en-us/products/ai-services/openai-service/)、 [Anthropic](https://console.anthropic.com/account/keys)、Hugging Face Hub、Replicate、Xinference、OpenLLM、 [iFLYTEK SPARK](https://www.xfyun.cn/solutions/xinghuoAPI)、 [WENXINYIYAN](https://console.bce.baidu.com/qianfan/ais/console/applicationConsole/application)、 [TONGYI](https://dashscope.console.aliyun.com/api-key_management?spm=a2c4g.11186623.0.0.3bbc424dxZms9k)、 [Minimax](https://api.minimax.chat/user-center/basic-information/interface-key)、ZHIPU(ChatGLM)、 [Ollama](https://docs.dify.ai/tutorials/model-configuration/ollama)、 [LocalAI](https://github.com/mudler/LocalAI)、 [GPUStack](https://github.com/gpustack/gpustack).

2. **Embedding Models:** Employed for embedding segmented documents in knowledge and processing user queries in applications.



> Providers include OpenAI, ZHIPU (ChatGLM), Jina AI( [Jina Embeddings](https://jina.ai/embeddings/)).

3. [**Rerank Models**](https://docs.dify.ai/advanced/retrieval-augment/rerank) **:** Enhance search capabilities in LLMs.



> Providers include Cohere, Jina AI( [Jina Reranker](https://jina.ai/reranker)).

4. **Speech-to-Text Models:** Convert spoken words to text in conversational applications.



> Provider: OpenAI.


Dify plans to add more LLM providers as technology and user needs evolve.

## [Direct link to heading](\#hosted-model-trial-service)    Hosted Model Trial Service

Dify offers trial quotas for cloud service users to experiment with different models. Set up your model provider before the trial ends to ensure uninterrupted application use.

- OpenAI Hosted Model Trial: Includes 200 invocations for models like GPT3.5-turbo, GPT3.5-turbo-16k, text-davinci-003 models.


## [Direct link to heading](\#setting-the-default-model)    Setting the Default Model

Dify automatically selects the default model based on usage. Configure this in `Settings > Model Provider`.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-9440bce8f1137b956a881fbdafc94a12c6ee1de5%252Fimage-default-models.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=293d097e&sv=2)

## [Direct link to heading](\#model-integration-settings)    Model Integration Settings

Choose your model in Dify's `Settings > Model Provider`.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-f1c30158dd452b41243e9e94154d54a2fd4c5bec%252Fimage-20231210143654461.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=72d72b13&sv=2)

Model providers fall into two categories:

1. Proprietary Models: Developed by providers such as OpenAI and Anthropic.

2. Hosted Models: Offer third-party models, like Hugging Face and Replicate.


Integration methods differ between these categories.

**Proprietary Model Providers:** Dify connects to all models from an integrated provider. Set the provider's API key in Dify to integrate.

Dify uses [PKCS1\_OAEP](https://pycryptodome.readthedocs.io/en/latest/src/cipher/oaep.html) encryption to protect your API keys. Each user (tenant) has a unique key pair for encryption, ensuring your API keys remain confidential.

**Hosted Model Providers:** Integrate third-party models individually.

Specific integration methods are not detailed here.

- [Hugging Face](https://docs.dify.ai/advanced/model-configuration/hugging-face)

- [Replicate](https://docs.dify.ai/advanced/model-configuration/replicate)

- [Xinference](https://docs.dify.ai/advanced/model-configuration/xinference)

- [OpenLLM](https://docs.dify.ai/advanced/model-configuration/openllm)


## [Direct link to heading](\#using-models)    Using Models

Once configured, these models are ready for application use.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-02b7704fb4e23b6d12edee6c3a2984bdc1971df0%252Fchoice-model-in-app.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=b992d36e&sv=2)

[PreviousDify Premium on AWS](/getting-started/dify-premium-on-aws) [NextAdd New Provider](/guides/model-configuration/new-provider)

Last updated 2 months ago### [Direct link to heading](\#tool-definition)    Tool Definition

Tools can extend the capabilities of LLMs (Language Learning Models), such as performing web searches, scientific calculations, or generating images, thereby enhancing the LLM's ability to connect with the external world. Dify provides two types of tools: **First-party Tools** and **Custom Tools**.

You can directly use the first-party built-in tools provided by the Dify ecosystem, or easily import custom API tools (currently supporting OpenAPI / Swagger and OpenAI Plugin specifications).

#### [Direct link to heading](\#functions-of-tools)    Functions of Tools:

1. Tools allow users to create more powerful AI applications on Dify. For example, you can arrange suitable tools for an intelligent assistant application (Agent) that can complete complex tasks through task reasoning, step-by-step breakdown, and tool invocation.

2. They facilitate connecting your application with other systems or services and interacting with the external environment, such as code execution or access to proprietary information sources.


### [Direct link to heading](\#how-to-configure-first-party-tools)    How to Configure First-party Tools

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-dd81c9a8a472ccbd703b491499e4e2e203dbff16%252Ffirst-party-tools.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=24801fc8&sv=2)

First-party Tools List

Dify currently supports:

Tool

Description

Google Search

Tool for performing Google SERP searches and extracting snippets and web pages. The input should be a search query.

Wikipedia

Tool for performing Wikipedia searches and extracting snippets and web pages.

DALL-E Drawing

Tool for generating high-quality images through natural language input.

Web Scraping

Tool for scraping web data.

WolframAlpha

A powerful computational knowledge engine that provides standardized answers based on questions and has strong mathematical computation capabilities.

Chart Generation

Tool for generating visual charts, allowing you to create bar charts, line charts, pie charts, and other types of charts.

Current Time

Tool for querying the current time.

Yahoo Finance

Tool for obtaining and organizing the latest financial information, such as news and stock quotes.

Stable Diffusion

A tool for generating images that can be deployed locally using stable-diffusion-webui.

Vectorizer

Tool for quickly and easily converting PNG and JPG images to SVG vector graphics.

YouTube

Tool for retrieving statistics of YouTube channel videos.

We welcome you to contribute your developed tools to Dify. For detailed methods on how to contribute, please refer to the [Dify Development Contribution Documentation](https://github.com/langgenius/dify/blob/main/CONTRIBUTING.md). Your support is invaluable to us.

#### [Direct link to heading](\#first-party-tool-authorization)    First-party Tool Authorization

If you need to use the first-party built-in tools provided by the Dify ecosystem, you need to configure the corresponding credentials before using them.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-029dd98f0072c266f4111008116e734fe4c24c55%252Fconfigure-first-party-tool-api.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=13384ed1&sv=2)

Configure First-party Tool Credentials

Once the credentials are successfully verified, the tool will display an "Authorized" status. After configuring the credentials, all members in the workspace can use this tool when arranging applications.

### [Direct link to heading](\#how-to-create-custom-tools)    How to Create Custom Tools

You can import custom API tools in the "Tools - Custom Tools" section, currently supporting OpenAPI / Swagger and ChatGPT Plugin specifications. You can directly paste the OpenAPI schema content or import it from a URL. For the OpenAPI / Swagger specification, you can refer to the [official documentation](https://swagger.io/specification/).

Currently, tools support two authentication methods: No Authentication and API Key.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fgithub.com%2Flanggenius%2Fdify-docs%2Fblob%2Fmain%2Fen%2F.gitbook%2Fassets%2Fen-tools-create-customized-tools-1.png&width=768&dpr=4&quality=100&sign=9c1b88a&sv=2)

Create Custom Tools

After importing the schema content, the system will automatically parse the parameters in the file, and you can preview the specific parameters, methods, and paths of the tool. You can also test the tool parameters here.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fgithub.com%2Flanggenius%2Fdify-docs%2Fblob%2Fmain%2Fen%2F.gitbook%2Fassets%2Fen-tools-create-customized-tools-2.png&width=768&dpr=4&quality=100&sign=bfb0e87f&sv=2)

Custom Tool Parameter Testing

Once the custom tool is created, all members in the workspace can use this tool when arranging applications in the "Studio."

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fgithub.com%2Flanggenius%2Fdify-docs%2Fblob%2Fmain%2Fen%2F.gitbook%2Fassets%2Fen-tools-create-customized-tools-3.png&width=768&dpr=4&quality=100&sign=39262bc&sv=2)

Custom Tool Added

#### [Direct link to heading](\#cloudflare-workers)    Cloudflare Workers

You can also use [dify-tools-worker](https://github.com/crazywoola/dify-tools-worker) to quickly deploy custom tools. This tool provides:

- Routes that can be imported into Dify `https://difytoolsworker.yourname.workers.dev/doc`, offering an OpenAPI-compatible interface documentation.

- API implementation code that can be directly deployed to Cloudflare Workers.


### [Direct link to heading](\#how-to-use-tools-in-applications)    How to Use Tools in Applications

Currently, you can use the configured tools when creating **intelligent assistant applications** in the "Studio."

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-2c902e08df13801eb4f13cf7a48648fca5bd0fb6%252Fuse-tools-in-app.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=9efee366&sv=2)

Add Tools When Creating Intelligent Assistant Applications

For example, after adding tools in a financial analysis application, the intelligent assistant will autonomously invoke tools when needed to query financial report data, analyze the data, and complete the conversation with the user.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-39e584b149a9e935acf45ab1332771dd80b8c861%252Fai-using-tools-during-conversation.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=33ee5749&sv=2)

Intelligent Assistant Using Tools to Answer Questions During Conversation

[PreviousExternal Knowledge API](/guides/knowledge-base/external-knowledge-api-documentation) [NextQuick Tool Integration](/guides/tools/quick-tool-integration)

Last updated 2 months agoDify is an open-source platform for building AI applications. We combine Backend-as-a-Service and LLMOps to streamline the development of generative AI solutions, making it accessible to both developers and non-technical innovators.

Our platform integrates:

- Support for mainstream LLMs

- An intuitive Prompt orchestration interface

- High-quality RAG engines

- A flexible AI Agent framework

- An Intuitive Low-code Workflow

- Easy-to-use interfaces and APIs


With Dify, you can skip the complexity and focus on what matters most - creating innovative AI applications that solve real-world problems.

### [Direct link to heading](\#the-advantage-of-dify)    The Advantage of Dify

While many AI development tools offer individual components, Dify provides a comprehensive, production-ready solution. Think of Dify as a well-designed scaffolding system, not just a toolbox.

As an open-source platform, Dify is co-created by a dedicated professional team and a vibrant community. This collaboration ensures rapid iteration, robust features, and a user-friendly interface.

With Dify, you can:

- Deploy capabilities similar to Assistants API and GPTs using any model

- Maintain full control over your data with flexible security options

- Leverage an intuitive interface for easy management and deployment


### [Direct link to heading](\#dify)    Dify

The name Dify comes from "Define + Modify", referring to defining and continuously improving your AI applications. It's made for you.

Here's how various groups are leveraging Dify:

1. **Startups**: Rapidly prototype and iterate on AI ideas, accelerating both successes and failures. Numerous teams have used Dify to build MVPs, secure funding, and win customer contracts.

2. **Established Businesses**: Enhance existing applications with LLM capabilities. Use Dify's RESTful APIs to separate prompts from business logic, while utilizing our management interface to track data, costs, and usage.

3. **Enterprise AI infrastructure**: Banks and tech companies are deploying Dify as an internal LLM gateway, facilitating GenAI adoption with centralized governance.

4. **AI Enthusiasts and Learners**: Practice prompt engineering and explore agent technologies with ease. Over 60,000 developers built their first AI app on Dify even before GPTs were introduced. Since then, our community has grown significantly, now boasting over 180,000 developers and supporting 59,000+ end users.


Whether you're a startup founder, an enterprise developer, or an AI enthusiast, Dify is designed to meet your needs and accelerate your AI journey!

### [Direct link to heading](\#next-steps)    Next Steps

- Read [**Quick Start**](https://docs.dify.ai/application/creating-an-application) for an overview of Dify’s application building workflow.

- Learn how to [**self-deploy Dify**](https://docs.dify.ai/getting-started/install-self-hosted) to your servers and [**integrate open source models**](https://docs.dify.ai/advanced/model-configuration) **.**

- Understand Dify’s [**specifications and roadmap**](https://docs.dify.ai/getting-started/readme/features-and-specifications) **.**

- [**Star us on GitHub**](https://github.com/langgenius/dify) and read our **Contributor Guidelines.**


[NextFeatures and Specifications](/getting-started/readme/features-and-specifications)

Last updated 3 months agoIn the process of creating AI applications, developers face constantly changing business needs and complex technical challenges. Effectively leveraging extension capabilities can not only enhance the flexibility and functionality of applications but also ensure the security and compliance of enterprise data. Dify offers the following two methods of extension:

[API-Based Extension](/guides/extension/api-based-extension) [Code-Based Extension](/guides/extension/code-based-extension)

[PreviousIntegrate Langfuse](/guides/monitoring/integrate-external-ops-tools/integrate-langfuse) [NextAPI-Based Extension](/guides/extension/api-based-extension)

Last updated 5 months agoDify supports various tools to enhance your application's capabilities. Each tool has unique features and parameters, so select a tool that suits your application's needs. **Obtain the API key from the tool provider's official website before using it in Dify.**

## [Direct link to heading](\#tools-integration-guides)    Tools Integration Guides

- [StableDiffusion](/guides/tools/tool-configuration/stable-diffusion): A tool for generating images based on text prompts.

- [SearXNG](/guides/tools/tool-configuration/searxng): A free internet metasearch engine which aggregates results from various search services and databases.


[PreviousAdvanced Tool Integration](/guides/tools/advanced-tool-integration) [NextGoogle](/guides/tools/tool-configuration/google)

Last updated 5 months ago[App Management](/guides/management/app-management) [Team Members Management](/guides/management/team-members-management) [Personal Account Management](/guides/management/personal-account-management) [Subscription Management](/guides/management/subscription-management)

[PreviousInvite and Manage Members](/guides/workspace/invite-and-manage-members) [NextApp Management](/guides/management/app-management)Dify is a multi-user platform where workspaces are the basic units of team collaboration. Members of a workspace can create and edit applications and knowledge bases, and can also directly use public applications created by other team members in the [Discover](/guides/workspace/app) area.

### [Direct link to heading](\#login-methods)    Login Methods

It is important to note that the login methods supported by Dify's cloud service and community edition differ, as shown in the table below.

Community version & Dify Premium

Dify Cloud

Enterprise version

Email Login

Supported

Not Supported

Supported

GitHub Login

Not Supported

Supported

-

Google Login

Not Supported

Supported

-

SSO Login

Not Supported

Not Supported

Supported

### [Direct link to heading](\#creating-an-account)    Creating an Account

If you are using the cloud service, a workspace will be automatically created for you upon your first login, and you will become the administrator.

In the community version, you will be prompted to set an administrator email and password during installation. The community edition does not support the creation of multiple workspaces.

[PreviousModeration](/guides/extension/code-based-extension/moderation) [NextDiscover](/guides/workspace/app)

Last updated 4 months ago

This site uses cookies to deliver its service and to analyse traffic. By browsing this site, you accept the [privacy policy](https://dify.ai/privacy).

AcceptRejectDify 支持各种工具来增强应用的功能。每个工具都有独特的功能和参数，因此选择适合应用需求的工具。 **在 Dify 中使用之前，请从工具提供商的官方网站获取 API 密钥。**

> 在部分工具内配置凭据后，工作区中的所有成员都可以使用此工具，请注意对应 Key 背后的服务额度消耗。

## [Direct link to heading](\#gong-ju-ji-cheng-zhi-nan)    工具集成指南

- [StableDiffusion](/zh-hans/guides/tools/tool-configuration/stable-diffusion)：一种基于文本提示生成图像的工具。

- [SearXNG](/zh-hans/guides/tools/tool-configuration/searxng)：一个免费的互联网元搜索引擎，整合了各种搜索服务的结果。用户不会被跟踪，也不会被分析。


[Previous高级接入工具](/zh-hans/guides/tools/advanced-tool-integration) [NextGoogle](/zh-hans/guides/tools/tool-configuration/google)

Last updated 4 months ago如果你阅读这套文档时，仍然对产品使用存在疑问和建议，可尝试以下方式寻求支持。我们的团队与社区会竭尽所能的为你提供帮助。

### [Direct link to heading](\#she-qu-zhi-chi)    社区支持

请不要将涉及你的 Dify 账户信息与其它密钥信息发至社区，我们的支持人员也不会索要你的账户信息。

- 在 [Github](https://github.com/langgenius/dify) 上提交 Issue

- 加入 [Discord](https://discord.gg/8Tpq4AcN9c) 社群


### [Direct link to heading](\#lian-xi-wo-men)    联系我们

适用于除了寻求产品支持以外的其他事宜。

- 发邮件至 [hello@dify.ai](mailto:hello@dify.ai)


[PreviousChatFlow 实战：搭建 Twitter 账号分析助手](/zh-hans/workshop/intermediate/twitter-chatflow) [Next成为贡献者](/zh-hans/community/contribution)

Last updated 1 month ago[GPUStack](https://github.com/gpustack/gpustack) is an open-source GPU cluster manager for running large language models(LLMs).

Dify allows integration with GPUStack for local deployment of large language model inference, embedding and reranking capabilities.

## [Direct link to heading](\#deploying-gpustack)    Deploying GPUStack

You can refer to the official [Documentation](https://docs.gpustack.ai) for deployment, or quickly integrate following the steps below:

### [Direct link to heading](\#linux-or-macos)    Linux or MacOS

GPUStack provides a script to install it as a service on systemd or launchd based systems. To install GPUStack using this method, just run:

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
curl -sfL https://get.gpustack.ai | sh -s -
```

### [Direct link to heading](\#windows)    Windows

Run PowerShell as administrator ( **avoid** using PowerShell ISE), then run the following command to install GPUStack:

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
Invoke-Expression (Invoke-WebRequest -Uri "https://get.gpustack.ai" -UseBasicParsing).Content
```

Then you can follow the printed instructions to access the GPUStack UI.

## [Direct link to heading](\#deploying-llm)    Deploying LLM

Using a LLM hosted on GPUStack as an example:

1. In GPUStack UI, navigate to the "Models" page and click on "Deploy Model", choose `Hugging Face` from the dropdown.

2. Use the search bar in the top left to search for the model name `Qwen/Qwen2.5-0.5B-Instruct-GGUF`.

3. Click `Save` to deploy the model.


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-111d898b89d289911d27b2f83686c498d4a800dc%252Fgpustack-deploy-llm.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=71903d83&sv=2)

gpustack-deploy-llm

## [Direct link to heading](\#create-an-api-key)    Create an API Key

1. Navigate to the "API Keys" page and click on "New API Key".

2. Fill in the name, then click `Save`.

3. Copy the API key and save it for later use.


## [Direct link to heading](\#integrating-gpustack-into-dify)    Integrating GPUStack into Dify

1. Go to `Settings > Model Providers > GPUStack` and fill in:



- Model Type: `LLM`

- Model Name: `qwen2.5-0.5b-instruct`

- Server URL: `http://your-gpustack-server-ip`

- API Key: `Input the API key you copied from previous steps`


Click "Save" to use the model in the application.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-54ece0bc1f8f7b334cc51288c395f59c3f7a136d%252Fadd-gpustack-llm.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=ab97e5f&sv=2)

add-gpustack-llm

For more information about GPUStack, please refer to [Github Repo](https://github.com/gpustack/gpustack).

[PreviousIntegrate Models on LiteLLM Proxy](/development/models-integration/litellm) [NextUse Cases](/learn-more/use-cases)

Last updated 1 month agoWe adopt transparent policies around product specifications to ensure decisions are made based on complete understanding. Such transparency not only benefits your technical selection, but also promotes deeper comprehension within the community for active contributions.

### [Direct link to heading](\#project-basics)    Project Basics

Established

March 2023

Open Source License

[Apache License 2.0 with commercial licensing](/policies/open-source)

Official R&D Team

Over 15 full-time employees

Community Contributors

Over [290](https://ossinsight.io/analyze/langgenius/dify#overview) people(As of Q2 2024)

Backend Technology

Python/Flask/PostgreSQL

Frontend Technology

Next.js

Codebase Size

Over 130,000 lines

Release Frequency

Average once per week

### [Direct link to heading](\#technical-features)    Technical Features

LLM Inference Engines

Dify Runtime (LangChain removed since v0.4)

Commercial Models Supported

**10+**, including OpenAI and Anthropic
Onboard new mainstream models within 48 hours

MaaS Vendor Supported

**7**, Hugging Face, Replicate, AWS Bedrock, NVIDIA, GroqCloud, together.ai,, OpenRouter

Local Model Inference Runtimes Supported

**6**, Xoribits (recommended), OpenLLM, LocalAI, ChatGLM,Ollama, NVIDIA TIS

OpenAI Interface Standard Model Integration Supported

**∞**

Multimodal Capabilities

ASR Models

Rich-text models up to GPT-4o specs

Built-in App Types

Text generation, Chatbot, Agent, Workflow, Chatflow

Prompt-as-a-Service Orchestration

Visual orchestration interface widely praised, modify Prompts and preview effects in one place.

**Orchestration Modes**

- Simple orchestration

- Assistant orchestration

- Flow orchestration


**Prompt Variable Types**

- String

- Radio enum

- External API

- File (Q3 2024)


Agentic Workflow Features

Industry-leading visual workflow orchestration interface, live-editing node debugging, modular DSL, and native code runtime, designed for building more complex, reliable, and stable LLM applications.

Supported Nodes

- LLM

- Knowledge Retrieval

- Question Classifier

- IF/ELSE

- CODE

- Template

- HTTP Request

- Tool


RAG Features

Industry-first visual knowledge base management interface, supporting snippet previews and recall testing.

**Indexing Methods**

- Keywords

- Text vectors

- LLM-assisted question-snippet model


**Retrieval Methods**

- Keywords

- Text similarity matching

- Hybrid Search

- N choose 1（Legacy）

- Multi-path retrieval


**Recall Optimization**

- Rerank models


ETL Capabilities

Automated cleaning for TXT, Markdown, PDF, HTML, DOC, CSV formats. Unstructured service enables maximum support.

Sync Notion docs as knowledge bases.
Sync Webpages as knowledge bases.

Vector Databases Supported

Qdrant (recommended), Weaviate，Zilliz/Milvus, Pgvector, Pgvector-rs，Chroma, OpenSearch, TiDB, Tencent Vector, Oracle, Relyt, Analyticdb, Couchbase

Agent Technologies

ReAct, Function Call.

**Tooling Support**

- Invoke OpenAI Plugin standard tools

- Directly load OpenAPI Specification APIs as tools


**Built-in Tools**

- 40+ tools(As of Q2 2024)


Logging

Supported, annotations based on logs

Annotation Reply

Based on human-annotated Q&As, used for similarity-based replies. Exportable as data format for model fine-tuning.

Content Moderation

OpenAI Moderation or external APIs

Team Collaboration

Workspaces, multi-member management

API Specs

RESTful, most features covered

Deployment Methods

Docker, Helm

[PreviousWelcome to Dify](/) [NextList of Model Providers](/getting-started/readme/model-providers)

Last updated 1 month ago[Xorbits inference](https://github.com/xorbitsai/inference) is a powerful and versatile library designed to serve language, speech recognition, and multimodal models, and can even be used on laptops. It supports various models compatible with GGML, such as chatglm, baichuan, whisper, vicuna, orca, etc. And Dify supports connecting to Xinference deployed large language model inference and embedding capabilities locally.

## [Direct link to heading](\#deploy-xinference)    Deploy Xinference

Please note that you usually do not need to manually find the IP address of the Docker container to access the service, because Docker offers a port mapping feature. This allows you to map the container ports to local machine ports, enabling access via your local address. For example, if you used the `-p 80:80` parameter when running the container, you can access the service inside the container by visiting `http://localhost:80` or `http://127.0.0.1:80`.

If you do need to use the container's IP address directly, the steps above will assist you in obtaining this information.

### [Direct link to heading](\#starting-xinference)    Starting Xinference

There are two ways to deploy Xinference, namely [local deployment](https://github.com/xorbitsai/inference/blob/main/README.md#local) and [distributed deployment](https://github.com/xorbitsai/inference/blob/main/README.md#distributed), here we take local deployment as an example.

1. First, install Xinference via PyPI:







Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
$ pip install "xinference[all]"
```

2. Start Xinference locally:







Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
$ xinference-local
2023-08-20 19:21:05,265 xinference   10148 INFO     Xinference successfully started. Endpoint: http://127.0.0.1:9997
2023-08-20 19:21:05,266 xinference.core.supervisor 10148 INFO     Worker 127.0.0.1:37822 has been added successfully
2023-08-20 19:21:05,267 xinference.deploy.worker 10148 INFO     Xinference worker successfully started.
```





Xinference will start a worker locally by default, with the endpoint: `http://127.0.0.1:9997`, and the default port is `9997`. By default, access is limited to the local machine only, but it can be configured with `-H 0.0.0.0` to allow access from any non-local client. To modify the host or port, you can refer to xinference's help information: `xinference-local --help`.



> If you use the Dify Docker deployment method, you need to pay attention to the network configuration to ensure that the Dify container can access the endpoint of Xinference. The Dify container cannot access localhost inside, and you need to use the host IP address.

3. Create and deploy the model



Visit `http://127.0.0.1:9997`, select the model and specification you need to deploy, as shown below:





![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-1da79199a6fdc32848d828fc0a647d724d7845c6%252Fimage%2520%2816%29%2520%281%29.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=3bdc113e&sv=2)





As different models have different compatibility on different hardware platforms, please refer to [Xinference built-in models](https://inference.readthedocs.io/en/latest/models/builtin/index.html) to ensure the created model supports the current hardware platform.

4. Obtain the model UID



Copy model ID from `Running Models` page, such as: `2c886330-8849-11ee-9518-43b0b8f40bea`

5. After the model is deployed, connect the deployed model in Dify.



In `Settings > Model Providers > Xinference`, enter:



- Model name: `vicuna-v1.3`

- Server URL: `http://<Machine_IP>:9997` **Replace with your machine IP address**

- Model UID: `2c886330-8849-11ee-9518-43b0b8f40bea`


Click "Save" to use the model in the dify application.

Dify also supports using [Xinference builtin models](https://github.com/xorbitsai/inference/blob/main/README.md#builtin-models) as Embedding models, just select the Embeddings type in the configuration box.

For more information about Xinference, please refer to: [Xorbits Inference](https://github.com/xorbitsai/inference)

[PreviousIntegrate Open Source Models from Replicate](/development/models-integration/replicate) [NextIntegrate Local Models Deployed by OpenLLM](/development/models-integration/openllm)

Last updated 6 months ago

This site uses cookies to deliver its service and to analyse traffic. By browsing this site, you accept the [privacy policy](https://dify.ai/privacy).

AcceptRejectワークフローアプリは通常、複数の連携する部分（ノード）から成り立っています。どこか一つの部分で発生したエラー（APIリクエストの失敗やLLM出力の問題など）が全体の動作を止めてしまうことがあり、その場合、開発者は故障箇所を見つけて修正するのに大きな労力を費やす必要があります。これは、特に複雑なワークフローの場合には一層の課題となります。

エラー処理メカニズムによって、部分的な問題を様々な方法でうまく対処できるようになります。これにより、一部で問題が発生しても、全体の処理を止めることなくエラー情報を記録したり、別の方法でタスクを完了させることが可能です。アプリケーションの重要な部分にこのメカニズムを取り入れることで、全体の柔軟性と強靭さが大きく向上します。

開発者は、複雑なエラー対応コードを各ノードに書き込む必要がなくなります。また、エラー処理用の追加部分を設けることもなくなります。このメカニズムは、ワークフローの設計をシンプルにし、様々な戦略を用いて実行ロジックを整理します。

## [Direct link to heading](\#shinario)    実践シナリオ

1. **ネットワークエラーの対応** 例えば、あるワークフローが天気情報、ニュース要約、ソーシャルメディア分析の3つのAPIサービスからデータを取得し、それらを統合する必要があるとします。リクエスト制限により一部のサービスが応答しない場合があります。エラー処理を利用して、メインの処理は他のデータソースの処理を続けつつ、失敗したAPI呼び出しの詳細を記録します。これにより開発者は後からこれらの情報を分析し、サービス呼び出しの戦略を改善することができます。

2. **ワークフローの代替ルート** たとえば、あるLLMノードが詳細なドキュメントの要約を行う際に、入力が長すぎてトークン制限を超えてしまい、エラーが発生することがあります。エラー処理メカニズムを設定することで、このような状況に遭遇した際には、内容を小分けにして処理を続ける代替ルートを自動的に選択でき、処理の中断を避けることができます。

3. **エラー情報の明確化** 実行中にあいまいなエラーメッセージ（「呼び出し失敗」など）が返されると、問題の特定が難しくなることがあります。エラー処理メカニズムにより、開発者はエラーメッセージを事前に定義することができ、デバッグ時により明確で正確な情報を提供することが可能になります。


## [Direct link to heading](\#ermekanizumuno)    エラー処理メカニズムの活用

以下の4つのノードタイプにエラー処理メカニズムを組み込むことで、より詳細なドキュメントを参照し、アプリを強化することができます：

- [LLM](/ja-jp/guides/workflow/node/llm)

- [HTTP](/ja-jp/guides/workflow/node/http-request)

- [コード](/ja-jp/guides/workflow/node/code)

- [ツール](/ja-jp/guides/workflow/node/tools)


**失敗後の再試行**

特定の例外状況では、ノードの再試行操作によって問題を解決できる場合があります。このような場合には、ノードの「失敗後の再試行」機能を有効化し、再試行の最大回数と間隔を指定することが可能です。

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2F18097e4c94b67a79150b967fc50f9f43.png&width=768&dpr=4&quality=100&sign=5bbe2be9&sv=2)

もしノードの再試行を行ってもエラーが続く場合、エラー処理機能が予め定められた対策に従って次の手順を進めます。

**エラー処理**

異常処理の仕組みには、次の3つの選択肢があります：

- **処理なし**：エラーを処理せずに、ノードからのエラーメッセージをそのまま返し、フロー全体を停止します。

- **デフォルト値**：開発者がエラー情報をあらかじめ定義できるようにします。エラーが発生した場合、定義された値によって元のノードが返すエラー情報を置き換えます。

- **エラーブランチ**：エラーが発生した場合、あらかじめ設定されたエラー処理のブランチを実行します。


各処理方法の詳細と設定方法については、 [事前定義されたエラー処理ロジック](https://github.com/langgenius/dify-docs/blob/main/jp/guides/workflow/error-handling/predefined-nodes-failure-logic.md) をご覧ください。

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2F6e2655949889d4d162945d840d698649.png&width=768&dpr=4&quality=100&sign=5c5b26ea&sv=2)

## [Direct link to heading](\#suttoappugaido)    スタートアップガイド

**シナリオ：ワークフローアプリにエラー処理メカニズムを追加する**

以下は、ワークフローアプリで異常処理メカニズムを設定し、ノードの異常に備えて代替処理を行う方法の簡単な例です。

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2F958326384d3b60a98246e9ff565c7ed3.png&width=768&dpr=4&quality=100&sign=29cf0f50&sv=2)

**アプリのロジック**：LLMノードは入力された指示に従って、正しい形式や間違った形式のJSONコードを生成します。その後、Aコードノードがこのコードを実行し結果を出力します。Aコードノードが誤った形式のJSONコンテンツを受け取った場合には、設定された異常処理メカニズムに基づいて、代替パスを実行しメインプロセスを継続します。

**1\. JSONコード生成ノードの設定**

新しいワークフローアプリを作成し、LLMノードとコードノードを追加します。プロンプトを使ってLLMが指示に従い、正しい形式や間違った形式のJSONコンテンツを生成し、それがAコードノードで検証されます。

**LLMノードでのプロンプト例：**

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
You are a teaching assistant. According to the user's requirements, you only output a correct or incorrect sample code in json format.
```

**コードノードでのJSON検証コード：**

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
def main(json_str: str) -> dict:
    obj = json.loads(json_str)
    return {'result': obj}
```

**2\. Aコードノードにエラー処理機能を追加する**

Aコードノードは、JSONコンテンツを検証する役割を持ち、受け取ったJSONコンテンツがフォーマットに合わない場合には、エラー処理機能を通じて代替の手順を踏み、エラーを修正するために次のLLMノードに渡します。その後、JSONを再度検証し、メインの処理フローを再開します。Aコードノードの「エラー処理」タブから「エラー分岐」の設定を行い、新たなLLMノードを設定しましょう。

**3\. Aコードノードが出力するエラーの内容を修正**

新設したLLMノードでは、プロンプトに指示を記述し、変数を用いてAコードノードが出力したエラー内容を参照・修正します。次に、Bコードノードを追加し、JSONコンテンツの再検証を行います。

**4\. プロセスの完了**

変数を集約するノードを追加して、正常な処理結果とエラー処理結果をまとめ、終了ノードで出力します。これでフロー全体のプロセスが完了します。

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2F059b5a814514cd9abe10f1f4077ed17f.png&width=768&dpr=4&quality=100&sign=98b36ab7&sv=2)

> デモ用のDSLファイルはこちらから [ダウンロード](https://assets-docs.dify.ai/2024/12/087861aa20e06bb4f8a2bef7e7ae0522.yml) できます。

## [Direct link to heading](\#suttasu)    ステータス説明

この文書では、ノードとプロセスの状態について説明します。状態を明確にすることで、開発者は現在のワークフローアプリケーションの動作状況を理解しやすくなり、問題解決や迅速な意思決定に役立ちます。エラー処理機能を導入したことにより、ノードとプロセスの状態には以下のような分類があります：

**ノードの状態**

- **成功** ノードが正常に動作して正確な情報を出力しました。

- **失敗** エラー処理が行われず、ノードの動作が失敗し、エラー情報が出力されました。

- **エラー** ノードでエラーが発生しましたが、処理が継続されました。


**ワークフローの状態**

- **成功** プロセスの全ノードが正常に動作し、終了ノードが適切に情報を出力し、ステータスが成功として設定されました。

- **失敗** ノードでエラーが発生し、プロセス全体が停止し、ステータスが失敗として設定されました。

- **部分成功** ノードでエラーが発生しましたが、エラー処理機能によってプロセス全体が最終的に正常に動作しました。ステータスは部分成功として設定されました。


## [Direct link to heading](\#yokuaru)    よくある質問

**1\. エラー処理機構を導入することで何が変わりますか？**

**エラー処理機構がない場合:**

- **作業フローが中断する**：外部のサービス呼び出しに失敗する、ネットワークに問題がある、ツールにエラーが存在するなどの理由で、一つのエラーが発生すると、作業フローが即座に停止します。開発者はエラーを手動で探し出し、修正後に作業フローを再開する必要があります。

- **対応策の制約**：開発者は異なるエラータイプや事象に応じて特別な対応策を講じることができません。たとえば、エラーが発生した場合にもフローを継続する、または別の処理へ切り替えるといったことができなくなります。

- **冗長なノードの手動追加が必要**：エラーがフロー全体に影響を与えないようにするためには、エラーを捉えて処理するために多くの追加ノードを設計する必要があり、これが作業フローの複雑さや開発コストを増加させます。

- **限られたログ情報**：エラーログは通常、内容が簡素であったり、必要な情報が不足していたりします。これでは問題の迅速な診断が難しくなります。


**エラー処理機構を導入した後:**

- **フローが中断されることがない**：あるノードでエラーが発生しても、事前に定めたルールに従って作業フローを継続することができ、一点の障害が全体に影響することが少なくなります。

- **エラー処理を柔軟にカスタマイズ可能**：開発者はそれぞれのノードごとにエラー対応の戦略を設定できます。例えば、フローを継続したり、ログを残したり、別のルートに切り替えたりすることができます。

- **作業フローの設計をシンプルに**：一般的なエラー処理機構により、開発者が冗長なノードを手動で設計する必要が減り、作業フローがよりシンプルで明瞭になります。

- **詳細なエラーログを提供**：カスタマイズ可能なエラー情報の整理メカニズムを提供し、開発者が問題を迅速に特定し、フローを最適化するのに役立ちます。


**2\. 代替ルートの実行状況をどうやってデバッグしますか？**

作業フローの実行ログをチェックすることで、条件分岐やルート選択の状況を確認できます。エラー処理のブランチは黄色でハイライトされ、開発者が計画通りに代替ルートが実行されているかどうかを簡単に確認できます。

[Previousファイルアップロード](/ja-jp/guides/workflow/file-upload) [Next事前定義されたエラー処理ロジック](/ja-jp/guides/workflow/error-handling/predefined-nodes-failure-logic)

Last updated 13 days ago[LocalAI](https://github.com/go-skynet/LocalAI) is a drop-in replacement REST API that's compatible with OpenAI API specifications for local inferencing. It allows you to run LLMs (and not only) locally or on-prem with consumer grade hardware, supporting multiple model families that are compatible with the ggml format. Does not require GPU.

Dify allows integration with LocalAI for local deployment of large language model inference and embedding capabilities.

## [Direct link to heading](\#deploying-localai)    Deploying LocalAI

### [Direct link to heading](\#starting-localai)    Starting LocalAI

You can refer to the official [Getting Started](https://localai.io/basics/getting_started/) guide for deployment, or quickly integrate following the steps below:

(These steps are derived from [LocalAI Data query example](https://github.com/go-skynet/LocalAI/blob/master/examples/langchain-chroma/README.md))

1. First, clone the LocalAI code repository and navigate to the specified directory.







Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
$ git clone https://github.com/go-skynet/LocalAI
$ cd LocalAI/examples/langchain-chroma
```

2. Download example LLM and Embedding models.







Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
$ wget https://huggingface.co/skeskinen/ggml/resolve/main/all-MiniLM-L6-v2/ggml-model-q4_0.bin -O models/bert
$ wget https://gpt4all.io/models/ggml-gpt4all-j.bin -O models/ggml-gpt4all-j
```





Here, we choose two smaller models that are compatible across all platforms. `ggml-gpt4all-j` serves as the default LLM model, and `all-MiniLM-L6-v2` serves as the default Embedding model, for quick local deployment.

3. Configure the .env file.







Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
$ mv .env.example .env
```





NOTE: Ensure that the THREADS variable value in `.env` doesn't exceed the number of CPU cores on your machine.

4. Start LocalAI.







Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
# start with docker-compose
$ docker-compose up -d --build

# tail the logs & wait until the build completes
$ docker logs -f langchain-chroma-api-1
7:16AM INF Starting LocalAI using 4 threads, with models path: /models
7:16AM INF LocalAI version: v1.24.1 (9cc8d9086580bd2a96f5c96a6b873242879c70bc)
```





The LocalAI request API endpoint will be available at http://127.0.0.1:8080.



And it provides two models, namely:



- LLM Model: `ggml-gpt4all-j`



External access name: `gpt-3.5-turbo` (This name is customizable and can be configured in `models/gpt-3.5-turbo.yaml`).

- Embedding Model: `all-MiniLM-L6-v2`



External access name: `text-embedding-ada-002` (This name is customizable and can be configured in `models/embeddings.yaml`).


> If you use the Dify Docker deployment method, you need to pay attention to the network configuration to ensure that the Dify container can access the endpoint of LocalAI. The Dify container cannot access localhost inside, and you need to use the host IP address.

5. Integrate the models into Dify.



Go to `Settings > Model Providers > LocalAI` and fill in:



Model 1: `ggml-gpt4all-j`



- Model Type: Text Generation

- Model Name: `gpt-3.5-turbo`

- Server URL: http://127.0.0.1:8080



If Dify is deployed via docker, fill in the host domain: `http://<your-LocalAI-endpoint-domain>:8080`, which can be a LAN IP address, like: `http://192.168.1.100:8080`


Click "Save" to use the model in the application.

Model 2: `all-MiniLM-L6-v2`

- Model Type: Embeddings

- Model Name: `text-embedding-ada-002`

- Server URL: http://127.0.0.1:8080



> If Dify is deployed via docker, fill in the host domain: `http://<your-LocalAI-endpoint-domain>:8080`, which can be a LAN IP address, like: `http://192.168.1.100:8080`


Click "Save" to use the model in the application.

For more information about LocalAI, please refer to: https://github.com/go-skynet/LocalAI

[PreviousIntegrate Local Models Deployed by OpenLLM](/development/models-integration/openllm) [NextIntegrate Local Models Deployed by Ollama](/development/models-integration/ollama)

Last updated 3 months agoThe Chatflow / Workflow application orchestration page supports the following shortcut keys to help you improve the efficiency of orchestration nodes.

Windows

macOS

Explanation

Ctrl + C

Command + C

Copy nodes

Ctrl + V

Command + V

Paste nodes

Ctrl + D

Command + D

Duplicate nodes

Ctrl + O

Command + O

Organize nodes

Ctrl + Z

Command + Z

Undo

Ctrl + Y

Command + Y

Redo

Ctrl + Shift + Z

Command + Shift + Z

Redo

Ctrl + 1

Command + 1

Canvas fits view

Ctrl + (-)

Command + (-)

Canvas zooms out

Ctrl + (=)

Command + (=)

Canvas zooms in

Shift + 1

Shift + 1

Resets canvas view to 100%

Shift + 5

Shift + 5

Scales canvas to 50%

H

H

Canvas toggles to Hand mode

V

V

Canvas toggles to Pointer mode

Delete/Backspace

Delete/Backspace

Delete selected nodes

Alt + R

Option + R

Workflow starts to run

[PreviousTools](/guides/workflow/node/tools) [NextOrchestrate Node](/guides/workflow/orchestrate-node)

Last updated 2 months agoこのドキュメントを読んでも製品の使用に関して疑問や提案がある場合は、以下の方法で支援を求めることができます。私たちのチームとコミュニティは、できる限りのサポートを提供いたします。

### [Direct link to heading](\#komyunitisapto)    コミュニティサポート

Difyのアカウント情報やその他の情報をコミュニティに投稿しないでください。また、サポートスタッフもアカウント情報を要求することはありません。

- [Github](https://github.com/langgenius/dify) 上でイシューを提出

- [Discord](https://discord.gg/8Tpq4AcN9c) コミュニティに参加


### [Direct link to heading](\#oiwase)    お問い合わせ

製品サポート以外のその他の事柄に適用されます。

- [hello@dify.ai](mailto:hello@dify.ai) へメールを送信


[Previousファイルアップロードを使用した記事理解アシスタントの構築方法](/ja-jp/workshop/intermediate/article-reader) [Next貢献者ガイド](/ja-jp/community/contribution)

Last updated 5 months ago你可以在 **概览** 内监控、跟踪应用程序在生产环境中的性能，在数据分析仪表盘内分析生产环境中应用的使用成本、延迟、用户反馈、性能等指标，并通过持续调试、迭代不断改进你的应用程序。

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F1288284732-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FCdDIVDY6AtAz028MFT4d%252Fuploads%252FPYOpT6gGSjwNZ2HkqlkQ%252Fimage.png%3Falt%3Dmedia%26token%3D3daaabed-b185-439b-8a1c-74232aee154c&width=768&dpr=4&quality=100&sign=f67d7ce&sv=2)

概览

[Previous标注回复](/zh-hans/guides/annotation/annotation-reply) [Next集成外部 Ops 工具](/zh-hans/guides/monitoring/integrate-external-ops-tools)

Last updated 6 months ago### [Direct link to heading](\#tsru)    ツール定義

ツールは、ネット検索、科学計算、画像の描画などの機能を追加し、大規模言語モデル(LLM)の能力を拡張して外部世界と接続する力を与えます。Difyは2種類のツールを提供しています： **ファーストパーティツール** と **カスタムAPIツール** です。

Difyエコシステムが提供するファーストパーティツールを直接使用することができ、また、OpenAPI/SwaggerおよびOpenAIプラグイン規格をサポートするカスタムAPIツールを簡単にインポートできます。

#### [Direct link to heading](\#tsruno)    ツールの役割：

1. ツールを使用すると、Dify上でより強力なAIアプリケーションを作成できます。たとえば、エージェント型アプリケーションに適切なツールを組み合わせることで、タスク推論、ステップの分解、ツールの呼び出しを通じて複雑なタスクを完了させることができます。

2. あなたのアプリケーションを他のシステムやサービスと連携させ、外部環境と対話できるようにします。たとえば、コードの実行や専用情報源へのアクセスなどです。


### [Direct link to heading](\#fsutoptitsruno)    ファーストパーティツールの設定方法

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3244742310-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FBl3K6n12AeCkG3icHwfh%252Fuploads%252Fgit-blob-dd81c9a8a472ccbd703b491499e4e2e203dbff16%252Ffirst-party-tools.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=ef0acee1&sv=2)

ファーストパーティツールリスト

Difyは現在、以下のツールをサポートしています：

ツール

ツールの説明

Google検索

Google SERP検索を実行し、スニペットやウェブページを抽出するツール。入力は検索クエリであるべきです。

ウィキペディア

ウィキペディア検索を実行し、スニペットやウェブページを抽出するツール。

DALL-E

自然言語入力を通じて高品質な画像を生成するツール。

ウェブスクレイピング

ウェブページデータをクロールするためのツール。

WolframAlpha

質問に基づいた標準化された回答を提供し、強力な数学計算機能を持つ知識エンジン。

可視化チャート生成

棒グラフ、折れ線グラフ、円グラフなどの可視化チャートを生成するツール。

現在時刻

現在の時刻を問い合わせるツール。

Yahooファイナンス

最新のニュース、株価情報などの財務情報を取得して整理するツール。

Stable Diffusion

ローカルに展開可能な画像生成ツールで、stable-diffusion-webuiを使用して展開できます。

ベクトライザー

PNGおよびJPG画像をSVGベクトル画像に迅速かつ簡単に変換するツール。

YouTube

YouTubeチャンネルの動画統計データを取得するためのツール。

Difyに自分で開発したツールを貢献することを歓迎します。貢献方法については [Dify開発貢献ドキュメント](https://github.com/langgenius/dify/blob/main/CONTRIBUTING.md) を確認してください。あなたのサポートは私たちにとって非常に貴重です。

#### [Direct link to heading](\#fsutoptitsruno-1)    ファーストパーティツールの認証

Difyエコシステムが提供するファーストパーティ・ビルトインツールを直接使用する場合、使用前に適切な認証情報を設定する必要があります。

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3244742310-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FBl3K6n12AeCkG3icHwfh%252Fuploads%252Fgit-blob-029dd98f0072c266f4111008116e734fe4c24c55%252Fconfigure-first-party-tool-api.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=d737747e&sv=2)

ファーストパーティツール認証情報の設定

認証情報の検証が成功すると、ツールは「認証済み」の状態になります。認証情報が設定されると、ワークスペース内のすべてのメンバーがアプリケーションの編成時にこのツールを使用できます。

### [Direct link to heading](\#kasutamutsruno)    カスタムツールの作成方法

「ツール \- カスタムツール」内でカスタムAPIツールをインポートできます。現在、OpenAPI / SwaggerおよびChatGPTプラグイン規格をサポートしています。OpenAPIスキーマの内容を直接貼り付けるか、URLからインポートできます。OpenAPI / Swagger規格については [公式ドキュメント](https://swagger.io/specification/) を参照してください。

ツールは現在、2種類の認証方式をサポートしています：無認証とAPIキー。

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3244742310-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FBl3K6n12AeCkG3icHwfh%252Fuploads%252Fgit-blob-e328217d8e16ed86651222f25c9d11133ebee705%252Fen-tools-create-customized-tools-1.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=dea80a7b&sv=2)

カスタムツールの作成

スキーマ内容をインポートすると、システムはファイル内のパラメーターを自動的に解析し、ツールの具体的なパラメーター、方法、パスをプレビューできます。ここでツールのパラメーターをテストすることもできます。

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3244742310-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FBl3K6n12AeCkG3icHwfh%252Fuploads%252Fgit-blob-635537ed2c4431eee09c30351a4c3533ca4915bd%252Fen-tools-create-customized-tools-2.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=7becf06b&sv=2)

カスタムツールのパラメータテスト

カスタムツールの作成が完了すると、ワークスペース内のすべてのメンバーが「スタジオ」内でアプリケーションを編成する際にこのツールを使用できます。

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3244742310-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FBl3K6n12AeCkG3icHwfh%252Fuploads%252Fgit-blob-18756551650f48b8fc92666a784d169c3272b235%252Fen-tools-create-customized-tools-3.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=243166fb&sv=2)

カスタムツールが追加されました

#### [Direct link to heading](\#cloudflare-workers)    Cloudflare Workers

[dify-tools-worker](https://github.com/crazywoola/dify-tools-worker) を使用してカスタムツールを迅速に展開することもできます。このツールは以下を提供します：

- Difyにインポート可能なルーティング `https://difytoolsworker.yourname.workers.dev/doc`、OpenAPI互換のインターフェイスドキュメントを提供します。

- APIの実装コードを提供し、Cloudflare Workersに直接展開できます。


### [Direct link to heading](\#apuridetsruwosuru)    アプリ内でツールを使用する方法

現在、「スタジオ」で **エージェント型アプリケーション** を作成する際に、認証情報が設定されたツールを使用できます。

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3244742310-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FBl3K6n12AeCkG3icHwfh%252Fuploads%252Fgit-blob-2c902e08df13801eb4f13cf7a48648fca5bd0fb6%252Fuse-tools-in-app.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=733fd645&sv=2)

エージェント型アプリケーション作成時にツールを追加

以下の図のように、財務分析アプリケーションにツールを追加すると、エージェントは必要に応じてツールを自動的に呼び出し、ツールから財務報告データを取得し、それを解析してユーザーとの対話を完了します。

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3244742310-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FBl3K6n12AeCkG3icHwfh%252Fuploads%252Fgit-blob-39e584b149a9e935acf45ab1332771dd80b8c861%252Fai-using-tools-during-conversation.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=cf7ef792&sv=2)

エージェントが対話中にツールを呼び出して質問に回答

[Previous外部ナレッジベースAPI](/ja-jp/guides/knowledge-base/external-knowledge-api-documentation) [Nextクイック統合ツール](/ja-jp/guides/tools/quick-tool-integration)

Last updated 2 months agoIf you still have questions or suggestions about using the product while reading this documentation, please try the following ways to seek support. Our team and community will do their best to help you.

### [Direct link to heading](\#community-support)    Community Support

Please do not share your Dify account information or other sensitive information with the community. Our support staff will not ask for your account information.

- Submit an Issue on [GitHub](https://github.com/langgenius/dify)

- Join the [Discord community](https://discord.gg/8Tpq4AcN9c)

- Post your ideas or questions on [Reddit](https://www.reddit.com/r/difyai/)


### [Direct link to heading](\#contact-us)    Contact Us

For matters other than product support.

- Email [hello@dify.ai](mailto:hello@dify.ai)


[PreviousGenerating analysis of Twitter account using Chatflow Agent](/workshop/intermediate/twitter-chatflow) [NextBecome a Contributor](/community/contribution)

Last updated 1 month ago### [Direct link to heading](\#ji-ben-shao-jie)    基本紹介

ワークフローは、複雑なタスクを小さなステップ（ノード）に分解することでシステムの複雑さを軽減し、プロンプト技術やモデル推論能力への依存を減らし、LLMアプリケーションの複雑なタスクに対するパフォーマンスを向上させ、システムの解釈性、安定性、耐障害性を高めます。

Difyワークフローには、以下の2種類があります：

- **チャットフロー**：カスタマーサービス、セマンティック検索、その他の対話型アプリケーションの構築において、複数のステップを含む論理を必要とする対話型シナリオに対応します。

- **ワークフロー**：自動化とバッチ処理のシナリオに対応し、高品質な翻訳、データ分析、コンテンツ生成、メール自動化などのアプリケーションに適しています。


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3244742310-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FBl3K6n12AeCkG3icHwfh%252Fuploads%252Fgit-blob-e7ae82959e8f9c3f3353545048b8ee8852a9c6b2%252Fjp-workflow.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=ad57c8d0&sv=2)

自然言語入力におけるユーザー意図認識の複雑さを解決するために、チャットフローは問題理解ノードを提供します。ワークフローに対してチャットボット特性のサポートを追加し、会話履歴（メモリ）、注釈付き返信、Answerノードなどを含みます。

自動化とバッチ処理のシナリオにおける複雑なビジネスロジックを解決するために、ワークフローはコードノード、IF/ELSEノード、テンプレート変換、イテレーションノードなどの豊富なロジックノードを提供し、さらにスケジューリングやイベントトリガの機能も提供し、自動化プロセスの構築を容易にします。

### [Direct link to heading](\#naksu)    一般的なケース

- カスタマーサービス


LLMをカスタマーサービスシステムに統合することで、よくある質問への自動応答を実現し、サポートチームの負担を軽減できます。LLMは顧客の問い合わせのコンテキストと意図を理解し、リアルタイムで役立つ正確な回答を生成します。

- コンテンツ生成


ブログ記事、製品説明、マーケティング資料の作成が必要な場合、LLMは高品質なコンテンツの生成をサポートします。アウトラインやテーマを提供するだけで、LLMは広範なナレッジベースを活用して、魅力的で情報豊富かつ構造化されたコンテンツを作成します。

- タスク自動化


Trello、Slack、Larkなどのタスク管理システムと統合することで、プロジェクトやタスク管理の自動化が可能です。自然言語処理を使用して、LLMはユーザー入力を理解し解釈し、タスクを作成、ステータスを更新し、優先度を割り当てることができます。

- データ分析とレポート


大規模なデータセットを分析し、レポートや要約を生成するために使用できます。関連情報をLLMに提供することで、トレンド、パターン、インサイトを特定し、生データを実行可能なインテリジェンスに変換します。データ駆動型意思決定を目指す企業にとって、これは非常に価値があります。

- メール自動化処理


メールの下書き、ソーシャルメディアの更新、その他のコミュニケーション形式の作成に使用できます。簡単なアウトラインや重要ポイントを提供することで、LLMは構造化され、連続性があり、コンテキストに関連した情報を生成します。これにより、大量の時間を節約し、明確かつプロフェッショナルな返信を確保できます。

### [Direct link to heading](\#me)    始め方

- 空白のワークフローから構築を開始するか、システムテンプレートを使用して開始します。

- 基本操作に慣れる、画面上でノードを作成、接続、設定、ワークフローのデバッグ、実行履歴の確認など。

- ワークフローを保存し公開します。

- 公開済みアプリケーションで実行するか、API呼び出しでワークフローを実行します。


[Previousコンテンツモデレーション](/ja-jp/guides/application-orchestrate/app-toolkits/moderation-tool) [Nextキーコンセプト](/ja-jp/guides/workflow/key-concept)

Last updated 5 months ago### [Direct link to heading](\#id-1-definition)    1 Definition

Define the final output content of a workflow. Every workflow needs at least one end node after complete execution to output the final result.

The end node is a termination point in the process; no further nodes can be added after it. In a workflow application, results are only output when the end node is reached. If there are conditional branches in the process, multiple end nodes need to be defined.

The end node must declare one or more output variables, which can reference any upstream node's output variables.

End nodes are not supported within Chatflow.

* * *

### [Direct link to heading](\#id-2-scenarios)    2 Scenarios

In the following [long story generation workflow](/guides/workflow/node/iteration#example-2-long-article-iterative-generation-another-scheduling-method), the variable `Output` declared by the end node is the output of the upstream code node. This means the workflow will end after the Code node completes execution and will output the execution result of Code.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-9d99907b12419fb3b7c1ab4082a147af3ffb6221%252Fend-answer.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=701b99ab&sv=2)

End Node - Long Story Generation Example

**Single Path Execution Example:**

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-9deec5b609fa4fd1a87afafd808ad6d58f12cdb9%252Fsingle-path-execution.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=f74f840&sv=2)

**Multi-Path Execution Example:**

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-c178f7b324998e9b3f80052815939158580a8212%252Foutput%2520%281%29%2520%283%29.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=88d883ea&sv=2)

[PreviousStart](/guides/workflow/node/start) [NextAnswer](/guides/workflow/node/answer)

Last updated 5 months ago[Logs and Annotation](/guides/annotation/logs) [Annotation Reply](/guides/annotation/annotation-reply)

[PreviousRe-develop Based on Frontend Templates](/guides/application-publishing/based-on-frontend-templates) [NextLogs and Annotation](/guides/annotation/logs)

Last updated 6 months ago### [Direct link to heading](\#introduction)    Introduction

`DifySandbox` is a lightweight, fast, and secure code execution environment that supports multiple programming languages, including Python and Node.js. It serves as the underlying execution environment for various components in Dify Workflow, such as the Code node, Template Transform node, LLM node, and the Code Interpreter in the Tool node. DifySandbox ensures system security while enabling Dify to execute user-provided code.

### [Direct link to heading](\#features)    Features

- **Multi-language Support**: DifySandbox is built on Seccomp, a low-level security mechanism that enables support for multiple programming languages. Currently, it supports Python and Node.js.

- **System Security**: It implements a whitelist policy, allowing only specific system calls to prevent unexpected security breaches.

- **File System Isolation**: User code runs in an isolated file system environment.

- **Network Isolation**:



- **DockerCompose**: Utilizes a separate Sandbox network and proxy containers for network access, maintaining intranet system security while offering flexible proxy configuration options.

- **K8s**: Network isolation strategies can be directly configured using Egress policies.


### [Direct link to heading](\#project-repository)    Project Repository

You can access the [DifySandbox](https://github.com/langgenius/dify-sandbox) repository to obtain the project source code and follow the project documentation for deployment and usage instructions.

### [Direct link to heading](\#contribution)    Contribution

Please refer to the [Contribution Guide](/development/backend/sandbox/contribution) to learn how you can participate in the development of DifySandbox.

[PreviousBackend](/development/backend) [NextContribution Guide](/development/backend/sandbox/contribution)

Last updated 6 months ago在创造 AI 应用的过程中，开发者面临着不断变化的业务需求和复杂的技术挑战。有效地利用扩展能力不仅可以提高应用的灵活性和功能性，还可以确保企业数据的安全性和合规性。

Dify 提供了以下两种扩展方式：

- API 扩展

- 代码扩展


[Previous数据分析](/zh-hans/guides/monitoring/analysis) [NextAPI 扩展](/zh-hans/guides/extension/api-based-extension)

Last updated 7 months agoAfter completing debugging, clicking "Publish" in the upper right corner allows you to save and quickly release the workflow as different types of applications.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-ac78f47bc82135a751876434521af98446414a02%252Foutput%2520%284%29%2520%283%29.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=c9fc3800&sv=2)

Conversational applications can be published as:

- Run App

- Embed into Site

- Access API Reference


Workflow applications can be published as:

- Run App

- Batch Run App

- Access API Reference


You can also click "Restore" to preview the last published version of the application. Confirming the restore will use the last published workflow version to overwrite the current workflow version.

[PreviousRun History](/guides/workflow/debug-and-preview/history) [NextBulletin: Image Upload Replaced by File Upload](/guides/workflow/bulletin)

Last updated 6 months ago所以你想为 Dify 做贡献 - 这太棒了，我们迫不及待地想看到你的贡献。作为一家人员和资金有限的初创公司，我们有着雄心勃勃的目标，希望设计出最直观的工作流程来构建和管理 LLM 应用程序。社区的任何帮助都是宝贵的。

考虑到我们的现状，我们需要灵活快速地交付，但我们也希望确保像你这样的贡献者在贡献过程中获得尽可能顺畅的体验。我们为此编写了这份贡献指南，旨在让你熟悉代码库和我们与贡献者的合作方式，以便你能快速进入有趣的部分。

这份指南，就像 Dify 本身一样，是一个不断改进的工作。如果有时它落后于实际项目，我们非常感谢你的理解，并欢迎任何反馈以供我们改进。

在许可方面，请花一分钟阅读我们简短的 [许可证和贡献者协议](https://github.com/langgenius/dify/blob/main/LICENSE)。社区还遵守 [行为准则](https://github.com/langgenius/.github/blob/main/CODE_OF_CONDUCT.md)。

## [Direct link to heading](\#zai-kai-shi-zhi-qian)    在开始之前

[查找](https://github.com/langgenius/dify/issues?q=is:issue+is:closed) 现有问题，或 [创建](https://github.com/langgenius/dify/issues/new/choose) 一个新问题。我们将问题分为两类：

### [Direct link to heading](\#gong-neng-qing-qiu)    功能请求：

- 如果你要提出新的功能请求，请解释所提议的功能的目标，并尽可能提供详细的上下文。 [@perzeusss](https://github.com/perzeuss) 制作了一个很好的 [功能请求助手](https://udify.app/chat/MK2kVSnw1gakVwMX)，可以帮助你起草需求。随时尝试一下。

- 如果你想从现有问题中选择一个，请在其下方留下评论表示你的意愿。


相关方向的团队成员将参与其中。如果一切顺利，他们将批准你开始编码。在此之前，请不要开始工作，以免我们提出更改导致你的工作付诸东流。

根据所提议的功能所属的领域不同，你可能需要与不同的团队成员交流。以下是我们团队成员目前正在从事的各个领域的概述：

Member

Scope

[@yeuoly](https://github.com/Yeuoly)

Architecting Agents

[@jyong](https://github.com/JohnJyong)

RAG pipeline design

[@GarfieldDai](https://github.com/GarfieldDai)

Building workflow orchestrations

[@iamjoel](https://github.com/iamjoel) & [@zxhlyh](https://github.com/zxhlyh)

Making our frontend a breeze to use

[@guchenhe](https://github.com/guchenhe) & [@crazywoola](https://github.com/crazywoola)

Developer experience, points of contact for anything

[@takatost](https://github.com/takatost)

Overall product direction and architecture

优先级的评判标准:

Feature Type

Priority

High-Priority Features as being labeled by a team member

High Priority

Popular feature requests from our [community feedback board](https://github.com/langgenius/dify/discussions/categories/ideas)

Medium Priority

Non-core features and minor enhancements

Low Priority

Valuable but not immediate

Future-Feature

### [Direct link to heading](\#qi-ta-ren-he-shi-qing-li-ru-bug-bao-gao-xing-neng-you-hua-pin-xie-cuo-wu-geng-zheng)    其他任何事情（例如 bug 报告、性能优化、拼写错误更正）：

- 立即开始编码。



优先级的评判标准:











Issue Type



Priority















Bugs in core functions (cannot login, applications not working, security loopholes)











Critical















Non-critical bugs, performance boosts











Medium Priority















Minor fixes (typos, confusing but working UI)











Low Priority


## [Direct link to heading](\#an-zhuang)    安装

以下是设置 Dify 进行开发的步骤：

### [Direct link to heading](\#id-1.-fork-gai-cang-ku)    1\. Fork 该仓库

### [Direct link to heading](\#id-2.-ke-long-cang-ku)    2\. 克隆仓库

从终端克隆 fork 的仓库：

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
git clone git@github.com:<github_username>/dify.git
```

### [Direct link to heading](\#id-3.-yan-zheng-yi-lai-xiang)    3\. 验证依赖项

Dify 依赖以下工具和库：

- [Docker](https://www.docker.com/)

- [Docker Compose](https://docs.docker.com/compose/install/)

- [Node.js v18.x (LTS)](http://nodejs.org)

- [npm](https://www.npmjs.com/) version 8.x.x or [Yarn](https://yarnpkg.com/)

- [Python](https://www.python.org/) version 3.10.x


### [Direct link to heading](\#id-4.-an-zhuang)    4\. 安装

Dify 由后端和前端组成。通过 `cd api/` 导航到后端目录，然后按照 [后端 README](https://github.com/langgenius/dify/blob/main/api/README.md) 进行安装。在另一个终端中，通过 `cd web/` 导航到前端目录，然后按照 [前端 README](https://github.com/langgenius/dify/blob/main/web/README.md) 进行安装。

查看 [安装常见问题解答](https://docs.dify.ai/v/zh-hans/learn-more/faq/install-faq) 以获取常见问题列表和故障排除步骤。

### [Direct link to heading](\#id-5.-zai-liu-lan-qi-zhong-fang-wen-dify)    5\. 在浏览器中访问 Dify

为了验证你的设置，打开浏览器并访问 [http://localhost:3000](http://localhost:3000)（默认或你自定义的 URL 和端口）。现在你应该看到 Dify 正在运行。

## [Direct link to heading](\#kai-fa)    开发

如果你要添加模型提供程序，请参考 [此指南](https://github.com/langgenius/dify/blob/main/api/core/model_runtime/README.md)。

如果你要向 Agent 或 Workflow 添加工具提供程序，请参考 [此指南](https://github.com/langgenius/dify/blob/main/api/core/tools/README_CN.md)。

> **注意**：如果你想要贡献新的工具，请确保已在工具的 `YAML` 文件内留下了你的联系方式，并且在 [Dify-docs](https://github.com/langgenius/dify-docs/tree/main/en/guides/tools/tool-configuration) 帮助文档代码仓库中提交了对应的文档 PR。

为了帮助你快速了解你的贡献在哪个部分，以下是 Dify 后端和前端的简要注释大纲：

### [Direct link to heading](\#hou-duan)    后端

Dify 的后端使用 Python 编写，使用 [Flask](https://flask.palletsprojects.com/en/3.0.x/) 框架。它使用 [SQLAlchemy](https://www.sqlalchemy.org/) 作为 ORM，使用 [Celery](https://docs.celeryq.dev/en/stable/getting-started/introduction.html) 作为任务队列。授权逻辑通过 Flask-login 进行处理。

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
[api/]
├── constants             // Constant settings used throughout code base.
├── controllers           // API route definitions and request handling logic.
├── core                  // Core application orchestration, model integrations, and tools.
├── docker                // Docker & containerization related configurations.
├── events                // Event handling and processing
├── extensions            // Extensions with 3rd party frameworks/platforms.
├── fields                //field definitions for serialization/marshalling.
├── libs                  // Reusable libraries and helpers.
├── migrations            // Scripts for database migration.
├── models                // Database models & schema definitions.
├── services              // Specifies business logic.
├── storage               // Private key storage.
├── tasks                 // Handling of async tasks and background jobs.
└── tests
```

### [Direct link to heading](\#qian-duan)    前端

该网站使用基于 Typescript 的 [Next.js](https://nextjs.org/) 模板进行引导，并使用 [Tailwind CSS](https://tailwindcss.com/) 进行样式设计。 [React-i18next](https://react.i18next.com/) 用于国际化。

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
[web/]
├── app                   //layouts, pages, and components
│   ├── (commonLayout)    //common layout used throughout the app
│   ├── (shareLayout)     //layouts specifically shared across token-specific sessions
│   ├── activate          //activate page
│   ├── components        //shared by pages and layouts
│   ├── install           //install page
│   ├── signin            //signin page
│   └── styles            //globally shared styles
├── assets                // Static assets
├── bin                   //scripts ran at build step
├── config                //adjustable settings and options
├── context               //shared contexts used by different portions of the app
├── dictionaries          // Language-specific translate files
├── docker                //container configurations
├── hooks                 // Reusable hooks
├── i18n                  // Internationalization configuration
├── models                //describes data models & shapes of API responses
├── public                //meta assets like favicon
├── service               //specifies shapes of API actions
├── test
├── types                 //descriptions of function params and return values
└── utils                 // Shared utility functions
```

## [Direct link to heading](\#ti-jiao-ni-de-pr)    提交你的 PR

最后，是时候向我们的仓库提交一个拉取请求（PR）了。对于重要的功能，我们首先将它们合并到 `deploy/dev` 分支进行测试，然后再合并到 `main` 分支。如果你遇到合并冲突或者不知道如何提交拉取请求的问题，请查看 [GitHub 的拉取请求教程](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests)。

就是这样！一旦你的 PR 被合并，你将成为我们 [README](https://github.com/langgenius/dify/blob/main/README_CN.md) 中的贡献者。

## [Direct link to heading](\#huo-qu-bang-zhu)    获取帮助

如果你在贡献过程中遇到困难或者有任何问题，可以通过相关的 GitHub 问题提出你的疑问，或者加入我们的 [Discord](https://discord.gg/AhzKf7dNgk) 进行快速交流。

[Previous寻求支持](/zh-hans/community/support) [Next为 Dify 文档做出贡献](/zh-hans/community/docs-contribution)

Last updated 1 month agoAIアプリケーションを作成する過程で、開発者は絶えず変化するビジネスニーズと複雑な技術的課題に直面します。拡張能力を効果的に活用することで、アプリケーションの柔軟性と機能性を向上させるだけでなく、企業データのセキュリティとコンプライアンスも確保できます。

Difyは以下の2つの拡張方法を提供しています：

[API 拡張](/ja-jp/guides/extension/api-based-extension) [https://github.com/langgenius/dify-docs/blob/main/jp/guides/extension/code-based-extension/README.md](https://github.com/langgenius/dify-docs/blob/main/jp/guides/extension/code-based-extension/README.md)

[PreviousLangFuseを統合](/ja-jp/guides/monitoring/integrate-external-ops-tools/integrate-langfuse) [NextAPI 拡張](/ja-jp/guides/extension/api-based-extension)

Last updated 5 months ago

This site uses cookies to deliver its service and to analyse traffic. By browsing this site, you accept the [privacy policy](https://dify.ai/privacy).

AcceptReject![Page cover image](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252FN0jIpgrjihYi6ZgFKpk2%252F%2525E7%252594%2525BB%2525E6%25259D%2525BF_1.png%3Falt%3Dmedia%26token%3D26d1914e-2167-49da-922e-aba0f5503fb2&width=1248&dpr=4&quality=100&sign=77ba846b&sv=2)

## [Direct link to heading](\#introduction)    Introduction

In Dify, you can use some crawler tools, such as Jina, which can convert web pages into markdown format that LLMs can read.

Recently, [wordware.ai](https://www.wordware.ai/) has brought to our attention that we can use crawlers to scrape social media for LLM analysis, creating more interesting applications.

However, knowing that X (formerly Twitter) stopped providing free API access on February 2, 2023, and has since upgraded its anti-crawling measures. Tools like Jina are unable to access X's content directly.

> Starting February 9, we will no longer support free access to the Twitter API, both v2 and v1.1. A paid basic tier will be available instead 🧵
>
> — Developers (@XDevelopers) [February 2, 2023](https://twitter.com/XDevelopers/status/1621026986784337922?ref_src=twsrc%5Etfw)

Fortunately, Dify also has an HTTP tool, which allows us to call external crawling tools by sending HTTP requests. Let's get started!

## [Direct link to heading](\#prerequisites)    **Prerequisites**

### [Direct link to heading](\#register-crawlbase)    Register Crawlbase

Crawlbase is an all-in-one data crawling and scraping platform designed for businesses and developers.

Moreover, using Crawlbase Scraper allows you to scrape data from social platforms like X, Facebook and Instagram.

Click to register: [crawlbase.com](https://crawlbase.com)

### [Direct link to heading](\#deploy-dify-locally)    Deploy Dify locally

Dify is an open-source LLM app development platform. You can choose cloud service or deploy it locally using docker compose.

In this article, If you don’t want to deploy it locally, register a free Dify Cloud sandbox account here: [https://cloud.dify.ai/signin](https://cloud.dify.ai/signin).

Dify Cloud Sandbox users get 200 free credits, equivalent to 200 GPT-3.5 messages or 20 GPT-4 messages.

The following are brief tutorials on how to deploy Dify:

#### [Direct link to heading](\#clone-dify)    Clone Dify

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
git clone https://github.com/langgenius/dify.git
```

#### [Direct link to heading](\#start-dify)    **Start Dify**

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
cd dify/docker
cp .env.example .env
docker compose up -d
```

### [Direct link to heading](\#configure-llm-providers)    Configure LLM Providers

Configure Model Provider in account setting:

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252FHzo3umL8cPmJZsB8I1QW%252F%2525E6%252588%2525AA%2525E5%2525B1%25258F2024-09-03_08.51.29.png%3Falt%3Dmedia%26token%3D16fad141-b64d-4f1d-9134-8a4b3c9f7306&width=768&dpr=4&quality=100&sign=46282112&sv=2)

## [Direct link to heading](\#create-a-chatflow)    Create a chatflow

Now, let's get started on the chatflow.

Click on `Create from Blank` to start:

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252FgmH0SroJ5lGqoS4OTFtJ%252F%2525E6%252588%2525AA%2525E5%2525B1%25258F2024-09-02_20.37.09.png%3Falt%3Dmedia%26token%3D88f238d0-5ce7-40af-92d7-485ff3549f16&width=768&dpr=4&quality=100&sign=7cf9e8bd&sv=2)

The initialized chatflow should be like:

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fej70Uxlo1KZUKUW8Znhg%252F%2525E6%252588%2525AA%2525E5%2525B1%25258F2024-09-02_22.44.44.png%3Falt%3Dmedia%26token%3D0675f229-b0b3-44c5-8c43-fb8d68280d32&width=768&dpr=4&quality=100&sign=69bfb8e9&sv=2)

## [Direct link to heading](\#add-nodes-to-chatflow)    Add nodes to chatflow

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252FMnKAZJQAfxWUE8nQRWe2%252Fimage.png%3Falt%3Dmedia%26token%3D9c564284-9be4-4d2d-b063-8f0f8a5bc087&width=768&dpr=4&quality=100&sign=2329931&sv=2)

The final chatflow looks like this

### [Direct link to heading](\#start-node)    Start node

In start node, we can add some system variables at the beginning of a chat. In this article, we need a Twitter user’s ID as a string variable. Let’s name it `id` .

Click on Start node and add a new variable:

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fe6PLRI62Ix2Kx41szVve%252F%2525E6%252588%2525AA%2525E5%2525B1%25258F2024-09-03_08.42.10.png%3Falt%3Dmedia%26token%3D349577ce-b0ad-43a4-ab23-933895dd5716&width=768&dpr=4&quality=100&sign=a52d3a8c&sv=2)

### [Direct link to heading](\#code-node)    Code node

According to [Crawlbase docs](https://crawlbase.com/docs/crawling-api/scrapers/#twitter-profile), the variable `url` (this will be used in the following node) should be `https://twitter.com/` \+ `user id` , such as `https://twitter.com/elonmusk` for Elon Musk.

To convert the user ID into a complete URL, we can use the following Python code to integrate the prefix `https://twitter.com/` with the user ID:

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
def main(id: str) -> dict:
    return {
        "url": "https://twitter.com/"+id,
    }
```

Add a code node and select python, and set input and output variable names:

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252F61kUz6dfRv1mMWb843sY%252F7d5de1cce4426f70f448402d7812bd040d681c225e49a2de66b59cbde66ba834.png%3Falt%3Dmedia%26token%3D0ecc94c1-e9df-4d25-8451-7beae1a65f1f&width=768&dpr=4&quality=100&sign=2b883157&sv=2)

### [Direct link to heading](\#http-request-node)    HTTP request node

Based on the [Crawlbase docs](https://crawlbase.com/docs/crawling-api/scrapers/#twitter-profile), to scrape a Twitter user’s profile in http format, we need to complete HTTP request node in the following format:

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252F1izSEuAMsImXmhzUiCYl%252F%2525E6%252588%2525AA%2525E5%2525B1%25258F2024-09-02_19.43.21.png%3Falt%3Dmedia%26token%3Dd501d9d3-3961-46df-815f-7391ec8be851&width=768&dpr=4&quality=100&sign=7154d476&sv=2)

Importantly, it is best not to directly enter the token value as plain text for security reasons, as this is not a good practice. Actually, in the latest version of Dify, we can set token values in `Environment Variables`. Click `env` \- `Add Variable` to set the token value, so plain text will not appear in the node.

Check [https://crawlbase.com/dashboard/account/docs](https://crawlbase.com/dashboard/account/docs) for your crawlbase API Key.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252FsNvufbEik0JJnyywl1Oh%252F%2525E6%252588%2525AA%2525E5%2525B1%25258F2024-09-02_22.55.20.png%3Falt%3Dmedia%26token%3Df53c219b-d46e-41e6-b4a9-e8fe16854238&width=768&dpr=4&quality=100&sign=d7942dfa&sv=2)

By typing `/` , you can easily insert the API Key as a variable.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252FzIuXoBddQZiS86AoTL1B%252F%2525E6%252588%2525AA%2525E5%2525B1%25258F2024-09-02_23.02.04.png%3Falt%3Dmedia%26token%3Dc3de84a3-f64f-4c62-bad8-a7a6bf59a9c4&width=768&dpr=4&quality=100&sign=d7f2c41a&sv=2)

Tap the start button of this node to check whether it works correctly:

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252FatdSaaAT14XmJ6WZ9F0P%252FCleanShot%25202024-10-07%2520at%252021.44.50%25402x.png%3Falt%3Dmedia%26token%3D8b7568a2-83c5-4d0c-a267-fad9ab811060&width=768&dpr=4&quality=100&sign=ce373786&sv=2)

### [Direct link to heading](\#llm-node)    LLM node

Now, we can use LLM to analyze the result scraped by crawlbase and execute our command.

The value `context` should be `body` from HTTP Request node.

The following is a sample system prompt.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252FbOPBh4JKGI21gm7nbuvp%252F%2525E6%252588%2525AA%2525E5%2525B1%25258F2024-09-02_23.35.38.png%3Falt%3Dmedia%26token%3De57337a3-55a3-4fcf-9070-cc3ec93c1a4a&width=768&dpr=4&quality=100&sign=af6f5b2a&sv=2)

## [Direct link to heading](\#test-run)    Test run

Click `Preview` to start a test run and input twitter user id in `id`

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252FcVUZR0MdJ1SzCj4Y3LNJ%252F%2525E6%252588%2525AA%2525E5%2525B1%25258F2024-09-02_23.41.03.png%3Falt%3Dmedia%26token%3Daff0cec4-285e-4b70-8d1a-0a35feae5518&width=768&dpr=4&quality=100&sign=31e0da9a&sv=2)

For example, I want to analyze Elon Musk's tweets and write a tweet about global warming in his tone.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252F0tAXQM4m2ZCMdfDF6SWl%252F%2525E6%252588%2525AA%2525E5%2525B1%25258F2024-09-02_23.47.20.png%3Falt%3Dmedia%26token%3Dc7e7c7c9-66a6-4954-a5ee-bcbabf43a17d&width=768&dpr=4&quality=100&sign=f27eba7e&sv=2)

Does this sound like Elon? lol

Click `Publish` in the upper right corner and add it in your website.

Have fun!

## [Direct link to heading](\#lastly)    Lastly…

### [Direct link to heading](\#other-x-twitter-crawlers)    Other X(Twitter) Crawlers

In this article, I’ve introduced crawlbase. It should be the cheapest Twitter crawler service available, but sometimes it cannot correctly scrape the content of user tweets.

The Twitter crawler service used by [wordware.ai](http://wordware.ai) mentioned earlier is **Tweet Scraper V2**, but the subscription for the hosted platform **apify** is $49 per month.

## [Direct link to heading](\#links)    Links

- [X@dify\_ai](https://x.com/dify_ai)

- Dify’s repo on GitHub: [https://github.com/langgenius/dify](https://github.com/langgenius/dify)


[PreviousBuilding a Smart Customer Service Bot Using a Knowledge Base](/workshop/intermediate/customer-service-bot) [NextSeek Support](/community/support)

Last updated 3 months agoThe knowledge base supports crawling content from public web pages using third-party tools such as [Jina Reader](https://jina.ai/reader/) and [Firecrawl](https://www.firecrawl.dev/), parsing it into Markdown content, and importing it into the knowledge base.

​ [Firecrawl](https://www.firecrawl.dev/) and [Jina Reader](https://jina.ai/reader/) are both open-source web parsing tools that can convert web pages into clean Markdown format text that is easy for LLMs to recognize, while providing easy-to-use API services.

The following sections will introduce the usage methods for Firecrawl and Jina Reader respectively.

### [Direct link to heading](\#how-to-configure)    Firecrawl

#### [Direct link to heading](\#id-1.-configure-firecrawl-api-credentials)    **1\. Configure Firecrawl API credentials**

Click on the avatar in the upper right corner, then go to the **DataSource** page, and click the **Configure** button next to Firecrawl.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2Fd468cf996f591b4b2bd0ffb5de62bad4.png&width=768&dpr=4&quality=100&sign=22af78&sv=2)

Configuring Firecrawl credentials

Log in to the [Firecrawl website](https://www.firecrawl.dev/) to complete registration, get your API Key, and then enter and save it in Dify.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Ffiles.gitbook.com%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252FtAwcLoAYT1A2v12pfJC3%252Fimage.png%3Falt%3Dmedia%26token%3D3b5b784f-2808-431f-8595-2638d038c190&width=768&dpr=4&quality=100&sign=ffcbad4f&sv=2)

Get the API Key and save it in Dify

#### [Direct link to heading](\#id-2.-scrape-target-webpage)    2\. Scrape target webpage

On the knowledge base creation page, select **Sync from website**, choose Firecrawl as the provider, and enter the target URL to be crawled.

The configuration options include: Whether to crawl sub-pages, Page crawling limit, Page scraping max depth, Excluded paths, Include only paths, and Content extraction scope. After completing the configuration, click **Run** to preview the parsed pages.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2F3e63b4ced9770e21d5132c3aa8e5d2de.png&width=768&dpr=4&quality=100&sign=adc4a355&sv=2)

Execute scraping

#### [Direct link to heading](\#id-3.-review-import-results)    3\. Review import results

After importing the parsed text from the webpage, it is stored in the knowledge base documents. View the import results and click **Add URL** to continue importing new web pages.

* * *

### [Direct link to heading](\#jina-reader)    Jina Reader

#### [Direct link to heading](\#id-1.-configuring-jina-reader-credentials)    1\. Configuring Jina Reader Credentials

Click on the avatar in the upper right corner, then go to the **DataSource** page, and click the **Configure** button next to Jina Reader.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2F28b37f9b36fe808b2d3302c48fce5ea3.png&width=768&dpr=4&quality=100&sign=4a3fdf79&sv=2)

Configuring Jina Reader

Log in to the [Jina Reader website](https://jina.ai/reader/), complete registration, obtain the API Key, then fill it in and save.

#### [Direct link to heading](\#id-2.-using-jina-reader-to-crawl-web-content)    2\. Using Jina Reader to Crawl Web Content

On the knowledge base creation page, select **Sync from website**, choose Jina Reader as the provider, and enter the target URL to be crawled.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2Ff9170b2a2ab1be94bc85ff3ed3c3e723.png&width=768&dpr=4&quality=100&sign=66ebaef3&sv=2)

Web crawling configuration

Configuration options include: whether to crawl subpages, maximum number of pages to crawl, and whether to use sitemap for crawling. After completing the configuration, click the **Run** button to preview the page links to be crawled.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2Fa875f21a751551c03109c76308c577ee.png&width=768&dpr=4&quality=100&sign=3a6eb097&sv=2)

Executing the crawl process

After importing the parsed text from web pages into the knowledge base, you can review the imported results in the documents section. To add more web pages, click the **Add URL** button on the right to continue importing new pages.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2F03494dc3c882ac1c74b464ea931e2533.png&width=768&dpr=4&quality=100&sign=523c6950&sv=2)

Importing parsed web text into the knowledge base

After crawling is complete, the content from the web pages will be incorporated into the knowledge base.

[Previous1.1 Import Data from Notion](/guides/knowledge-base/create-knowledge-and-upload-documents/1.-import-text-data/1.1-import-data-from-notion) [Next2\. Choose a Chunk Mode](/guides/knowledge-base/create-knowledge-and-upload-documents/2.-choose-a-chunk-mode)

Last updated 6 days ago### [Direct link to heading](\#editing-application-information)    Editing Application Information

After creating an application, if you want to modify the application name or description, you can click "Edit info" in the upper left corner of the application to revise the application's icon, name, or description.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252FvlhblaCxbtgHzU3FLKFu%252Fimage.png%3Falt%3Dmedia%26token%3D50df3dc3-d1a5-4a24-9ad8-e01d38f233e6&width=768&dpr=4&quality=100&sign=f7177067&sv=2)

Edit App Info

### [Direct link to heading](\#duplicating-application)    Duplicating Application

All applications support copying. Click "Duplicate" in the upper left corner of the application.

### [Direct link to heading](\#exporting-application)    Exporting Application

Applications created in Dify support export in DSL format files, allowing you to import the configuration files into other Dify teams freely. You can export DSL files using either of the following two methods:

- Click "Export DSL" in the application menu button on the "Studio" page

- After entering the application's orchestration page, click "Export DSL" in the upper left corner


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-0e8339986edc971da9f9e2501bdc90d7d7443272%252Fexport-dsl.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=bae744ce&sv=2)

The DSL file does not include authorization information already filled in [Tool](/guides/workflow/node/tools) nodes, such as API keys for third-party services.

If the environment variables contain variables of the `Secret` type, a prompt will appear during file export asking whether to allow the export of this sensitive information.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-1d249e2794cad92e87dda55f01093b493b45ff82%252Fexport-dsl-secret.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=95d85074&sv=2)

Dify DSL is an AI application engineering file standard defined by Dify.AI in v0.6 and later. The file format is YML. This standard covers the basic description of the application, model parameters, orchestration configuration, and other information.

### [Direct link to heading](\#importing-application)    Importing Application

To import a Dify application, upload the DSL file to the Dify platform. A version check will be conducted during the import process, and a warning will be issued if a lower version of the DSL file is detected.

- For SaaS users, the DSL file exported from the SaaS platform will always be the latest version.

- For Community users, it is recommended to consult [Upgrade Dify](https://docs.dify.ai/getting-started/install-self-hosted/docker-compose#upgrade-dify) to update the Community Edition and export an updated version of the DSL file, thus avoiding potential compatibility issues.


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F11%2F487d2c1cc8b86666feb35ea8a346c053.png&width=768&dpr=4&quality=100&sign=35add027&sv=2)

### [Direct link to heading](\#deleting-application)    Deleting Application

If you want to remove an application, you can click "Delete" in the upper left corner of the application.

⚠️ The deletion of an application cannot be undone. All users will be unable to access your application, and all prompts, orchestration configurations, and logs within the application will be deleted.

[PreviousManagement](/guides/management) [NextTeam Members Management](/guides/management/team-members-management)

Last updated 1 month agoYou can monitor and track the performance of your application in a production environment within the **Overview** section. In the data analytics dashboard, you can analyze various metrics such as usage costs, latency, user feedback, and performance in the production environment. By continuously debugging and iterating, you can continually improve your application.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-c80136ea4aa809fcffcd6e9667b83f04ad6e42c9%252Fmonitoring-app.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=6c63a57c&sv=2)

概览

[PreviousAnnotation Reply](/guides/annotation/annotation-reply) [NextData Analysis](/guides/monitoring/analysis)

Last updated 5 months ago### [Direct link to heading](\#ji-ben-jie-shao)    基本介绍

工作流通过将复杂的任务分解成较小的步骤（节点）降低系统复杂度，减少了对提示词技术和模型推理能力的依赖，提高了 LLM 应用面向复杂任务的性能，提升了系统的可解释性、稳定性和容错性。

Dify 工作流分为两种类型：

- **Chatflow**：面向对话类情景，包括客户服务、语义搜索、以及其他需要在构建响应时进行多步逻辑的对话式应用程序。

- **Workflow**：面向自动化和批处理情景，适合高质量翻译、数据分析、内容生成、电子邮件自动化等应用程序。


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F1288284732-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FCdDIVDY6AtAz028MFT4d%252Fuploads%252FvdBlcbguy4O2jYQQdYH1%252Fimage.png%3Falt%3Dmedia%26token%3D4450ffa8-5c2c-476b-a3b9-7e424d2c0e35&width=768&dpr=4&quality=100&sign=f669664b&sv=2)

为解决自然语言输入中用户意图识别的复杂性，Chatflow 提供了问题理解类节点。相对于 Workflow 增加了 Chatbot 特性的支持，如：对话历史（Memory）、标注回复、Answer 节点等。

为解决自动化和批处理情景中复杂业务逻辑，工作流提供了丰富的逻辑节点，如代码节点、IF/ELSE 节点、模板转换、迭代节点等，除此之外也将提供定时和事件触发的能力，方便构建自动化流程。

### [Direct link to heading](\#chang-jian-an-li)    常见案例

- 客户服务


通过将 LLM 集成到你的客户服务系统中，你可以自动化回答常见问题，减轻支持团队的工作负担。 LLM 可以理解客户查询的上下文和意图，并实时生成有帮助且准确的回答。

- 内容生成


无论你需要创建博客文章、产品描述还是营销材料，LLM 都可以通过生成高质量内容来帮助你。只需提供一个大纲或主题，LLM将利用其广泛的知识库来制作引人入胜、信息丰富且结构良好的内容。

- 任务自动化


可以与各种任务管理系统集成，如 Trello、Slack、Lark、以自动化项目和任务管理。通过使用自然语言处理，LLM 可以理解和解释用户输入，创建任务，更新状态和分配优先级，无需手动干预。

- 数据分析和报告


可以用于分析大型知识库并生成报告或摘要。通过提供相关信息给 LLM，它可以识别趋势、模式和洞察力，将原始数据转化为可操作的智能。对于希望做出数据驱动决策的企业来说，这尤其有价值。

- 邮件自动化处理


LLM 可以用于起草电子邮件、社交媒体更新和其他形式的沟通。通过提供简要的大纲或关键要点，LLM 可以生成一个结构良好、连贯且与上下文相关的信息。这样可以节省大量时间，并确保你的回复清晰和专业。

### [Direct link to heading](\#ru-he-kai-shi)    如何开始

- 从一个空白的工作流开始构建或者使用系统模版帮助你开始；

- 熟悉基础操作，包括在画布上创建节点、连接和配置节点、调试工作流、查看运行历史等；

- 保存并发布一个工作流；

- 在已发布应用中运行或者通过 API 调用工作流；


[Previous敏感内容审查](/zh-hans/guides/application-orchestrate/app-toolkits/moderation-tool) [Next关键概念](/zh-hans/guides/workflow/key-concept)

Last updated 1 month ago

This site uses cookies to deliver its service and to analyse traffic. By browsing this site, you accept the [privacy policy](https://dify.ai/privacy).

AcceptRejectThe **Overview -- Data Analysis** section displays metrics such as usage, active users, and LLM (Language Learning Model) invocation costs. This allows you to continuously improve the effectiveness, engagement, and cost-efficiency of your application operations. We will gradually provide more useful visualization capabilities, so please let us know what you need.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-0f936e5c956dd6ded1f4bfa53ff2a7ca557092d8%252Foverview-data-analysis.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=5a64af73&sv=2)

Overview—Data Analysis

* * *

**Total Messages**

Reflects the total number of daily interactions between users and AI. Each time the AI answers a user's question, it counts as one message. Prompt orchestration and debugging sessions are not included.

**Active Users**

The number of unique users who have had effective interactions with the AI, defined as having more than one question-and-answer exchange. Prompt orchestration and debugging sessions are not included.

**Average Session Interactions**

Reflects the number of continuous interactions per session user. For example, if a user has a 10-round Q&A with the AI, it is counted as 10. This metric reflects user engagement. It is available only for conversational applications.

**Token Output Speed**

The number of tokens output per second, indirectly reflecting the model's generation rate and the application's usage frequency.

**User Satisfaction Rate**

The number of likes per 1,000 messages, reflecting the proportion of users who are very satisfied with the answers.

**Token Usage**

Reflects the daily token expenditure for language model requests by the application, useful for cost control.

**Total Conversations**

Daily AI conversation count; each new conversation session counts as one. A single conversation session may contain multiple message exchanges; messages related to prompt engineering and debugging are not included.

[PreviousMonitoring](/guides/monitoring) [NextIntegrate External Ops Tools](/guides/monitoring/integrate-external-ops-tools)

Last updated 4 months ago## [Direct link to heading](\#template-applications)    Template Applications

In the **Discover** section, several commonly used template applications are provided. These applications cover areas such as human resources, assistants, translation, programming, and writing.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-21b025e8456e10d090e0ceb221701d3caf493def%252Fexplore-apps-by-dify.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=30950250&sv=2)

To use a template application, click the "Add to Workspace" button on the template. You can then use the application in the workspace on the left side.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-23f495506d4ded0136c4ece8acbb976231d83cd3%252Fcreate-app.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=e1b30ffa&sv=2)

To modify a template and create a new application, click the "Customize" button on the template.

## [Direct link to heading](\#workspace)    Workspace

The workspace serves as the navigation for applications. Click on an application within the workspace to use it directly.

Applications in the workspace include your own applications as well as those added to the workspace by other team members.

[PreviousCollaboration](/guides/workspace) [NextInvite and Manage Members](/guides/workspace/invite-and-manage-members)

Last updated 5 months agoThe image upload feature has been integrated into the more comprehensive [File Upload](/guides/workflow/file-upload) functionality. To avoid redundant features, we have decided to upgrade and adjust the “ [Features](/guides/workflow/additional-features)” for Workflow and Chatflow applications as follows:

- The image upload option in Chatflow’s “Features” has been removed and replaced by the new “File Upload” feature. Within the “File Upload” feature, you can select the image file type. Additionally, the image upload icon in the application dialog has been replaced with a file upload icon.


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252F6WJvzWQzc3PLlW1XFvi4%252Fimage.png%3Falt%3Dmedia%26token%3Dbe87eed6-32eb-4211-a77c-0e864aa00d92&width=768&dpr=4&quality=100&sign=abfaa424&sv=2)

- The image upload option in Workflow’s “Features” and the `sys.files` [variable](/guides/workflow/variables) will be deprecated in the future. Both have been marked as `LEGACY`, and developers are encouraged to use custom file variables to add file upload functionality to Workflow applications.


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252FL27fBYsZksssPSJvQPKv%252Fimage.png%3Falt%3Dmedia%26token%3Dcc03e186-aad7-4ec0-9ee6-d2fa466b225f&width=768&dpr=4&quality=100&sign=d1620e45&sv=2)

### [Direct link to heading](\#why-replace-the-image-upload-feature)    Why Replace the “Image Upload” Feature?

Previously, Dify only supported image file uploads. In the latest version, a more comprehensive file upload capability has been introduced, supporting documents, images, audio, video, and custom file formats.

**Image uploading is now part of the broader “File Upload” feature.** When adding the file upload feature, developers can simply check the “image” file type to enable image uploads.

To avoid confusion caused by redundant features, we have decided to replace the standalone image upload feature in Chatflow applications with the more comprehensive file upload capability, and no longer recommend enabling image upload for Workflow applications.

### [Direct link to heading](\#more-comprehensive-functionality-file-upload)    More Comprehensive Functionality: File Upload

To enhance the information processing capabilities of your applications, we have introduced the “File Upload” feature in this update. Unlike chat text, document files can carry a large amount of information, such as academic reports or legal contracts.

- The file upload feature allows files to be uploaded, parsed, referenced, and downloaded as file variables within Workflow applications.

- Developers can now easily build applications capable of understanding and processing complex tasks involving images, audio, and video.


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252FsapA8iNlShdIikvTvuCH%252Fimage.png%3Falt%3Dmedia%26token%3D5940cce2-8948-4d4c-8620-1fb6676a5ed8&width=768&dpr=4&quality=100&sign=413d95e&sv=2)

We no longer recommend using the standalone “Image Upload” feature and instead suggest transitioning to the more comprehensive “File Upload” feature to improve the application experience.

### [Direct link to heading](\#what-you-need-to-do)    What You Need to Do?

#### [Direct link to heading](\#for-dify-cloud-users)    For Dify Cloud Users:

- **Chatflow Applications**


If you have already created Chatflow applications with the “Image Upload” feature enabled and activated the Vision feature in the LLM node, the system will automatically switch the feature, and it will not affect the application’s image upload capability. If you need to update and republish the application, select the file variable in the Vision variable selection box of the LLM node, clear the item from the checklist, and republish the application.\

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252FAamJSCS29SCEfSZ3F2td%252Fimage.png%3Falt%3Dmedia%26token%3D0cd8c9ec-c826-4418-889f-6ef4616444ef&width=768&dpr=4&quality=100&sign=8691af35&sv=2)

If you wish to add the “Image Upload” feature to a Chatflow application, enable “File Upload” in the features and select only the “image” file type. Then enable the Vision feature in the LLM node and specify the sys.files variable. The upload entry will appear as a “paperclip” icon. For detailed instructions, refer to [Additional Features](/guides/workflow/additional-features).

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252F8kJGC9EG5SaPAN7q73Ha%252Fimage.png%3Falt%3Dmedia%26token%3De9c7e51b-89ba-4c2d-bf7d-607316a5eae0&width=768&dpr=4&quality=100&sign=9d0fc5fc&sv=2)

- **Workflow Applications**


If you have already created Workflow applications with the “Image Upload” feature enabled and activated the Vision feature in the LLM node, this change will not affect you immediately, but you will need to complete manual migration before the official deprecation.

If you wish to enable the “Image Upload” feature for a Workflow application, add a file variable in the [Start](/guides/workflow/node/start) node. Then, reference this file variable in subsequent nodes instead of using the `sys.files` variable.

#### [Direct link to heading](\#for-dify-community-edition-or-self-hosted-enterprise-users)    For Dify Community Edition or Self-hosted Enterprise Users:

After upgrading to version v0.10.0, you will see the “File Upload” feature.

- Chatflow Applications:


Chatflow applications with the “Image Upload” feature enabled will automatically switch to the file upload feature, with no changes required.

If you wish to add the “Image Upload” feature to a Chatflow application, refer to the Additional Features section for detailed instructions.

- Workflow Applications:


Existing Workflow applications will not be affected, but please complete the manual migration before the official deprecation.

If you wish to enable the “Image Upload” feature for a Workflow application, add a file variable in the [Start](/guides/workflow/node/start) node. Then, reference this file variable in subsequent nodes instead of using the `sys.files` variable.\

### [Direct link to heading](\#faqs)    FAQs:

#### [Direct link to heading](\#id-1.-will-this-update-affect-my-existing-applications)    1\. Will This Update Affect My Existing Applications?

- Existing Chatflow applications will automatically migrate, seamlessly switching image upload capabilities to the file upload feature. The `sys.files` variable will still be used as the default Vision input. The image upload entry in the application interface will be replaced with a file upload entry.

- Existing Workflow applications will not be affected for now. The `sys.files` variable and the image upload feature have been marked as `LEGACY`, but they can still be used. However, these `LEGACY` features will be deprecated in the future, and a manual update will be required at that time.


#### [Direct link to heading](\#id-2.-do-i-need-to-update-my-applications-immediately)    2\. Do I Need to Update My Applications Immediately?

- For Chatflow applications, the system will automatically migrate, and no manual updates are required.

- For Workflow applications, although an immediate update is not necessary, we recommend familiarizing yourself with the new file upload feature to prepare for future migration.


#### [Direct link to heading](\#id-3.-how-can-i-ensure-my-applications-are-compatible-with-the-new-file-upload-feature)    3\. How Can I Ensure My Applications Are Compatible with the New File Upload Feature?

For Chatflow applications:

• Check if the file upload option is enabled in the features configuration.

• Ensure you’re using an LLM with Vision capabilities, and turn on the Vision toggle.

• Verify that `sys.files` is correctly selected as the input item in the Vision box.

For Workflow applications:

• Create a file-type variable in the “Start” node.

• Reference this file variable in subsequent nodes instead of using the LEGACY `sys.files` variable.

#### [Direct link to heading](\#id-4.-how-to-handle-missing-image-upload-icons-in-previously-published-chatflow-applications)    4\. How to handle missing image upload icons in previously published Chatflow applications?

It is recommended to republish the application, and the file upload icon will appear in the application's chat box.

#### [Direct link to heading](\#we-value-your-feedback)    We Value Your Feedback

As a key member of the Dify community, your experience and feedback are crucial to us. We warmly invite you to:

1. Try the file upload feature and experience its convenience and flexibility.

2. Share your thoughts and suggestions via the following channels:



• [GitHub](https://github.com/langgenius/dify)



• [Discord channel](https://discord.com/invite/FngNHpbcY7)


Your feedback will help us continuously improve the product and provide a better experience for the entire community.

[PreviousApplication Publishing](/guides/workflow/publish) [NextKnowledge](/guides/knowledge-base)

Last updated 2 months ago

This site uses cookies to deliver its service and to analyse traffic. By browsing this site, you accept the [privacy policy](https://dify.ai/privacy).

AcceptRejectWith [OpenLLM](https://github.com/bentoml/OpenLLM), you can run inference with any open-source large-language models, deploy to the cloud or on-premises, and build powerful AI apps. And Dify supports connecting to OpenLLM deployed large language model's inference capabilities locally.

## [Direct link to heading](\#deploy-openllm-model)    Deploy OpenLLM Model

### [Direct link to heading](\#starting-openllm)    Starting OpenLLM

Each OpenLLM Server can deploy one model, and you can deploy it in the following way:

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
docker run --rm -it -p 3333:3000 ghcr.io/bentoml/openllm start facebook/opt-1.3b --backend pt
```

> Note: Using the `facebook/opt-1.3b` model here is only for demonstration, and the effect may not be good. Please choose the appropriate model according to the actual situation. For more models, please refer to: [Supported Model List](https://github.com/bentoml/OpenLLM#-supported-models).

After the model is deployed, use the connected model in Dify.

Fill in under `Settings > Model Providers > OpenLLM`:

- Model Name: `facebook/opt-1.3b`

- Server URL: `http://<Machine_IP>:3333` Replace with your machine IP address


Click "Save" and the model can be used in the application.

This instruction is only for quick connection as an example. For more features and information on using OpenLLM, please refer to: [OpenLLM](https://github.com/bentoml/OpenLLM)

[PreviousIntegrate Local Models Deployed by Xinference](/development/models-integration/xinference) [NextIntegrate Local Models Deployed by LocalAI](/development/models-integration/localai)

Last updated 3 months agoWorkflow applications often comprise multiple interconnected nodes operating in sequence. When an error occurs—such as an API request failure, an LLM output issue, or an unexpected exception—it can disrupt the entire process. Such disruptions force developers to spend significant time troubleshooting, especially in workflows with complex node dependencies.

**Error handling** introduces robust strategies to manage node failures effectively. These feature allow workflows to log and monitor errors without halting execution or switch seamlessly to predefined fallback paths, ensuring task continuity. **Developers can significantly improve application reliability and operational resilience by integrating strong error-handling feature into critical nodes.**

Developers no longer need to handle potential node errors by embedding complex logic within nodes or adding extra nodes. The error-handling feature simplifies workflow design, enabling streamlined execution through various predefined strategies.

![](https://www.gitbook.com/cdn-cgi/image/width=256,format=auto/https%3A%2F%2Ffiles.gitbook.com%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fintegrations%252Farcade%252Ficon%252F7TEQUDaaKQX5t9WlliuF%252Ficon.png%3Falt%3Dmedia)

Arcade

### [Direct link to heading](\#application-scenarios)    Application Scenarios

#### [Direct link to heading](\#id-1.-handling-network-exceptions)    1\. Handling Network Exceptions

**Example**: In a workflow that retrieves and aggregates data from three API services (such as weather services, news summaries, and social media analysis), one service might fail to respond due to request limits, causing data retrieval to fail. With the error-handling function, the main process can continue using the data from the other two successful services while logging the failed API request. This log helps developers analyze the issue later and refine their service call strategies.

#### [Direct link to heading](\#id-2.-backup-workflow-design)    2\. Backup Workflow Design

**Example**: An LLM node tasked with generating detailed document summaries may encounter token limit errors when processing lengthy input. The workflow can switch to a backup path by setting the "Fail branch" on Error-handling Feature.

For instance, a code node on the alternative path can split the content into smaller chunks and re-invoke the LLM node, preventing the workflow from breaking down.

#### [Direct link to heading](\#id-3.-predefined-error-messages)    3\. Predefined Error Messages

**Example**: When running a workflow, you might occasionally encounter a node returning vague error messages (such as a simple "request failed"), complicating pinpointing the issue quickly. Developers can write predefined error messages within the error handling feature to provide more explicit and more precise error information for subsequent application debugging.

### [Direct link to heading](\#error-handling-feature)    Error Handling Feature

The following four types of nodes have added error-handling feature. Click on the title to read the detailed documents:

- [LLM](/guides/workflow/node/llm)

- [HTTP](/guides/workflow/node/http-request)

- [Code](/guides/workflow/node/code)

- [Tools](/guides/workflow/node/tools)


**Retry on Failure**

Some exceptions can be resolved by retrying the node. In this case, you can enable the **Retry on Failure** feature in the node and set the number of max retries and the retry interval.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2F18097e4c94b67a79150b967fc50f9f43.png&width=768&dpr=4&quality=100&sign=5bbe2be9&sv=2)

If an error is still reported after retrying the node, the next process will be run according to the predefined strategy in the Error Handling feature.

**Error Handling**

The error handling feature provides the following three options:

• **None**: Do not handle the exception, directly throw the node's error message and interrupt the entire process.

• **Default Value**: Allows developers to predefine exception messages. After an exception occurs, use the predefined value to replace the original built-in error output message of the node.

• **Fail Branch**: Execute the pre-arranged fail branch after an exception occurs.

For explanations and configuration methods of each strategy, please refer to the [predefined error handling logic](/guides/workflow/error-handling/predefined-error-handling-logic).

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2F3c198be3a7b9c1f9649bbd8b9a0a9ec5.png&width=768&dpr=4&quality=100&sign=2d893389&sv=2)

Error handling

### [Direct link to heading](\#quick-start)    Quick Start

Scenario: Enabling Error-handling feature for Workflow Application

Error Handling feature for Code Output in Workflow Applications The following example demonstrates how to implement error handling feature within a workflow application, using fail branch to handle node exceptions.

The idea of the workflow design: An LLM node generates JSON code content (either correctly or incorrectly formatted) based on user's input instructions, which is then executed and output through Code Node A.

If Code Node A receives incorrectly formatted JSON content, it follows the predefined error handling design, executing the backup path while continuing the main process.

1. **Creating a JSON Code Generation Node**


Create a new Workflow application and add both LLM and Code nodes. Use a Prompt to instruct the LLM to generate either correctly or incorrectly formatted JSON content, which will then be validated through Code Node A.

**The Prompt reference of LLM node:**

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
You are a teaching assistant. According to the user's requirements, you only output a correct or incorrect sample code in json format.
```

**The JSON verification of Code Node：**

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
def main(json_str: str) -> dict:
    obj = json.loads(json_str)
    return {'result': obj}
```

1. **Enable Error Handling Feature for Node A**


Node A is responsible for validating JSON content. If it receives incorrectly formatted JSON content, the error handling feature will be triggered and execute th backup path, allowing the subsequent LLM node to fix the incorrect content and revalidate the JSON, thereby continuing the main process.

In the "Error Handling" tab of Node A, select "Fail Branch" and create a new LLM node.

![](https://www.gitbook.com/cdn-cgi/image/width=256,format=auto/https%3A%2F%2Ffiles.gitbook.com%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fintegrations%252Farcade%252Ficon%252F7TEQUDaaKQX5t9WlliuF%252Ficon.png%3Falt%3Dmedia)

Arcade

1. **Correct the Error Output from Node A**


In the new LLM node, fill in the prompt and reference the exception output from Node A using variables for correction. Add Node B to revalidate the JSON content.

**4\. End**

Add a variable aggregation node to consolidate the results from both the correct and error branches and output them to the end node, completing the entire process.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2F059b5a814514cd9abe10f1f4077ed17f.png&width=768&dpr=4&quality=100&sign=98b36ab7&sv=2)

> Click [here](https://assets-docs.dify.ai/2024/12/087861aa20e06bb4f8a2bef7e7ae0522.yml) to download the Demo DSL file.

### [Direct link to heading](\#status-overview)    Status Overview

In workflow applications, understanding both node and workflow status is crucial for effective monitoring and troubleshooting. Let's explore how status indicators help developers track execution progress and handle exceptions efficiently.

#### [Direct link to heading](\#node-status-types)    Node Status Types

- **Success**: Every node runs properly - the node completes its task and produces the expected output.

- **Failure**: When error handling isn't enabled, the node stops working and reports an error.

- **Exception**: Even though an error occurs, the node doesn't completely fail because error handling (either default values or alternative paths) kicks in to manage the situation.


#### [Direct link to heading](\#workflow-status-types)    Workflow Status Types

- **Success**: A perfect run - all nodes complete their tasks successfully, and the workflow produces the intended output.

- **Failure**: The workflow stops completely due to an unhandled node error.

- **Partial Success**: Think of this as a "managed failure" - while some nodes encounter issues, error handling mechanisms keep the workflow moving forward to completion.


### [Direct link to heading](\#faq)    FAQ

1. **What is the difference before and after enabling the exception handling mechanism?**


#### [Direct link to heading](\#before-implementation)    Before Implementation

Without error handling, workflows are quite fragile:

- A single node failure (like an LLM timeout or network hiccup) brings everything to a halt

- Developers must manually investigate and fix issues before restarting

- Creating workarounds means building complex, redundant safety nets

- Error messages tend to be vague and unhelpful


#### [Direct link to heading](\#after-implementation)    After Implementation

Error handling transforms your workflow into a more resilient system:

- Workflows keep running even when things go wrong

- Developers can create custom responses for different types of errors

- The overall design becomes cleaner and more maintainable

- Detailed error logging makes troubleshooting much faster


* * *

1. **How to debug the execution of backup paths?**


Need to check if your error handling is working? It's simple - just look for yellow-highlighted paths in your workflow logs. These visual indicators show exactly when and where your backup error handling routes are being used.

[PreviousFile Upload](/guides/workflow/file-upload) [NextPredefined Error Handling Logic](/guides/workflow/error-handling/predefined-error-handling-logic)

Last updated 15 days ago[应用管理](/zh-hans/guides/management/app-management) [团队成员管理](/zh-hans/guides/management/team-members-management) [个人账号管理](/zh-hans/guides/management/personal-account-management) [订阅管理](/zh-hans/guides/management/subscription-management)

[Previous邀请与管理成员](/zh-hans/guides/workspace/invite-and-manage-members) [Next应用管理](/zh-hans/guides/management/app-management)

This site uses cookies to deliver its service and to analyse traffic. By browsing this site, you accept the [privacy policy](https://dify.ai/privacy).

AcceptReject**Dify** 是一款开源的大语言模型(LLM) 应用开发平台。它融合了后端即服务（Backend as Service）和 [LLMOps](/zh-hans/learn-more/extended-reading/what-is-llmops) 的理念，使开发者可以快速搭建生产级的生成式 AI 应用。即使你是非技术人员，也能参与到 AI 应用的定义和数据运营过程中。

由于 Dify 内置了构建 LLM 应用所需的关键技术栈，包括对数百个模型的支持、直观的 Prompt 编排界面、高质量的 RAG 引擎、稳健的 Agent 框架、灵活的流程编排，并同时提供了一套易用的界面和 API。这为开发者节省了许多重复造轮子的时间，使其可以专注在创新和业务需求上。

### [Direct link to heading](\#wei-shen-me-shi-yong-dify)    为什么使用 Dify？

你或许可以把 LangChain 这类的开发库（Library）想象为有着锤子、钉子的工具箱。与之相比，Dify 提供了更接近生产需要的完整方案，Dify 好比是一套脚手架，并且经过了精良的工程设计和软件测试。

重要的是，Dify 是 **开源** 的，它由一个专业的全职团队和社区共同打造。你可以基于任何模型自部署类似 Assistants API 和 GPTs 的能力，在灵活和安全的基础上，同时保持对数据的完全控制。

> 我们的社区用户对 Dify 的产品评价可以归结为简单、克制、迭代迅速。
> ——路宇，Dify.AI CEO

希望以上信息和这份指南可以帮助你了解这款产品，我们相信 Dify 是为你而做的（Do It For You）。

### [Direct link to heading](\#dify-neng-zuo-shen-me)    Dify 能做什么？

Dify 一词源自 Define + Modify，意指定义并且持续的改进你的 AI 应用，它是为你而做的（Do it for you）。

- **创业**，快速的将你的 AI 应用创意变成现实，无论成功和失败都需要加速。在真实世界，已经有几十个团队通过 Dify 构建 MVP（最小可用产品）获得投资，或通过 POC（概念验证）赢得了客户的订单。

- **将 LLM 集成至已有业务**，通过引入 LLM 增强现有应用的能力，接入 Dify 的 RESTful API 从而实现 Prompt 与业务代码的解耦，在 Dify 的管理界面是跟踪数据、成本和用量，持续改进应用效果。

- **作为企业级 LLM 基础设施**，一些银行和大型互联网公司正在将 Dify 部署为企业内的 LLM 网关，加速 GenAI 技术在企业内的推广，并实现中心化的监管。

- **探索 LLM 的能力边界**，即使你是一个技术爱好者，通过 Dify 也可以轻松的实践 Prompt 工程和 Agent 技术，在 GPTs 推出以前就已经有超过 60,000 开发者在 Dify 上创建了自己的第一个应用。


### [Direct link to heading](\#xia-yi-bu-xing-dong)    下一步行动

- 阅读 [**快速开始**](/zh-hans/guides/application-orchestrate/creating-an-application)，速览 Dify 的应用构建流程

- 了解如何 [**自部署 Dify 到服务器**](/zh-hans/getting-started/install-self-hosted) 上，并 [**接入开源模型**](/zh-hans/guides/model-configuration)

- 了解 Dify 的 [**特性规格**](/zh-hans/getting-started/readme/features-and-specifications) 和 **Roadmap**

- 在 [**GitHub**](https://github.com/langgenius/dify) 上为我们点亮一颗星，并阅读我们的 **贡献指南**


[Next特性与技术规格](/zh-hans/getting-started/readme/features-and-specifications)

Last updated 4 months ago欢迎来到 Dify 动手实验室！本教程专为那些想要从零开始学习 Dify 的初学者设计。无论你是否有编程或 AI 相关的背景知识，我们都将毫无跳过地指导你逐步掌握 Dify 的核心概念和使用方法。

在本教程中，我们将通过一系列实验来帮助你深入理解 Dify 的各个方面。每个实验都将包含详细的步骤和解释，确保你能够轻松跟上并掌握所学内容。我们会在实验中穿插知识的教学，让你在实践中学习，逐步建立起对 Dify 的全面理解。

无需担心需要任何前置知识，我们会从最基础的概念开始，逐步引导你进入更高级的主题。无论你是完全的新手，还是有一些编程经验但想学习 AI 技术，本教程都将为你提供所需的一切。

让我们一起开始这段学习之旅，探索 Dify 的无限可能吧！

[Previous订阅管理](/zh-hans/guides/management/subscription-management) [Next如何搭建 AI 图片生成应用](/zh-hans/workshop/basic/build-ai-image-generation-app)

Last updated 3 months ago[チャットストリームエージェントを使用した Twitter アカウントの分析方法](/ja-jp/workshop/intermediate/twitter-chatflow) [ファイルアップロードを使用した記事理解アシスタントの構築方法](/ja-jp/workshop/intermediate/article-reader)

[PreviousAIエージェントの実践：個人のオンライン旅行アシスタントの構築方法](/ja-jp/workshop/basic/travel-assistant) [Nextチャットストリームエージェントを使用した Twitter アカウントの分析方法](/ja-jp/workshop/intermediate/twitter-chatflow)

Last updated 3 months ago## [Direct link to heading](\#endpoint)    Endpoint

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
POST <your-endpoint>/retrieval
```

This API is used to connect to a knowledge base that is independent of the Dify and maintained by developers. For more details, please refer to [Connecting to an External Knowledge Base](https://docs.dify.ai/guides/knowledge-base/connect-external-knowledge-base). You can use `API-Key` in the `Authorization` HTTP Header to verify permissions. The authentication logic is defined by you in the retrieval API, as shown below:

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
Authorization: Bearer {API_KEY}
```

## [Direct link to heading](\#request-body-elements)    Request Body Elements

The request accepts the following data in JSON format.

Property

Required

Type

Description

Example value

knowledge\_id

TRUE

string

Your knowledge's unique ID

AAA-BBB-CCC

query

TRUE

string

User's query

What is Dify?

retrieval\_setting

TRUE

object

Knowledge's retrieval parameters

See below

The `retrieval_setting` property is an object containing the following keys:

Property

Required

Type

Description

Example value

top\_k

TRUE

int

Maximum number of retrieved results

5

score\_threshold

TRUE

float

The score limit of relevance of the result to the query, scope: 0~1

0.5

## [Direct link to heading](\#request-syntax)    Request Syntax

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
POST <your-endpoint>/retrieval HTTP/1.1
-- header
Content-Type: application/json
Authorization: Bearer your-api-key
-- data
{
    "knowledge_id": "your-knowledge-id",
    "query": "your question",
    "retrieval_setting":{
        "top_k": 2,
        "score_threshold": 0.5
    }
}
```

## [Direct link to heading](\#response-elements)    Response Elements

If the action is successful, the service sends back an HTTP 200 response.

The following data is returned in JSON format by the service.

Property

Required

Type

Description

Example value

records

TRUE

List\[Object\]

A list of records from querying the knowledge base.

See below

The `records` property is a list object containing the following keys:

Property

Required

Type

Description

Example value

content

TRUE

string

Contains a chunk of text from a data source in the knowledge base.

Dify:The Innovation Engine for GenAI Applications

score

TRUE

float

The score of relevance of the result to the query, scope: 0~1

0.5

title

TRUE

string

Document title

Dify Introduction

metadata

FALSE

json

Contains metadata attributes and their values for the document in the data source.

See example

## [Direct link to heading](\#response-syntax)    Response Syntax

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
HTTP/1.1 200
Content-type: application/json
{
    "records": [{\
                    "metadata": {\
                            "path": "s3://dify/knowledge.txt",\
                            "description": "dify knowledge document"\
                    },\
                    "score": 0.98,\
                    "title": "knowledge.txt",\
                    "content": "This is the document for external knowledge."\
            },\
            {\
                    "metadata": {\
                            "path": "s3://dify/introduce.txt",\
                            "description": "dify introduce"\
                    },\
                    "score": 0.66,\
                    "title": "introduce.txt",\
                    "content": "The Innovation Engine for GenAI Applications"\
            }\
    ]
}
```

## [Direct link to heading](\#errors)    Errors

If the action fails, the service sends back the following error information in JSON format:

Property

Required

Type

Description

Example value

error\_code

TRUE

int

Error code

1001

error\_msg

TRUE

string

The description of API exception

Invalid Authorization header format. Expected 'Bearer ' format.

The `error_code` property has the following types:

Code

Description

1001

Invalid Authorization header format.

1002

Authorization failed

2001

The knowledge does not exist

### [Direct link to heading](\#http-status-codes)    HTTP Status Codes

**AccessDeniedException** The request is denied because of missing access permissions. Check your permissions and retry your request. HTTP Status Code: 403

**InternalServerException** An internal server error occurred. Retry your request. HTTP Status Code: 500

[PreviousConnect to an External Knowledge Base](/guides/knowledge-base/connect-external-knowledge) [NextTools](/guides/tools)

Last updated 2 months agoIn Dify, an "application" refers to a practical scenario application built on large language models like GPT. By creating an application, you can apply intelligent AI technology to specific needs. It encompasses both the engineering paradigm for developing AI applications and the specific deliverables.

In short, an application provides developers with:

- A user-friendly API that can be directly called by backend or frontend applications, authenticated via Token

- A ready-to-use, aesthetically pleasing, and hosted WebApp, which you can further develop using the WebApp template

- An easy-to-use interface that includes prompt engineering, context management, log analysis, and annotation


You can choose **any one** or **all** of these to support your AI application development.

### [Direct link to heading](\#application_type)    Application Types

Dify offers four types of applications:

- **Chat Assistant**: A conversational assistant built on LLM

- **Text Generation**: An assistant for text generation tasks such as writing stories, text classification, translation, etc.

- **Agent**: A conversational intelligent assistant capable of task decomposition, reasoning, and tool invocation

- **Workflow**: Defines more flexible LLM workflows based on process orchestration


The differences between Text Generation and Chat Assistant are shown in the table below:

Text Generation

Chat Assistant

WebApp Interface

Form + Results

Chat-based

WebAPI Endpoint

`completion-messages`

`chat-messages`

Interaction Mode

One question, one answer

Multi-turn conversation

Streaming Results

Supported

Supported

Context Preservation

Per session

Continuous

User Input Form

Supported

Supported

Datasets and Plugins

Supported

Supported

AI Opening Remarks

Not supported

Supported

Example Scenarios

Translation, judgment, indexing

Chatting

### [Direct link to heading](\#undefined)

[PreviousLoad Balancing](/guides/model-configuration/load-balancing) [NextCreate Application](/guides/application-orchestrate/creating-an-application)

Last updated 6 months ago[Integrate Open Source Models from Hugging Face](/development/models-integration/hugging-face) [Integrate Open Source Models from Replicate](/development/models-integration/replicate) [Integrate Local Models Deployed by Xinference](/development/models-integration/xinference) [Integrate Local Models Deployed by OpenLLM](/development/models-integration/openllm) [Integrate Local Models Deployed by LocalAI](/development/models-integration/localai) [Integrate Local Models Deployed by Ollama](/development/models-integration/ollama) [Integrate Models on LiteLLM Proxy](/development/models-integration/litellm) [Integrating with GPUStack for Local Model Deployment](/development/models-integration/gpustack)

[PreviousContribution Guide](/development/backend/sandbox/contribution) [NextIntegrate Open Source Models from Hugging Face](/development/models-integration/hugging-face)

This site uses cookies to deliver its service and to analyse traffic. By browsing this site, you accept the [privacy policy](https://dify.ai/privacy).

AcceptRejectDefining Reply Content in a Chatflow Process. In a text editor, you have the flexibility to determine the reply format. This includes crafting a fixed block of text, utilizing output variables from preceding steps as the reply content, or merging custom text with variables for the response.

Answer node can be seamlessly integrated at any point to dynamically deliver content into the dialogue responses. This setup supports a live-editing configuration mode, allowing for both text and image content to be arranged together. The configurations include:

1. Outputting the reply content from a Language Model (LLM) node.

2. Outputting generated images.

3. Outputting plain text.


Example 1: Output plain text.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-07294e06b1f999b3afb430bf881b16cc14d246ec%252Fanswer-plain-text.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=5f389ef8&sv=2)

Example 2: Output image and LLM reply.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-a2986bd3645edec4b0c74a739b21a77014b89be8%252Fanswer-img-1.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=8d27a38e&sv=2)

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-83e5b26b430795eaf34b4a8d42632c509e4e6069%252Fanswer-img-2.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=a6c05319&sv=2)

[PreviousEnd](/guides/workflow/node/end) [NextLLM](/guides/workflow/node/llm)

Last updated 6 months ago### [Direct link to heading](\#nodes)    Nodes

**Nodes are the key components of a workflow**. By connecting nodes with different functionalities, you can execute a series of operations within the workflow.

For core workflow nodes, please refer to [Block Description](/guides/workflow/node).

* * *

### [Direct link to heading](\#variables)    Variables

**Variables are used to link the input and output of nodes within a workflow**, enabling complex processing logic throughout the process. Fore more details, please take refer to [Variables](/guides/workflow/variables).

* * *

### [Direct link to heading](\#chatflow-and-workflow)    Chatflow and Workflow

**Application Scenarios**

- **Chatflow**: Designed for conversational scenarios, including customer service, semantic search, and other conversational applications that require multi-step logic in response construction.

- **Workflow**: Geared towards automation and batch processing scenarios, suitable for high-quality translation, data analysis, content generation, email automation, and more.


**Usage Entry Points**

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2Fbefca8ff01ac5dccf4d32bcab08b8a11.png&width=768&dpr=4&quality=100&sign=23aa859c&sv=2)

Chatflow

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2F56521297208916676acaf1c59e968e41.png&width=768&dpr=4&quality=100&sign=ec3c68e6&sv=2)

Workflow

**Differences in Available Nodes**

1. The [End node](/guides/workflow/node/end) is an ending node for Workflow and can only be selected at the end of the process.

2. The [Answer node](/guides/workflow/node/answer) is specific to Chatflow, used for streaming text output, and can output at intermediate steps in the process.

3. Chatflow has built-in chat memory (Memory) for storing and passing multi-turn conversation history, which can be enabled in nodes like LLM and question classifiers. Workflow does not have Memory-related configurations and cannot enable them.

4. Built-in variables for Chatflow's [start node](/guides/workflow/node/start) include: `sys.query`, `sys.files`, `sys.conversation_id`, `sys.user_id`. Built-in [variables](/guides/workflow/variables) for Workflow's start node include: `sys.files`, `sys_id`.


[PreviousWorkflow](/guides/workflow) [NextVariables](/guides/workflow/variables)

Last updated 19 days agoSo you're looking to contribute to Dify - that's awesome, we can't wait to see what you do. As a startup with limited headcount and funding, we have grand ambitions to design the most intuitive workflow for building and managing LLM applications. Any help from the community counts, truly.

We need to be nimble and ship fast given where we are, but we also want to make sure that contributors like you get as smooth an experience at contributing as possible. We've assembled this contribution guide for that purpose, aiming at getting you familiarized with the codebase & how we work with contributors, so you could quickly jump to the fun part.

This guide, like Dify itself, is a constant work in progress. We highly appreciate your understanding if at times it lags behind the actual project, and welcome any feedback for us to improve.

In terms of licensing, please take a minute to read our short [License and Contributor Agreement](https://github.com/langgenius/dify/blob/main/LICENSE). The community also adheres to the [code of conduct](https://github.com/langgenius/.github/blob/main/CODE_OF_CONDUCT.md).

### [Direct link to heading](\#before-you-jump-in)    Before you jump in

[Find](https://github.com/langgenius/dify/issues?q=is:issue+is:closed) an existing issue, or [open](https://github.com/langgenius/dify/issues/new/choose) a new one. We categorize issues into 2 types:

#### [Direct link to heading](\#feature-requests)    Feature requests:

- If you're opening a new feature request, we'd like you to explain what the proposed feature achieves, and include as much context as possible. [@perzeusss](https://github.com/perzeuss) has made a solid [Feature Request Copilot](https://udify.app/chat/MK2kVSnw1gakVwMX) that helps you draft out your needs. Feel free to give it a try.

- If you want to pick one up from the existing issues, simply drop a comment below it saying so.



A team member working in the related direction will be looped in. If all looks good, they will give the go-ahead for you to start coding. We ask that you hold off working on the feature until then, so none of your work goes to waste should we propose changes.



Depending on whichever area the proposed feature falls under, you might talk to different team members. Here's rundown of the areas each our team members are working on at the moment:











Member



Scope















[@yeuoly](https://github.com/Yeuoly)











Architecting Agents















[@jyong](https://github.com/JohnJyong)











RAG pipeline design















[@GarfieldDai](https://github.com/GarfieldDai)











Building workflow orchestrations















[@iamjoel](https://github.com/iamjoel) & [@zxhlyh](https://github.com/zxhlyh)











Making our frontend a breeze to use















[@guchenhe](https://github.com/guchenhe) & [@crazywoola](https://github.com/crazywoola)











Developer experience, points of contact for anything















[@takatost](https://github.com/takatost)











Overall product direction and architecture















How we prioritize:











Feature Type



Priority















High-Priority Features as being labeled by a team member











High Priority















Popular feature requests from our [community feedback board](https://github.com/langgenius/dify/discussions/categories/ideas)











Medium Priority















Non-core features and minor enhancements











Low Priority















Valuable but not immediate











Future-Feature


#### [Direct link to heading](\#anything-else-e.g.-bug-report-performance-optimization-typo-correction)    Anything else (e.g. bug report, performance optimization, typo correction):

- Start coding right away.



How we prioritize:











Issue Type



Priority















Bugs in core functions (cannot login, applications not working, security loopholes)











Critical















Non-critical bugs, performance boosts











Medium Priority















Minor fixes (typos, confusing but working UI)











Low Priority


### [Direct link to heading](\#installing)    Installing

Here are the steps to set up Dify for development:

#### [Direct link to heading](\#id-1.-fork-this-repository)    1\. Fork this repository

#### [Direct link to heading](\#id-2.-clone-the-repo)    2\. Clone the repo

Clone the forked repository from your terminal:

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
git clone git@github.com:<github_username>/dify.git
```

#### [Direct link to heading](\#id-3.-verify-dependencies)    3\. Verify dependencies

Dify requires the following dependencies to build, make sure they're installed on your system:

- [Docker](https://www.docker.com/)

- [Docker Compose](https://docs.docker.com/compose/install/)

- [Node.js v18.x (LTS)](http://nodejs.org)

- [npm](https://www.npmjs.com/) version 8.x.x or [Yarn](https://yarnpkg.com/)

- [Python](https://www.python.org/) version 3.10.x


#### [Direct link to heading](\#id-4.-installations)    4\. Installations

Dify is composed of a backend and a frontend. Navigate to the backend directory by `cd api/`, then follow the [Backend README](https://github.com/langgenius/dify/blob/main/api/README.md) to install it. In a separate terminal, navigate to the frontend directory by `cd web/`, then follow the [Frontend README](https://github.com/langgenius/dify/blob/main/web/README.md) to install.

Check the [installation FAQ](https://docs.dify.ai/learn-more/faq/install-faq) for a list of common issues and steps to troubleshoot.

#### [Direct link to heading](\#id-5.-visit-dify-in-your-browser)    5\. Visit dify in your browser

To validate your set up, head over to [http://localhost:3000](http://localhost:3000) (the default, or your self-configured URL and port) in your browser. You should now see Dify up and running.

### [Direct link to heading](\#developing)    Developing

If you are adding a model provider, [this guide](https://github.com/langgenius/dify/blob/main/api/core/model_runtime/README.md) is for you.

If you are adding tools used in Agent Assistants and Workflows, [this guide](https://github.com/langgenius/dify/blob/main/api/core/tools/README.md) is for you.

> **Note** : If you want to contribute to a new tool, please make sure you've left your contact information on the tool's 'YAML' file, and submitted a corresponding docs PR in the [Dify-docs](https://github.com/langgenius/dify-docs/tree/main/en/guides/tools/tool-configuration) repository.

To help you quickly navigate where your contribution fits, a brief, annotated outline of Dify's backend & frontend is as follows:

#### [Direct link to heading](\#backend)    Backend

Dify’s backend is written in Python using [Flask](https://flask.palletsprojects.com/en/3.0.x/). It uses [SQLAlchemy](https://www.sqlalchemy.org/) for ORM and [Celery](https://docs.celeryq.dev/en/stable/getting-started/introduction.html) for task queueing. Authorization logic goes via Flask-login.

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
[api/]
├── constants             // Constant settings used throughout code base.
├── controllers           // API route definitions and request handling logic.
├── core                  // Core application orchestration, model integrations, and tools.
├── docker                // Docker & containerization related configurations.
├── events                // Event handling and processing
├── extensions            // Extensions with 3rd party frameworks/platforms.
├── fields                // field definitions for serialization/marshalling.
├── libs                  // Reusable libraries and helpers.
├── migrations            // Scripts for database migration.
├── models                // Database models & schema definitions.
├── services              // Specifies business logic.
├── storage               // Private key storage.
├── tasks                 // Handling of async tasks and background jobs.
└── tests
```

#### [Direct link to heading](\#frontend)    Frontend

The website is bootstrapped on [Next.js](https://nextjs.org/) boilerplate in Typescript and uses [Tailwind CSS](https://tailwindcss.com/) for styling. [React-i18next](https://react.i18next.com/) is used for internationalization.

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
[web/]
├── app                   // layouts, pages, and components
│   ├── (commonLayout)    // common layout used throughout the app
│   ├── (shareLayout)     // layouts specifically shared across token-specific sessions
│   ├── activate          // activate page
│   ├── components        // shared by pages and layouts
│   ├── install           // install page
│   ├── signin            // signin page
│   └── styles            // globally shared styles
├── assets                // Static assets
├── bin                   // scripts ran at build step
├── config                // adjustable settings and options
├── context               // shared contexts used by different portions of the app
├── dictionaries          // Language-specific translate files
├── docker                // container configurations
├── hooks                 // Reusable hooks
├── i18n                  // Internationalization configuration
├── models                // describes data models & shapes of API responses
├── public                // meta assets like favicon
├── service               // specifies shapes of API actions
├── test
├── types                 // descriptions of function params and return values
└── utils                 // Shared utility functions
```

### [Direct link to heading](\#submitting-your-pr)    Submitting your PR

At last, time to open a pull request (PR) to our repo. For major features, we first merge them into the `deploy/dev` branch for testing, before they go into the `main` branch. If you run into issues like merge conflicts or don't know how to open a pull request, check out [GitHub's pull request tutorial](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests).

And that's it! Once your PR is merged, you will be featured as a contributor in our [README](https://github.com/langgenius/dify/blob/main/README.md).

### [Direct link to heading](\#getting-help)    Getting Help

If you ever get stuck or got a burning question while contributing, simply shoot your queries our way via the related GitHub issue, or hop onto our [Discord](https://discord.gg/AhzKf7dNgk) for a quick chat.

[PreviousSeek Support](/community/support) [NextContributing to Dify Documentation](/community/docs-contribution)

Last updated 4 months agoThe workflow provides a rich selection of tools, categorized into three types:

- **Built-in Tools**: Tools provided by Dify.

- **Custom Tools**: Tools imported or configured via the OpenAPI/Swagger standard format.

- **Workflows**: Workflows that have been published as tools.


## [Direct link to heading](\#add-and-use-the-tool-node)    Add and Use the Tool Node

Before using built-in tools, you may need to **authorize** the tools.

If built-in tools do not meet your needs, you can create custom tools in the **Dify menu navigation -- Tools** section.

You can also orchestrate a more complex workflow and publish it as a tool.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-4b527c3066ccc7832be2b101c605b541afb50270%252Fworkflow-tool.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=c7dae3c5&sv=2)

Tool Selection

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-7245598314b71aab560715836d1dd54262eb71e1%252Fworkflow-google-search-tool.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=ed7cc557&sv=2)

Configuring Google Search Tool to Retrieve External Knowledge

Configuring a tool node generally involves two steps:

1. Authorizing the tool/creating a custom tool/publishing a workflow as a tool.

2. Configuring the tool's input and parameters.


For more information on how to create custom tools and configure them, please refer to the [Tool Configuration Guide](https://docs.dify.ai/guides/tools).

### [Direct link to heading](\#advanced-features)    Advanced Features

**Retry on Failure**

For some exceptions that occur in the node, it is usually sufficient to retry the node again. When the error retry function is enabled, the node will automatically retry according to the preset strategy when an error occurs. You can adjust the maximum number of retries and the interval between each retry to set the retry strategy.

- The maximum number of retries is 10

- The maximum retry interval is 5000 ms


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2F34867b2d910d74d2671cd40287200480.png&width=768&dpr=4&quality=100&sign=abc8b586&sv=2)

**Error Handling**

Tool nodes may encounter errors during information processing that could interrupt the workflow. Developers can follow these steps to configure fail branches, enabling contingency plans when nodes encounter exceptions, avoiding workflow interruptions.

1. Enable "Error Handling" in the tool node

2. Select and configure an error-handling strategy


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2F39dc3b5881d9a5fe35b877971f70d3a6.png&width=768&dpr=4&quality=100&sign=94ac3b99&sv=2)

For more information about exception handling approaches, please refer to [Error Handling](https://docs.dify.ai/guides/workflow/error-handling).

## [Direct link to heading](\#publishing-workflow-applications-as-tools)    Publishing Workflow Applications as Tools

Workflow applications can be published as tools and used by nodes in other workflows. For information about creating custom tools and tool configuration, please refer to the [Tool Configuration Guide](https://docs.dify.ai/guides/tools).

[PreviousHTTP Request](/guides/workflow/node/http-request) [NextShortcut Key](/guides/workflow/shortcut-key)

Last updated 15 days ago图片上传功能已被纳入至更加综合的 [文件上传](/zh-hans/guides/workflow/file-upload) 功能中，为了避免出现功能重复，我们决定对 Workflow 和 Chatflow 应用的“ [附加功能](/zh-hans/guides/workflow/additional-features)”进行升级和调整：

- 移除 Chatflow 应用“功能”中的图片上传选项，取而代之的是新的“文件上传”功能。你可以在“文件上传”功能内选择图片文件类型。同时，应用对话框中的图片上传 icon 也被替换为文件上传 icon。


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F1288284732-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FCdDIVDY6AtAz028MFT4d%252Fuploads%252FbfZy31hpITpNTqF6kJhc%252Fimage.png%3Falt%3Dmedia%26token%3Dcdc39f68-ff6f-43a9-aeeb-a7d3101623c2&width=768&dpr=4&quality=100&sign=2d0ae4ea&sv=2)

- 将在未来 **停用 Workflow 应用“功能”中的图片上传选项** 以及移除 `sys.files` [变量](/zh-hans/guides/workflow/variables)，目前这两项功能已被标记为 `LEGACY`，建议应用开发者改用自定义文件变量为 Workflow 应用添加文件上传功能。


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F1288284732-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FCdDIVDY6AtAz028MFT4d%252Fuploads%252FNR3W6pfI0Ov5nyggKI3e%252Fimage.png%3Falt%3Dmedia%26token%3D4c9afec1-6c0a-4ea1-8f19-f9dfaf02e487&width=768&dpr=4&quality=100&sign=229447c3&sv=2)

### [Direct link to heading](\#wei-shen-me-yao-ti-huan-tu-pian-shang-chuan-gong-neng)    为什么要替换“图片上传”功能？

Dify 此前仅支持上传图片文件。而在最新的版本中，已提供更加全面的文件上传能力，支持文档、图片、音视频文件或自定义文件格式，\*\*图片上传能力已被更大的“文件上传”功能所包含。\*\*应用开发者添加文件上传功能后，仅勾选“图片”类型文件即可开启图片上传能力。

为了避免功能重复所造成体验上的困扰，我们决定替换 Chatflow 应用内单独的图片上传功能，转而提供更加全面的文件上传能力；同时不再建议继续为 Workflow 应用开启图片上传功能。

### [Direct link to heading](\#geng-jia-quan-mian-de-gong-neng-wen-jian-shang-chuan)    更加全面的功能：文件上传

为了让应用具备更加强大的信息处理能力，本次更新我们新增了“文件上传”能力。相较于聊天文本，文档文件能够承载大量的信息，例如学术报告、法律合同。

- 文件上传功能允许将文件以 File variables 的形式在工作流应用中上传、解析、引用、和下载。

- 开发者现可轻松构建能理解和处理图片、音频、视频复杂工作的应用。


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F1288284732-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FCdDIVDY6AtAz028MFT4d%252Fuploads%252FwObDyUfIug2M8ikgAXgk%252Fimage.png%3Falt%3Dmedia%26token%3D0be4a97a-6eae-42ac-bd89-d87ef643cc95&width=768&dpr=4&quality=100&sign=7c648124&sv=2)

因此不再建议使用单独的“图片上传”功能，而是改用更为综合全面的“文件上传”功能以增强应用体验。

### [Direct link to heading](\#ni-xu-yao-zuo-shen-me)    你需要做什么？

#### [Direct link to heading](\#dui-yu-dify-cloud-yong-hu)    **对于 Dify Cloud 用户：**

- **Chatflow 应用**


如果你已创建 Chatflow 应用并启用了“图片上传”功能，并在 LLM 节点中开启 Vision 功能，系统将自动完成功能切换，不会影响到应用的图片上传能力。如果需要更新并重新发布应用，需要在 LLM 节点中的 Vision 变量选择框指定文件变量后清除 checklist 中的 item，重新发布应用。

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F1288284732-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FCdDIVDY6AtAz028MFT4d%252Fuploads%252F9kHeB2P8NcoPfGgSweRq%252Fimage.png%3Falt%3Dmedia%26token%3Dbfa867a1-0a22-4ea6-a9b2-792a5011bd73&width=768&dpr=4&quality=100&sign=ea902f50&sv=2)

如果你希望在 Chatflow 应用中添加“图片上传”功能，请在功能中开启“文件上传”，仅勾选“图片”类型。然后在 LLM 节点中启用 Vision 功能，并在其中填写 `sys.files` 变量。此时输入框将出现“回形针”的上传入口，详细说明请参考 [附加功能](/zh-hans/guides/workflow/additional-features)。

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F1288284732-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FCdDIVDY6AtAz028MFT4d%252Fuploads%252F4UddIkjk5tVvjqjfex0E%252Fimage.png%3Falt%3Dmedia%26token%3D7b0c6428-fadf-457a-ae8a-15b06114f177&width=768&dpr=4&quality=100&sign=4495db7c&sv=2)

- **Workflow 应用**


如果你已创建 Workflow 应用并启用了“图片上传”功能，并在 LLM 节点中开启 Vision 功能，此次变动当下不会产生任何影响但你需要做正式下线前完成手动迁移。

如果希望为 Workflow 应用开启“图片上传”功能，请在 [开始](/zh-hans/guides/workflow/node/start) 节点中添加文件变量。然后在后续的节点中引用该文件变量，不再继续使用 `sys.files` 变量。

#### [Direct link to heading](\#dui-yu-dify-she-qu-ban-huo-ben-di-bu-shu-de-qi-ye-ban-yong-hu)    对于Dify 社区版或本地部署的企业版用户：

升级到 v0.10.0 版本后你将看到 “文件上传” 功能。

- **Chatflow 应用**


已启用“图片上传”功能的 Chatflow 应用将自动完成切换，无需变更。

如果你希望在 Chatflow 应用中添加“图片上传”功能，详细说明请参考 [附加功能](/zh-hans/guides/workflow/additional-features)。

- Workflow 应用


已创建的 Workflow 应用不会产生任何影响，但是请在正式下线前完成手动迁移。

如果希望为 Workflow 应用开启“图片上传”功能，请在 [开始](/zh-hans/guides/workflow/node/start) 节点中添加文件变量。然后在后续的节点中引用该文件变量，不再继续使用 `sys.files` 变量。

### [Direct link to heading](\#chang-jian-wen-ti)    常见问题

1. **这次更新会影响我现有的应用吗？**


- 已创建的 Chatflow 应用将自动迁移，图片上传功无感切换至文件上传功能。仍然会默认使用 sys.file 作为模型 vision 输入框的变量。应用使用页的图片上传入口会被替换为文件上传入口。

- 现有 Workflow 应用暂时不会受到影响。 `sys.file` 和图片上传功能会被标记为 `Legacy` ，但仍然可以使用。被标记为 `Legacy` 的功能将在未来下线，届时需要手动更新应用。


1. **我需要立即更新我的应用吗？**


- 对于 Chatflow 应用,系统会自动迁移，无需手动更新。

- 对于 Workflow 应用，虽然不需要立即更新，但建议你尽早熟悉新的文件上传功能，为未来的迁移做准备。


1. **如何确保我的应用兼容新的文件上传功能？**


对于 Chatflow 应用:

- 检查 features 配置中的文件上传选项是否已开启。

- 确保使用带有视觉能力的 LLM，并打开 Vision 功能开关。

- 验证 `sys.files` 是否被正确选中作 Vision 框中的输入项。


对于 Workflow 应用:

- 在“开始节点”创建文件类型的变量。

- 在后续的节点中引用这个文件变量，而不是使用已被标记为 `Legacy` 的 `sys.files`。


1. **历史发布的 Chatflow 应用内，原有的图片上传图标消失，如何处理？**


建议重新发布应用，应用聊天框将出现文件上传图标。

### [Direct link to heading](\#wo-men-qi-dai-ni-de-fan-kui)    我们期待你的反馈

作为 Dify 社区的重要成员，你的使用体验和反馈对我们至关重要。我们诚挚地邀请你：

1. 尝试新的文件上传功能，体验其便捷性和灵活性。

2. 通过以下渠道分享你的想法和建议：



- [GitHub](https://github.com/langgenius/dify)

- [Discord 频道](https://discord.gg/FngNHpbcY7)


你的每一条反馈都将帮助我们不断完善产品，为整个社区带来更好的体验。

[Previous应用发布](/zh-hans/guides/workflow/publish) [Next知识库](/zh-hans/guides/knowledge-base)

Last updated 1 month ago

This site uses cookies to deliver its service and to analyse traffic. By browsing this site, you accept the [privacy policy](https://dify.ai/privacy).

AcceptRejectThis section describes the interface methods and parameter explanations that need to be implemented by providers and various model types.

## [Direct link to heading](\#provider)    Provider

Inherit the `__base.model_provider.ModelProvider` base class and implement the following interfaces:

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
def validate_provider_credentials(self, credentials: dict) -> None:
    """
    Validate provider credentials
    You can choose any validate_credentials method of model type or implement validate method by yourself,
    such as: get model list api

    if validate failed, raise exception

    :param credentials: provider credentials, credentials form defined in `provider_credential_schema`.
    """
```

- `credentials` (object) Credential information



The parameters of credential information are defined by the `provider_credential_schema` in the provider's YAML configuration file. Inputs such as `api_key` are included.


If verification fails, throw the `errors.validate.CredentialsValidateFailedError` error.

## [Direct link to heading](\#model)    Model

Models are divided into 5 different types, each inheriting from different base classes and requiring the implementation of different methods.

All models need to uniformly implement the following 2 methods:

- Model Credential Verification



Similar to provider credential verification, this step involves verification for an individual model.







Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
def validate_credentials(self, model: str, credentials: dict) -> None:
      """
      Validate model credentials

      :param model: model name
      :param credentials: model credentials
      :return:
      """
```





Parameters:



- `model` (string) Model name

- `credentials` (object) Credential information



The parameters of credential information are defined by either the `provider_credential_schema` or `model_credential_schema` in the provider's YAML configuration file. Inputs such as `api_key` are included.


If verification fails, throw the `errors.validate.CredentialsValidateFailedError` error.

- Invocation Error Mapping Table



When there is an exception in model invocation, it needs to be mapped to the `InvokeError` type specified by Runtime. This facilitates Dify's ability to handle different errors with appropriate follow-up actions.



Runtime Errors:



- `InvokeConnectionError` Invocation connection error

- `InvokeServerUnavailableError` Invocation service provider unavailable

- `InvokeRateLimitError` Invocation reached rate limit

- `InvokeAuthorizationError` Invocation authorization failure

- `InvokeBadRequestError` Invocation parameter error


Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
@property
def _invoke_error_mapping(self) -> dict[type[InvokeError], list[type[Exception]]]:
    """
    Map model invoke error to unified error
    The key is the error type thrown to the caller
    The value is the error type thrown by the model,
    which needs to be converted into a unified error type for the caller.

    :return: Invoke error mapping
    """
```

​ You can refer to OpenAI's `_invoke_error_mapping` for an example.

### [Direct link to heading](\#llm)    LLM

Inherit the `__base.large_language_model.LargeLanguageModel` base class and implement the following interfaces:

- LLM Invocation



Implement the core method for LLM invocation, which can support both streaming and synchronous returns.







Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
def _invoke(self, model: str, credentials: dict,
              prompt_messages: list[PromptMessage], model_parameters: dict,
              tools: Optional[list[PromptMessageTool]] = None, stop: Optional[List[str]] = None,
              stream: bool = True, user: Optional[str] = None) \
          -> Union[LLMResult, Generator]:
      """
      Invoke large language model

      :param model: model name
      :param credentials: model credentials
      :param prompt_messages: prompt messages
      :param model_parameters: model parameters
      :param tools: tools for tool calling
      :param stop: stop words
      :param stream: is stream response
      :param user: unique user id
      :return: full response or stream response chunk generator result
      """
```





- Parameters:



- `model` (string) Model name

- `credentials` (object) Credential information



The parameters of credential information are defined by either the `provider_credential_schema` or `model_credential_schema` in the provider's YAML configuration file. Inputs such as `api_key` are included.

- `prompt_messages` (array\[ [PromptMessage](/guides/model-configuration/interfaces#PromptMessage)\]) List of prompts



If the model is of the `Completion` type, the list only needs to include one [UserPromptMessage](/guides/model-configuration/interfaces#UserPromptMessage) element;



If the model is of the `Chat` type, it requires a list of elements such as [SystemPromptMessage](/guides/model-configuration/interfaces#SystemPromptMessage), [UserPromptMessage](/guides/model-configuration/interfaces#UserPromptMessage), [AssistantPromptMessage](/guides/model-configuration/interfaces#AssistantPromptMessage), [ToolPromptMessage](/guides/model-configuration/interfaces#ToolPromptMessage) depending on the message.

- `model_parameters` (object) Model parameters



The model parameters are defined by the `parameter_rules` in the model's YAML configuration.

- `tools` (array\[ [PromptMessageTool](/guides/model-configuration/interfaces#PromptMessageTool)\]) \[optional\] List of tools, equivalent to the `function` in `function calling`.



That is, the tool list for tool calling.

- `stop` (array\[string\]) \[optional\] Stop sequences



The model output will stop before the string defined by the stop sequence.

- `stream` (bool) Whether to output in a streaming manner, default is True



Streaming output returns Generator\[ [LLMResultChunk](/guides/model-configuration/interfaces#LLMResultChunk)\], non-streaming output returns [LLMResult](/guides/model-configuration/interfaces#LLMResult).

- `user` (string) \[optional\] Unique identifier of the user



This can help the provider monitor and detect abusive behavior.


- Returns



Streaming output returns Generator\[ [LLMResultChunk](/guides/model-configuration/interfaces#LLMResultChunk)\], non-streaming output returns [LLMResult](/guides/model-configuration/interfaces#LLMResult).


- Pre-calculating Input Tokens



If the model does not provide a pre-calculated tokens interface, you can directly return 0.







Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
def get_num_tokens(self, model: str, credentials: dict, prompt_messages: list[PromptMessage],
                     tools: Optional[list[PromptMessageTool]] = None) -> int:
      """
      Get number of tokens for given prompt messages

      :param model: model name
      :param credentials: model credentials
      :param prompt_messages: prompt messages
      :param tools: tools for tool calling
      :return:
      """
```





For parameter explanations, refer to the above section on `LLM Invocation`.

- Fetch Custom Model Schema \[Optional\]







Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
def get_customizable_model_schema(self, model: str, credentials: dict) -> Optional[AIModelEntity]:
      """
      Get customizable model schema

      :param model: model name
      :param credentials: model credentials
      :return: model schema
      """
```





When the provider supports adding custom LLMs, this method can be implemented to allow custom models to fetch model schema. The default return null.


### [Direct link to heading](\#textembedding)    TextEmbedding

Inherit the `__base.text_embedding_model.TextEmbeddingModel` base class and implement the following interfaces:

- Embedding Invocation







Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
def _invoke(self, model: str, credentials: dict,
              texts: list[str], user: Optional[str] = None) \
          -> TextEmbeddingResult:
      """
      Invoke large language model

      :param model: model name
      :param credentials: model credentials
      :param texts: texts to embed
      :param user: unique user id
      :return: embeddings result
      """
```





- Parameters:



- `model` (string) Model name

- `credentials` (object) Credential information



The parameters of credential information are defined by either the `provider_credential_schema` or `model_credential_schema` in the provider's YAML configuration file. Inputs such as `api_key` are included.

- `texts` (array\[string\]) List of texts, capable of batch processing

- `user` (string) \[optional\] Unique identifier of the user



This can help the provider monitor and detect abusive behavior.


- Returns:



[TextEmbeddingResult](/guides/model-configuration/interfaces#TextEmbeddingResult) entity.


- Pre-calculating Tokens







Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
def get_num_tokens(self, model: str, credentials: dict, texts: list[str]) -> int:
      """
      Get number of tokens for given prompt messages

      :param model: model name
      :param credentials: model credentials
      :param texts: texts to embed
      :return:
      """
```





For parameter explanations, refer to the above section on `Embedding Invocation`.


### [Direct link to heading](\#rerank)    Rerank

Inherit the `__base.rerank_model.RerankModel` base class and implement the following interfaces:

- Rerank Invocation







Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
def _invoke(self, model: str, credentials: dict,
              query: str, docs: list[str], score_threshold: Optional[float] = None, top_n: Optional[int] = None,
              user: Optional[str] = None) \
          -> RerankResult:
      """
      Invoke rerank model

      :param model: model name
      :param credentials: model credentials
      :param query: search query
      :param docs: docs for reranking
      :param score_threshold: score threshold
      :param top_n: top n
      :param user: unique user id
      :return: rerank result
      """
```





- Parameters:



- `model` (string) Model name

- `credentials` (object) Credential information



The parameters of credential information are defined by either the `provider_credential_schema` or `model_credential_schema` in the provider's YAML configuration file. Inputs such as `api_key` are included.

- `query` (string) Query request content

- `docs` (array\[string\]) List of segments to be reranked

- `score_threshold` (float) \[optional\] Score threshold

- `top_n` (int) \[optional\] Select the top n segments

- `user` (string) \[optional\] Unique identifier of the user



This can help the provider monitor and detect abusive behavior.


- Returns:



[RerankResult](/guides/model-configuration/interfaces#RerankResult) entity.


### [Direct link to heading](\#speech2text)    Speech2text

Inherit the `__base.speech2text_model.Speech2TextModel` base class and implement the following interfaces:

- Invoke Invocation







Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
def _invoke(self, model: str, credentials: dict, file: IO[bytes], user: Optional[str] = None) -> str:
      """
      Invoke large language model

      :param model: model name
      :param credentials: model credentials
      :param file: audio file
      :param user: unique user id
      :return: text for given audio file
      """
```





- Parameters:



- `model` (string) Model name

- `credentials` (object) Credential information



The parameters of credential information are defined by either the `provider_credential_schema` or `model_credential_schema` in the provider's YAML configuration file. Inputs such as `api_key` are included.

- `file` (File) File stream

- `user` (string) \[optional\] Unique identifier of the user



This can help the provider monitor and detect abusive behavior.


- Returns:



The string after speech-to-text conversion.


### [Direct link to heading](\#text2speech)    Text2speech

Inherit the `__base.text2speech_model.Text2SpeechModel` base class and implement the following interfaces:

- Invoke Invocation







Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
def _invoke(self, model: str, credentials: dict, content_text: str, streaming: bool, user: Optional[str] = None):
      """
      Invoke large language model

      :param model: model name
      :param credentials: model credentials
      :param content_text: text content to be translated
      :param streaming: output is streaming
      :param user: unique user id
      :return: translated audio file
      """
```





- Parameters：



- `model` (string) Model name

- `credentials` (object) Credential information



The parameters of credential information are defined by either the `provider_credential_schema` or `model_credential_schema` in the provider's YAML configuration file. Inputs such as `api_key` are included.

- `content_text` (string) The text content that needs to be converted

- `streaming` (bool) Whether to stream output

- `user` (string) \[optional\] Unique identifier of the user



This can help the provider monitor and detect abusive behavior.


- Returns：



Text converted speech stream。


### [Direct link to heading](\#moderation)    Moderation

Inherit the `__base.moderation_model.ModerationModel` base class and implement the following interfaces:

- Invoke Invocation







Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
def _invoke(self, model: str, credentials: dict,
              text: str, user: Optional[str] = None) \
          -> bool:
      """
      Invoke large language model

      :param model: model name
      :param credentials: model credentials
      :param text: text to moderate
      :param user: unique user id
      :return: false if text is safe, true otherwise
      """
```





- Parameters:



- `model` (string) Model name

- `credentials` (object) Credential information



The parameters of credential information are defined by either the `provider_credential_schema` or `model_credential_schema` in the provider's YAML configuration file. Inputs such as `api_key` are included.

- `text` (string) Text content

- `user` (string) \[optional\] Unique identifier of the user



This can help the provider monitor and detect abusive behavior.


- Returns:



False indicates that the input text is safe, True indicates otherwise.


## [Direct link to heading](\#entities)    Entities

### [Direct link to heading](\#promptmessagerole)    PromptMessageRole

Message role

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
class PromptMessageRole(Enum):
    """
    Enum class for prompt message.
    """
    SYSTEM = "system"
    USER = "user"
    ASSISTANT = "assistant"
    TOOL = "tool"
```

### [Direct link to heading](\#promptmessagecontenttype)    PromptMessageContentType

Message content types, divided into text and image.

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
class PromptMessageContentType(Enum):
    """
    Enum class for prompt message content type.
    """
    TEXT = 'text'
    IMAGE = 'image'
```

### [Direct link to heading](\#promptmessagecontent)    PromptMessageContent

Message content base class, used only for parameter declaration and cannot be initialized.

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
class PromptMessageContent(BaseModel):
    """
    Model class for prompt message content.
    """
    type: PromptMessageContentType
    data: str
```

Currently, two types are supported: text and image. It's possible to simultaneously input text and multiple images.

You need to initialize `TextPromptMessageContent` and `ImagePromptMessageContent` separately for input.

### [Direct link to heading](\#textpromptmessagecontent)    TextPromptMessageContent

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
class TextPromptMessageContent(PromptMessageContent):
    """
    Model class for text prompt message content.
    """
    type: PromptMessageContentType = PromptMessageContentType.TEXT
```

If inputting a combination of text and images, the text needs to be constructed into this entity as part of the `content` list.

### [Direct link to heading](\#imagepromptmessagecontent)    ImagePromptMessageContent

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
class ImagePromptMessageContent(PromptMessageContent):
    """
    Model class for image prompt message content.
    """
    class DETAIL(Enum):
        LOW = 'low'
        HIGH = 'high'

    type: PromptMessageContentType = PromptMessageContentType.IMAGE
    detail: DETAIL = DETAIL.LOW  # Resolution
```

If inputting a combination of text and images, the images need to be constructed into this entity as part of the `content` list.

`data` can be either a `url` or a `base64` encoded string of the image.

### [Direct link to heading](\#promptmessage)    PromptMessage

The base class for all Role message bodies, used only for parameter declaration and cannot be initialized.

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
class PromptMessage(ABC, BaseModel):
    """
    Model class for prompt message.
    """
    role: PromptMessageRole
    content: Optional[str | list[PromptMessageContent]] = None  # Supports two types: string and content list. The content list is designed to meet the needs of multimodal inputs. For more details, see the PromptMessageContent explanation.
    name: Optional[str] = None
```

### [Direct link to heading](\#userpromptmessage)    UserPromptMessage

UserMessage message body, representing a user's message.

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
class UserPromptMessage(PromptMessage):
    """
    Model class for user prompt message.
    """
    role: PromptMessageRole = PromptMessageRole.USER
```

### [Direct link to heading](\#assistantpromptmessage)    AssistantPromptMessage

Represents a message returned by the model, typically used for `few-shots` or inputting chat history.

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
class AssistantPromptMessage(PromptMessage):
    """
    Model class for assistant prompt message.
    """
    class ToolCall(BaseModel):
        """
        Model class for assistant prompt message tool call.
        """
        class ToolCallFunction(BaseModel):
            """
            Model class for assistant prompt message tool call function.
            """
            name: str  # tool name
            arguments: str  # tool arguments

        id: str  # Tool ID, effective only in OpenAI tool calls. It's the unique ID for tool invocation and the same tool can be called multiple times.
        type: str  # default: function
        function: ToolCallFunction  # tool call information

    role: PromptMessageRole = PromptMessageRole.ASSISTANT
    tool_calls: list[ToolCall] = []  # The result of tool invocation in response from the model (returned only when tools are input and the model deems it necessary to invoke a tool).
```

Where `tool_calls` are the list of `tool calls` returned by the model after invoking the model with the `tools` input.

### [Direct link to heading](\#systempromptmessage)    SystemPromptMessage

Represents system messages, usually used for setting system commands given to the model.

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
class SystemPromptMessage(PromptMessage):
    """
    Model class for system prompt message.
    """
    role: PromptMessageRole = PromptMessageRole.SYSTEM
```

### [Direct link to heading](\#toolpromptmessage)    ToolPromptMessage

Represents tool messages, used for conveying the results of a tool execution to the model for the next step of processing.

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
class ToolPromptMessage(PromptMessage):
    """
    Model class for tool prompt message.
    """
    role: PromptMessageRole = PromptMessageRole.TOOL
    tool_call_id: str  # Tool invocation ID. If OpenAI tool call is not supported, the name of the tool can also be inputted.
```

The base class's `content` takes in the results of tool execution.

### [Direct link to heading](\#promptmessagetool)    PromptMessageTool

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
class PromptMessageTool(BaseModel):
    """
    Model class for prompt message tool.
    """
    name: str
    description: str
    parameters: dict
```

* * *

### [Direct link to heading](\#llmresult)    LLMResult

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
class LLMResult(BaseModel):
    """
    Model class for llm result.
    """
    model: str  # Actual used modele
    prompt_messages: list[PromptMessage]  # prompt messages
    message: AssistantPromptMessage  # response message
    usage: LLMUsage  # usage info
    system_fingerprint: Optional[str] = None  # request fingerprint, refer to OpenAI definition
```

### [Direct link to heading](\#llmresultchunkdelta)    LLMResultChunkDelta

In streaming returns, each iteration contains the `delta` entity.

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
class LLMResultChunkDelta(BaseModel):
    """
    Model class for llm result chunk delta.
    """
    index: int
    message: AssistantPromptMessage  # response message
    usage: Optional[LLMUsage] = None  # usage info
    finish_reason: Optional[str] = None  # finish reason, only the last one returns
```

### [Direct link to heading](\#llmresultchunk)    LLMResultChunk

Each iteration entity in streaming returns.

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
class LLMResultChunk(BaseModel):
    """
    Model class for llm result chunk.
    """
    model: str  # Actual used modele
    prompt_messages: list[PromptMessage]  # prompt messages
    system_fingerprint: Optional[str] = None  # request fingerprint, refer to OpenAI definition
    delta: LLMResultChunkDelta
```

### [Direct link to heading](\#llmusage)    LLMUsage

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
class LLMUsage(ModelUsage):
    """
    Model class for LLM usage.
    """
    prompt_tokens: int  # Tokens used for prompt
    prompt_unit_price: Decimal  # Unit price for prompt
    prompt_price_unit: Decimal  # Price unit for prompt, i.e., the unit price based on how many tokens
    prompt_price: Decimal  # Cost for prompt
    completion_tokens: int  # Tokens used for response
    completion_unit_price: Decimal  # Unit price for response
    completion_price_unit: Decimal  # Price unit for response, i.e., the unit price based on how many tokens
    completion_price: Decimal  # Cost for response
    total_tokens: int  # Total number of tokens used
    total_price: Decimal  # Total cost
    currency: str  # Currency unit
    latency: float  # Request latency (s)
```

* * *

### [Direct link to heading](\#textembeddingresult)    TextEmbeddingResult

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
class TextEmbeddingResult(BaseModel):
    """
    Model class for text embedding result.
    """
    model: str  # Actual model used
    embeddings: list[list[float]]  # List of embedding vectors, corresponding to the input texts list
    usage: EmbeddingUsage  # Usage information
```

### [Direct link to heading](\#embeddingusage)    EmbeddingUsage

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
class EmbeddingUsage(ModelUsage):
    """
    Model class for embedding usage.
    """
    tokens: int  # Number of tokens used
    total_tokens: int  # Total number of tokens used
    unit_price: Decimal  # Unit price
    price_unit: Decimal  # Price unit, i.e., the unit price based on how many tokens
    total_price: Decimal  # Total cost
    currency: str  # Currency unit
    latency: float  # Request latency (s)
```

* * *

### [Direct link to heading](\#rerankresult)    RerankResult

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
class RerankResult(BaseModel):
    """
    Model class for rerank result.
    """
    model: str  # Actual model used
    docs: list[RerankDocument]  # Reranked document list
```

### [Direct link to heading](\#rerankdocument)    RerankDocument

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
class RerankDocument(BaseModel):
    """
    Model class for rerank document.
    """
    index: int  # original index
    text: str
    score: float
```

[PreviousCustom Model Integration](/guides/model-configuration/customizable-model) [NextSchema](/guides/model-configuration/schema)

Last updated 5 months agoDifyに貢献したいと思っていることには素晴らしいと思います。私たちはあなたの貢献を心待ちにしております。スタッフも資金も限られた新興企業として、私たちはLLMアプリケーションの構築と管理のための最も直感的なワークフローを設計するという野心的な目標を持っています。そのため、コミュニティからのあらゆるサポートは貴重です。

我々の現状を考えると、柔軟かつ迅速に更新する必要がありますが、貢献者がスムーズに貢献できるようにしたいとも考えています。そのために、この貢献ガイドを作成しました。このガイドは、あなたがコードベースに慣れ、貢献者としての活動を迅速に開始できるようにすることを目的としています。

このガイドは、Dify自体と同様に、常に改善されています。時折プロジェクトの実態よりも遅れることがあるかもしれませんが、ご理解と改善のためのフィードバックを心から歓迎します。

ライセンスに関しては、時間を取って短い [ライセンスと貢献者協定](https://github.com/langgenius/dify/blob/main/LICENSE) を読んでください。また、コミュニティは [行動規範](https://github.com/langgenius/.github/blob/main/CODE_OF_CONDUCT.md) にも従います。

## [Direct link to heading](\#meruni)    始める前に

[既存のイシューを探す](https://github.com/langgenius/dify/issues?q=is:issue+is:closed) か、新しいイシューを [作成する](https://github.com/langgenius/dify/issues/new/choose) ことができます。イシューは次の2つのカテゴリに分かれます：

### [Direct link to heading](\#rikuesuto)    機能リクエスト：

- 新しい機能リクエストを行う場合は、提案する機能の目的を説明し、できるだけ詳細なコンテキストを提供してください。 [@perzeusss](https://github.com/perzeuss) が作成した優れた [機能リクエスト助手](https://udify.app/chat/MK2kVSnw1gakVwMX) を使ってドラフトを作成することもできます。ぜひ試してみてください。

- 既存のイシューから選びたい場合は、その下にコメントを残して意思を示してください。


関連するチームメンバーが関与します。うまくいけば、彼らがコーディングを開始することを承認します。それまでは、変更が提案される可能性があるため、作業を開始しないでください。

提案された機能が属する領域に応じて、異なるチームメンバーと連携する必要があります。以下は、各チームメンバーが現在取り組んでいる分野の概要です：

Member

Scope

[@yeuoly](https://github.com/Yeuoly)

Architecting Agents

[@jyong](https://github.com/JohnJyong)

RAG pipeline design

[@GarfieldDai](https://github.com/GarfieldDai)

Building workflow orchestrations

[@iamjoel](https://github.com/iamjoel) & [@zxhlyh](https://github.com/zxhlyh)

Making our frontend a breeze to use

[@guchenhe](https://github.com/guchenhe) & [@crazywoola](https://github.com/crazywoola)

Developer experience, points of contact for anything

[@takatost](https://github.com/takatost)

Overall product direction and architecture

優先順位の判定ルール：

Feature Type

Priority

High-Priority Features as being labeled by a team member

High Priority

Popular feature requests from our [community feedback board](https://github.com/langgenius/dify/discussions/categories/ideas)

Medium Priority

Non-core features and minor enhancements

Low Priority

Valuable but not immediate

Future-Feature

### [Direct link to heading](\#sonoebabagupafmansutaipo)    その他（例えばバグ報告、パフォーマンス向上、タイポ修正）：

- すぐにコーディングを開始してください。



優先順位の判定ルール：











Issue Type



Priority















Bugs in core functions (cannot login, applications not working, security loopholes)











Critical















Non-critical bugs, performance boosts











Medium Priority















Minor fixes (typos, confusing but working UI)











Low Priority


## [Direct link to heading](\#insutru)    インストール

以下はDifyを開発用に設定する手順です：

### [Direct link to heading](\#id-1-ripojitoriwofkusuru)    1\. リポジトリをフォークする

### [Direct link to heading](\#id-2-ripojitoriwokurnsuru)    2\. リポジトリをクローンする

ターミナルからフォークしたリポジトリをクローンします：

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
git clone git@github.com:<github_username>/dify.git
```

### [Direct link to heading](\#id-3-wosuru)    3\. 依存関係を確認する

Difyは以下のツールとライブラリに依存しています：

- [Docker](https://www.docker.com/)

- [Docker Compose](https://docs.docker.com/compose/install/)

- [Node.js v18.x (LTS)](http://nodejs.org)

- [npm](https://www.npmjs.com/) バージョン 8.x.x もしくは [Yarn](https://yarnpkg.com/)

- [Python](https://www.python.org/) バージョン 3.10.x


### [Direct link to heading](\#id-4-insutru)    4\. インストール

Difyはバックエンドとフロントエンドで構成されています。 `cd api/` を使ってバックエンドディレクトリに移動し、次は [バックエンドREADME](https://github.com/langgenius/dify/blob/main/api/README.md) に従ってインストールして下さい。別のターミナルで `cd web/` を使ってフロントエンドディレクトリに移動し、そして [フロントエンドREADME](https://github.com/langgenius/dify/blob/main/web/README.md) に従ってインストールして下さい。

一般的な問題とトラブルシューティングの手順については [インストールFAQ](https://docs.dify.ai/v/ja-jp/learn-more/faq/install-faq) を参照してください。

### [Direct link to heading](\#id-5-burauzadedifyniakusesusuru)    5\. ブラウザでDifyにアクセスする

設定を確認するため、ブラウザを開き [http://localhost:3000](http://localhost:3000)（デフォルトまたはカスタムURLとポート）にアクセスします。これでDifyが動作しているはずです。

## [Direct link to heading](\#kai-fa)    開発

モデルを追加提供する場合は、 [このガイド](https://github.com/langgenius/dify/blob/main/api/core/model_runtime/README.md) を参照してください。

エージェントやワークフローにツールを追加提供する場合は、 [このガイド](https://github.com/langgenius/dify/blob/main/api/core/tools/README.md) を参照してください。

> 注意点：新しいツールを提供したい場合は、必ずツールの YAML 説明ページに連絡先を残し、ドキュメント [Dify-docs](https://github.com/langgenius/dify-docs/tree/main/en/guides/tools/tool-configuration) のコードリポジトリに対応するPRを提出してください。

貢献する部分を迅速に理解できるように、以下にDifyのバックエンドとフロントエンドの簡単な注釈付きアウトラインを示します：

### [Direct link to heading](\#bakkuendo)    バックエンド

DifyのバックエンドはPythonで書かれており、 [Flask](https://flask.palletsprojects.com/en/3.0.x/) フレームワークを使用しています。 [SQLAlchemy](https://www.sqlalchemy.org/) をORMとして使用し、 [Celery](https://docs.celeryq.dev/en/stable/getting-started/introduction.html) をタスクキューとして使用しています。認証ロジックはFlask-loginで処理されます。

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
[api/]
├── constants             // コードベース全体で使用される定数設定。
├── controllers           // APIルート定義とリクエスト処理ロジック。
├── core                  // コアアプリケーションオーケストレーション、モデル統合、ツール。
├── docker                // Dockerおよびコンテナ化関連の設定。
├── events                // イベント処理と処理
├── extensions            // サードパーティフレームワーク/プラットフォームとの拡張機能。
├── fields                // シリアライズ/マーシャリングのためのフィールド定義。
├── libs                  // 再利用可能なライブラリとヘルパー。
├── migrations            // データベース移行のためのスクリプト。
├── models                // データベースモデルとスキーマ定義。
├── services              // ビジネスロジックを指定。
├── storage               // 秘密鍵保管。
├── tasks                 // 非同期タスクとバックグラウンドジョブの処理。
└── tests
```

### [Direct link to heading](\#furontoendo)    フロントエンド

このWebサイトは [Next.js](https://nextjs.org/) テンプレートを使用しており、スタイリングには [Tailwind CSS](https://tailwindcss.com/) を使用しています。 [React-i18next](https://react.i18next.com/) を国際化に使用しています。

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
[web/]
├── app                   // レイアウト、ページ、およびコンポーネント
│   ├── (commonLayout)    // アプリ全体で使用される共通レイアウト
│   ├── (shareLayout)     // トークン固有のセッション間で共有されるレイアウト
│   ├── activate          // アクティベートページ
│   ├── components        // ページとレイアウトで共有されるコンポーネント
│   ├── install           // インストールページ
│   ├── signin            // サインインページ
│   └── styles            // グローバルに共有されるスタイル
├── assets                // 静的アセット
├── bin                   // ビルドステップで実行されるスクリプト
├── config                // 調整可能な設定とオプション
├── context               // アプリの異なる部分で使用される共有コンテキスト
├── dictionaries          // 言語固有の翻訳ファイル
├── docker                // コンテナ設定
├── hooks                 // 再利用可能なフック
├── i18n                  // 国際化設定
├── models                // データモデルとAPIレスポンスの形状を記述
├── public                // ファビコンなどのメタアセット
├── service               // APIアクションの形状を指定
├── test
├── types                 // 関数パラメータと戻り値の記述
└── utils                 // 共有ユーティリティ関数
```

## [Direct link to heading](\#prwosuru)    PRを提出する

最後に、私たちのリポジトリにプルリクエスト（PR）を提出する時が来ました。重要な機能の場合、最初に `deploy/dev` ブランチにマージしてテストを行い、その後 `main` ブランチにマージします。マージコンフリクトが発生した場合や、プルリクエストの提出方法が分からない場合は、 [GitHubのプルリクエストチュートリアル](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests) を参照してください。

これで完了です！あなたのPRがマージされると、あなたは私たちの [README](https://github.com/langgenius/dify/blob/main/README_JA.md) に貢献者として掲載されます。

## [Direct link to heading](\#herupuwomeru)    ヘルプを求める

貢献の過程で困難に直面したり質問がある場合は、関連するGitHubのイシューで質問を提出するか、私たちの [Discord](https://discord.gg/AhzKf7dNgk) に参加して迅速なコミュニケーションを行ってください。

[Previousサポートの求め](/ja-jp/community/support) [Nextドキュメントへの貢献](/ja-jp/community/docs-contribution)

Last updated 1 month ago[ログとアノテーション](/ja-jp/guides/annotation/logs) [アノテーション返信](/ja-jp/guides/annotation/annotation-reply)

[Previousフロントエンドテンプレートに基づいた再開発](/ja-jp/guides/application-publishing/based-on-frontend-templates) [Nextログとアノテーション](/ja-jp/guides/annotation/logs)

Last updated 5 months ago

This site uses cookies to deliver its service and to analyse traffic. By browsing this site, you accept the [privacy policy](https://dify.ai/privacy).

AcceptRejectDify supports accessing [Language models](https://replicate.com/collections/language-models) and [Embedding models](https://replicate.com/collections/embedding-models) on Replicate. Language models correspond to Dify's reasoning model, and Embedding models correspond to Dify's Embedding model.

Specific steps are as follows:

1. You need to have a Replicate account ( [registered address](https://replicate.com/signin?next=/docs)).

2. Get API Key ( [get address](https://replicate.com/signin?next=/docs)).

3. Pick a model. Select the model under [Language models](https://replicate.com/collections/language-models) and [Embedding models](https://replicate.com/collections/embedding-models) .

4. Add models in Dify's `Settings > Model Provider > Replicate`.


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-0ef5f751388fb6bb290c92502e48ddefac410fd1%252Fset-up-replicate.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=35cb21ee&sv=2)

The API key is the API Key set in step 2. Model Name and Model Version can be found on the model details page:

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-47df9c32dc2fa4db8ad6fc9b2b0a846a21494ae0%252Freplicate-version.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=d9f69b39&sv=2)

[PreviousIntegrate Open Source Models from Hugging Face](/development/models-integration/hugging-face) [NextIntegrate Local Models Deployed by Xinference](/development/models-integration/xinference)

Last updated 6 months ago

This site uses cookies to deliver its service and to analyse traffic. By browsing this site, you accept the [privacy policy](https://dify.ai/privacy).

AcceptReject### [Direct link to heading](\#upgrading-dify-team-subscription)    Upgrading Dify Team Subscription

Team owners and administrators can upgrade the team subscription plan. Click the **"Upgrade"** button in the upper right corner of the Dify team homepage, select an appropriate package, and complete the payment to upgrade the team's subscription.

### [Direct link to heading](\#managing-dify-team-subscription)    Managing Dify Team Subscription

After subscribing to Dify's paid services (Professional or Team plan), team owners and administrators can navigate to **"Settings"** → **"Billing"** to manage the team's billing and subscription details.

On the billing page, you can view the usage statistics for various team resources.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-0d713633a2d9a2357aba3084b1957b0ed5137e78%252Fsubscription-management-01.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=a610d55e&sv=2)

Team billing management

### [Direct link to heading](\#frequently-asked-questions)    Frequently Asked Questions

#### [Direct link to heading](\#id-1.-how-to-upgrade-downgrade-the-team-plan-or-cancel-a-subscription)    1\. How to upgrade/downgrade the team plan or cancel a subscription?

Team owners and administrators can navigate to **Settings** → **Billing**, then click on **Manage billing and subscription** to change the subscription plan.

- Upgrading from Professional to Team plan requires paying the difference for the current month and takes effect immediately.

- Downgrading from Team to Professional plan takes effect immediately.


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-5e6b9a7072e88695804507a1ecdbd5b7fa912fe0%252Fsubscription-management-02.jpeg%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=f1a7bc9e&sv=2)

Changing the paid plan

Upon cancellation of the subscription plan, **the team will automatically transition to the Sandbox/Free plan at the end of the current billing cycle**. Subsequently, any team members and resources exceeding the Sandbox/Free plan limitations will become inaccessible.

#### [Direct link to heading](\#id-2.-what-changes-will-occur-to-the-teams-available-resources-after-upgrading-the-subscription-plan)    2\. What changes will occur to the team's available resources after upgrading the subscription plan?

Resource

Free

Professional

Team

Team member limit

1

3

Unlimited

Application limit

10

50

Unlimited

Vector space capacity

5MB

200MB

1GB

[Marked replies](https://docs.dify.ai/guides/biao-zhu/logs) for applications

10

2000

5000

Document uploads for knowledge base

50

500

1000

OpenAI conversation quota

200 total

5000 per month

10000 per month

Note:

- When upgrading from Free to Professional, all resources are increased as shown in the table.

- When upgrading from Professional to Team, resources are further expanded, with some becoming unlimited.


After upgrading the subscription plan:

- The OpenAI conversation quota will be reset to the new limit for the current billing cycle.

- Previously used computational resources (e.g., vector space usage, document uploads) will not be reset or removed.


#### [Direct link to heading](\#id-3.-what-if-i-forget-to-renew-subscription-on-time)    3\. What if I forget to renew subscription on time?

If you forget to renew your subscription, the team will automatically downgrade to the Sandbox/Free version. Except for the team owner, others will not be able to continue accessing the team. Excess computational resources within the team (such as documents, vector space, etc.) will also be locked.

#### [Direct link to heading](\#id-4.-will-deleting-the-team-owners-account-affect-the-team)    4\. Will deleting the team owner's account affect the team?

A team needs to be bound to one team owner. If the team ownership is not transferred to another team member in time, all data of the current team will be deleted along with the owner's account.

#### [Direct link to heading](\#id-5.-what-are-the-differences-between-the-subscription-versions)    5\. What are the differences between the subscription versions?

For a detailed feature comparison, please refer to the [Dify pricing](https://dify.ai/pricing).

[PreviousPersonal Account Management](/guides/management/personal-account-management) [NextBasic](/workshop/basic)

Last updated 3 months agoDify Premiumは [AWS AMI](https://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/ec2-instances-and-amis.html) 製品であります。これにより、ブランドのカスタマイズが可能で、AWS EC2にワンクリックで展開できます。 [AWS Marketplace](https://aws.amazon.com/marketplace/pp/prodview-t22mebxzwjhu6) から購読し、次のようなシナリオに最適です：

- 中小企業が1つ以上のアプリケーションをサーバーに構築し、データのプライバシーに関心がある場合。

- [Dify Cloud](https://docs.dify.ai/v/ja-jp/getting-started/cloud) のサブスクリプションプランに関心があり、しかし、活用事例が [プラン](https://dify.ai/pricing) で提供されるリソースを超える場合。

- Dify Enterpriseを組織内で導入する前に、POC検証を行いたい場合。


### [Direct link to heading](\#settoappu)    セットアップ

Difyを初めて使用する際には、管理者初期化パスワード（EC2インスタンスIDとして設定）を入力し、セットアッププロセスを開始してください。

AMIを展開した後は、EC2コンソールで見つかるインスタンスのパブリックIPを使用してDifyにアクセスします（デフォルトではHTTPポート80を使用します）。

### [Direct link to heading](\#appugurdo)    アップグレード

EC2インスタンスで、次のコマンドを実行してください：

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
git clone https://github.com/langgenius/dify.git /tmp/dify
mv -f /tmp/dify/docker/* /dify/
rm -rf /tmp/dify
docker-compose down
docker-compose pull
docker-compose -f docker-compose.yaml -f docker-compose.override.yaml up -d
```

### [Direct link to heading](\#kasutamaizu)    カスタマイズ

セルフホスト展開の場合と同様に、EC2インスタンス内の.envファイルの環境変数を必要に応じて変更することができます。その後、以下のコマンドを使用してDifyを再起動してください：

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
docker-compose down
ocker-compose -f docker-compose.yaml -f docker-compose.override.yaml up -d
```

[Previousよくある質問](/ja-jp/getting-started/install-self-hosted/faq) [Nextモデル](/ja-jp/guides/model-configuration)

Last updated 1 month ago[アプリの管理](/ja-jp/guides/management/app-management) [チームメンバーの管理](/ja-jp/guides/management/team-members-management) [個人アカウントの管理](/ja-jp/guides/management/personal-account-management) [サブスクリプション管理](/ja-jp/guides/management/subscription-management)

[Previousメンバーの招待と管理](/ja-jp/guides/workspace/invite-and-manage-members) [Nextアプリの管理](/ja-jp/guides/management/app-management)

Last updated 5 months agoDify documentation is an [open-source project](https://github.com/langgenius/dify-docs), and we welcome contributions. Whether you've spotted an issue while reading the docs or you're keen to contribute your own content, we encourage you to submit an issue or initiate a pull request on GitHub. We'll address your PR promptly.

## [Direct link to heading](\#how-to-contribute)    How to Contribute

We categorize documentation issues into two main types:

- Content Corrections (Typos / Inaccuracies)

- Content Additions (New documentation)


### [Direct link to heading](\#content-errors)    Content Errors

If you encounter errors while reading a document or wish to suggest modifications, please use the **"Edit on GitHub"** button located in the table of contents on the right side of the document page. Utilize GitHub's built-in online editor to make your changes, then submit a pull request with a concise description of your edits. Please format your pull request title as `Fix: Update xxx`. We'll review your submission and merge the changes if everything looks good.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-6b48005300f9d029485364fbe86424348fc405a8%252Fdocs-contribution.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=7761c8eb&sv=2)

Alternatively, you can post the document link on our [Issues page](https://github.com/langgenius/dify-docs/issues) with a brief description of the necessary modifications. We'll address these promptly upon receipt.

### [Direct link to heading](\#content-additions)    Content Additions

To contribute new documentation to our repository, please follow these steps:

1. Fork the repository


Fork the repository to your GitHub account, then clone the repository to your local:

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
git clone https://github.com/<your-github-account>/dify-docs.git
```

> Note: You can also use GitHub's online code editor to submit new Markdown files directly in the appropriate directory.

1. Locate the relevant document directory and add your file


For instance, if you're contributing documentation for third-party tools, please add new `.md` files to the `/guides/tools/tool-configuration/` directory.

1. Submit a pull request


When submitting a pull request, please use the format `Docs: Add xxx` for the title and provide a brief description in the comment field. We'll review your submission and merge the changes if everything is in order.

## [Direct link to heading](\#getting-help)    Getting Help

If you ever get stuck or got a burning question while contributing, simply shoot your queries our way via the related GitHub issue, or hop onto our [Discord](https://discord.gg/AhzKf7dNgk) for a quick chat.

We appreciate your efforts in improving Dify's documentation!

[PreviousBecome a Contributor](/community/contribution) [NextBackend](/development/backend)

Last updated 2 months ago## [Direct link to heading](\#table-of-contents)    Table of Contents

- [Introduction](/guides/workflow/node/code#introduction)

- [Usage Scenarios](/guides/workflow/node/code#usage-scenarios)

- [Local Deployment](/guides/workflow/node/code#local-deployment)

- [Security Policies](/guides/workflow/node/code#security-policies)


## [Direct link to heading](\#introduction)    Introduction

The code node supports running Python/NodeJS code to perform data transformations within a workflow. It can simplify your workflow and is suitable for scenarios such as arithmetic operations, JSON transformations, text processing, and more.

This node significantly enhances the flexibility for developers, allowing them to embed custom Python or JavaScript scripts within the workflow and manipulate variables in ways that preset nodes cannot achieve. Through configuration options, you can specify the required input and output variables and write the corresponding execution code:

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-582917a33e0c42491743364787716dc8270facd5%252Fimage%2520%28157%29.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=25af0fbf&sv=2)

## [Direct link to heading](\#configuration)    Configuration

If you need to use variables from other nodes in the code node, you must define the variable names in the `input variables` and reference these variables. You can refer to [Variable References](https://github.com/langgenius/dify-docs/blob/main/en/guides/workflow/key-concept.md#variables).

## [Direct link to heading](\#usage-scenarios)    Usage Scenarios

Using the code node, you can perform the following common operations:

### [Direct link to heading](\#structured-data-processing)    Structured Data Processing

In workflows, you often have to deal with unstructured data processing, such as parsing, extracting, and transforming JSON strings. A typical example is data processing from an HTTP node. In common API return structures, data may be nested within multiple layers of JSON objects, and you need to extract certain fields. The code node can help you perform these operations. Here is a simple example that extracts the `data.name` field from a JSON string returned by an HTTP node:

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
def main(http_response: str) -> str:
    import json
    data = json.loads(http_response)
    return {
        # Note to declare 'result' in the output variables
        'result': data['data']['name']
    }
```

### [Direct link to heading](\#mathematical-calculations)    Mathematical Calculations

When you need to perform complex mathematical calculations in a workflow, you can also use the code node. For example, calculating a complex mathematical formula or performing some statistical analysis on data. Here is a simple example that calculates the variance of an array:

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
def main(x: list) -> float:
    return {
        # Note to declare 'result' in the output variables
        'result': sum([(i - sum(x) / len(x)) ** 2 for i in x]) / len(x)
    }
```

### [Direct link to heading](\#data-concatenation)    Data Concatenation

Sometimes, you may need to concatenate multiple data sources, such as multiple knowledge retrievals, data searches, API calls, etc. The code node can help you integrate these data sources together. Here is a simple example that merges data from two knowledge bases:

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
def main(knowledge1: list, knowledge2: list) -> list:
    return {
        # Note to declare 'result' in the output variables
        'result': knowledge1 + knowledge2
    }
```

## [Direct link to heading](\#local-deployment)    Local Deployment

If you are a local deployment user, you need to start a sandbox service to ensure that malicious code is not executed. This service requires the use of Docker. You can find specific information about the sandbox service [here](https://github.com/langgenius/dify/tree/main/docker/docker-compose.middleware.yaml). You can also start the service directly via `docker-compose`:

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
docker-compose -f docker-compose.middleware.yaml up -d
```

## [Direct link to heading](\#security-policies)    Security Policies

Both Python and JavaScript execution environments are strictly isolated (sandboxed) to ensure security. This means that developers cannot use functions that consume large amounts of system resources or may pose security risks, such as direct file system access, making network requests, or executing operating system-level commands. These limitations ensure the safe execution of the code while avoiding excessive consumption of system resources.

### [Direct link to heading](\#advanced-features)    Advanced Features

**Retry on Failure**

For some exceptions that occur in the node, it is usually sufficient to retry the node again. When the error retry function is enabled, the node will automatically retry according to the preset strategy when an error occurs. You can adjust the maximum number of retries and the interval between each retry to set the retry strategy.

- The maximum number of retries is 10

- The maximum retry interval is 5000 ms


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2F9fdd5525a91dc925b79b89272893becf.png&width=768&dpr=4&quality=100&sign=6be16b11&sv=2)

**Error Handling**

When processing information, code nodes may encounter code execution exceptions. Developers can follow these steps to configure fail branches, enabling contingency plans when nodes encounter exceptions, thus avoiding workflow interruptions.

1. Enable "Error Handling" in the code node

2. Select and configure an error handling strategy


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2F58f392734ce44b22cd8c160faf28cd14.png&width=768&dpr=4&quality=100&sign=b3d2c4cc&sv=2)

Code Error handling

For more information about exception handling approaches, please refer to [Error Handling](https://docs.dify.ai/zh-hans/guides/workflow/error-handling).

### [Direct link to heading](\#faq)    FAQ

**Why can't I save the code it in the code node?**

Please check if the code contains potentially dangerous behaviors. For example:

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
def main() -> dict:
    return {
        "result": open("/etc/passwd").read(),
    }
```

This code snippet has the following issues:

- **Unauthorized file access:** The code attempts to read the "/etc/passwd" file, which is a critical system file in Unix/Linux systems that stores user account information.

- **Sensitive information disclosure:** The "/etc/passwd" file contains important information about system users, such as usernames, user IDs, group IDs, home directory paths, etc. Direct access could lead to information leakage.


Dangerous code will be automatically blocked by Cloudflare WAF. You can check if it's been blocked by looking at the "Network" tab in your browser's "Web Developer Tools".

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2Fad4dc065c4c567c150ab7fa7bfd123a3.png&width=768&dpr=4&quality=100&sign=26fb83f5&sv=2)

Cloudflare WAF

[PreviousConditional Branch IF/ELSE](/guides/workflow/node/ifelse) [NextTemplate](/guides/workflow/node/template)

Last updated 15 days ago**概要** で本番環境におけるアプリケーションのパフォーマンスをモニタリングし、データ分析ダッシュボードで本番環境におけるアプリケーションの使用コスト、レイテンシ、ユーザーフィードバック、パフォーマンスなどの指標を分析します。継続デバッグおよびイテレーションを通じてアプリケーションを絶えず改善します。

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3244742310-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FBl3K6n12AeCkG3icHwfh%252Fuploads%252Fgit-blob-0bde3189d80bf70d7ae17acc0f114eb08a204f63%252Fimage%2520%281%29.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=8cc818d7&sv=2)

概要

[Previousアノテーション返信](/ja-jp/guides/annotation/annotation-reply) [Nextデータ分析](/ja-jp/guides/monitoring/analysis)

Last updated 6 months ago

This site uses cookies to deliver its service and to analyse traffic. By browsing this site, you accept the [privacy policy](https://dify.ai/privacy).

AcceptReject[DifySandbox](/development/backend/sandbox)

[PreviousContributing to Dify Documentation](/community/docs-contribution) [NextDifySandbox](/development/backend/sandbox)

Last updated 6 months ago

This site uses cookies to deliver its service and to analyse traffic. By browsing this site, you accept the [privacy policy](https://dify.ai/privacy).

AcceptReject在 Dify，我们采用透明化的产品特性和技术规格政策，确保你在全面了解我们产品的基础上做出决策。这种透明度不仅有利于你的技术选型，也促进了社区成员对产品的深入理解和积极贡献。

### [Direct link to heading](\#xiang-mu-ji-chu-xin-xi)    项目基础信息

项目设立

2023 年 3 月

开源协议

[基于 Apache License 2.0 有限商业许可](/zh-hans/policies/open-source)

官方研发团队

超过 15 名全职员工

社区贡献者

[超过 290 人](https://ossinsight.io/analyze/langgenius/dify) （截止 2024 Q2）

后端技术

Python/Flask/PostgreSQL

前端技术

Next.js

代码行数

超过 13 万行

发版周期

平均每周一次

### [Direct link to heading](\#ji-shu-te-xing)    技术特性

LLM 推理引擎

Dify Runtime ( 自 v0.4 起移除了 LangChain)

商业模型支持

**10+ 家**，包括 OpenAI 与 Anthropic

新的主流模型通常在 48 小时内完成接入

MaaS 供应商支持

**7 家**，Hugging Face，Replicate，AWS Bedrock，NVIDIA，GroqCloud，together.ai，OpenRouter

本地模型推理 Runtime 支持

6 **家**，Xoribits（推荐），OpenLLM，LocalAI，ChatGLM，Ollama，NVIDIA TIS

OpenAI 接口标准模型接入支持

**∞ 家**

多模态技术

ASR 模型

GPT-4o 规格的富文本模型

预置应用类型

对话型应用

文本生成应用
Agent
工作流

Prompt 即服务编排

广受好评的可视化的 Prompt 编排界面，在同一个界面中修改 Prompt 并预览效果

**编排模式**

- 简易模式编排

- Assistant 模式编排

- Flow 模式编排


**Prompt 变量类型**

- 字符串

- 单选枚举

- 外部 API

- 文件（Q3 即将推出）


Agentic Workflow 特性

行业领先的可视化流程编排界面，所见即所得的节点调试，可插拔的 DSL，原生的代码运行时，构建更复杂、可靠、稳定的 LLM 应用。

**支持节点**

- LLM

- 知识库检索

- 问题分类

- 条件分支

- 代码执行

- 模板转换

- HTTP 请求

- 工具


RAG 特性

首创的可视化的知识库管理界面，支持分段预览和召回效果测试。

**索引方式**

- 关键词

- 文本向量

- 由 LLM 辅助的问题-分段模式


**检索方式**

- 关键词

- 文本相似度匹配

- 混合检索

- N 选 1 模式（即将下线）

- 多路召回


**召回优化技术**

- 使用 ReRank 模型


ETL 技术

支持对 TXT、Markdown、PDF、HTML、DOC、CSV 等格式文件进行自动清洗，内置的 Unstructured 服务开启后可获得最大化支持。

支持同步来自 Notion 的文档为知识库。
支持同步网页为知识库。

向量数据库支持

Qdrant（推荐），Weaviate，Zilliz/Milvus，Pgvector，Pgvector-rs，Chroma，OpenSearch，TiDB，Tencent Vector，Oracle，Relyt，Analyticdb, Couchbase

Agent 技术

ReAct，Function Call

**工具支持**

- 可调用 OpenAI Plugin 标准的工具

- 可直接加载 OpenAPI Specification 的 API 作为工具


**内置工具**

- 40+ 款（截止 2024 Q2）


日志

支持，可基于日志进行标注

标注回复

基于经人类标注的 Q&A 对，可用于相似度对比回复
可导出为供模型微调环节使用的数据格式

内容审查机制

OpenAI Moderation 或外部 API

团队协同

工作空间与多成员管理支持

API 规格

RESTful，已覆盖大部分功能

部署方式

Docker，Helm

[Previous欢迎使用 Dify](/zh-hans) [Next模型供应商列表](/zh-hans/getting-started/readme/model-providers)

Last updated 1 month agoFor more detailed information, please refer to the following sections:

- [Publish as a Single-page Webapp](/guides/application-publishing/launch-your-webapp-quickly)

- [Embedding In Websites](/guides/application-publishing/embedding-in-websites)

- [Developing with APIs](/guides/application-publishing/developing-with-apis)

- [Based on Frontend Templates](/guides/application-publishing/based-on-frontend-templates)


[PreviousComfyUI](/guides/tools/tool-configuration/comfyui) [NextPublish as a Single-page Web App](/guides/application-publishing/launch-your-webapp-quickly)

Last updated 5 months agoTemplate lets you dynamically format and combine variables from previous nodes into a single text-based output using Jinja2, a powerful templating syntax for Python. It's useful for combining data from multiple sources into a specific structure required by subsequent nodes. The simple example below shows how to assemble an article by piecing together various previous outputs:

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-82b1175674b3f5bfcaf4a4b0717e35ee05e4fe51%252Fimage%2520%28158%29.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=7681ce10&sv=2)

Beyond naive use cases, you can create more complex templates as per Jinja's [documentation](https://jinja.palletsprojects.com/en/3.1.x/templates/) for a variety of tasks. Here's one template that structures retrieved chunks and their relevant metadata from a knowledge retrieval node into a formatted markdown:

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
{% for item in chunks %}
### Chunk {{ loop.index }}.
### Similarity: {{ item.metadata.score | default('N/A') }}

#### {{ item.title }}

##### Content
{{ item.content | replace('\n', '\n\n') }}

---
{% endfor %}
```

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-b744beee2aca0f019df477641aa58f8e0d85a44e%252Fimage%2520%28159%29.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=3ae012a1&sv=2)

This template node can then be used within a Chatflow to return intermediate outputs to the end user, before a LLM response is initiated.

> The `Answer` node in a Chatflow is non-terminal. It can be inserted anywhere to output responses at multiple points within the flow.

[PreviousCode Execution](/guides/workflow/node/code) [NextDoc Extractor](/guides/workflow/node/doc-extractor)

Last updated 6 months agoDify’s Knowledge feature visualizes each stage of the RAG pipeline, providing a friendly UI for application builders to easily manage personal or team knowledge. It also allows for seamless integration into AI applications.

Developers can upload internal company documents, FAQs, and standard working guides, then process them into structured data that large language models (LLMs) can query.

Compared with the static pre-trained datasets built into AI models, the content in a knowledge base can be updated in real time, ensuring LLMs always have access to the latest information and helping avoid problems caused by outdated or missing data.

When an LLM receives a user query, it first uses keywords to search within the knowledge base. Based on those keywords, the knowledge base returns content chunks with high relevance rankings, giving the LLM crucial context to generate more precise answers.

This approach ensures LLMs don’t rely solely on pre-trained knowledge. Instead, they can also draw from real-time documents and databases, enhancing both the accuracy and relevance of responses.

**Key Advantages**

**• Real-Time Updates**: The knowledge base can be updated anytime, ensuring the model always has the latest information.

• **Precision**: By retrieving relevant documents, the LLM can ground its answers in actual information, minimizing hallucinations.

• **Flexibility**: Developers can customize the knowledge base content to match specific needs, defining the scope of knowledge as required.

* * *

You only need to prepare text content, such as:

- Long text content (TXT, Markdown, DOCX, HTML, JSONL, or even PDF files)

- Structured data (CSV, Excel, etc.)

- Online data source(Web pages, Notion, etc.)


By simply uploading files to the **Knowledge Base**, data processing is handled automatically.

> If your team already has an independent knowledge base, you can use the [“Connect to an External Knowledge Base”](/guides/knowledge-base/connect-external-knowledge) feature to establish its connection with Dify.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2Feffc826d2584d5f2983cdcd746099bb6.png&width=768&dpr=4&quality=100&sign=cf0821c6&sv=2)

Create a knowledge base

### [Direct link to heading](\#use-case)    **Use Case**

If you want to create an AI customer support assistant based on your existing knowledge base and product documentation, you can simply upload those files to the Knowledge Base in Dify, then set up a conversational application.

Traditionally, going from raw text training to a fully developed AI customer support chatbot could take weeks, plus it’s challenging to maintain and iterate effectively.

In Dify, the entire process takes just three minutes, after which you can immediately begin gathering user feedback.

### [Direct link to heading](\#knowledge-base-and-documents)    Knowledge Base and Documents

In Dify, a Knowledge Base is a collection of Documents, each of which can include multiple Chunks of content. You can integrate an entire knowledge base into an application to serve as a retrieval context, drawing from uploaded files or data synchronized from other sources.

If your team already has an independent, external knowledge that is separate from the Dify platform, you can link it using the [External Knowledge Base](/guides/knowledge-base/external-knowledge-api-documentation) feature. This way, you don’t need to re-upload all your content to Dify. Your AI app can directly access and process information in real time from your team’s existing knowledge.

[PreviousBulletin: Image Upload Replaced by File Upload](/guides/workflow/bulletin) [NextCreate Knowledge](/guides/knowledge-base/create-knowledge-and-upload-documents)

Last updated 5 days agoPlease ensure that your application complies with local regulations when collecting user data. The common practice is to publish a privacy policy and obtain user consent.

The **Logs** feature is designed to observe and annotate the performance of Dify applications. Dify records logs for all interactions with the application, whether through the WebApp or API. If you are a Prompt Engineer or LLM operator, it will provide you with a visual experience of LLM application operations.

### [Direct link to heading](\#using-the-logs-console)    Using the Logs Console

You can find the Logs in the left navigation of the application. This page typically displays:

- Interaction records between users and AI within the selected timeframe

- The results of user input and AI output, which for conversational applications are usually a series of message flows

- Ratings from users and operators, as well as improvement annotations from operators


The logs currently do not include interaction records from the Prompt debugging process.

> For the Free tier teams, interaction logs are only retained for the last 30 days. To keep interaction history for a longer period, please visit our [pricing page](https://dify.ai/pricing) to upgrade to a higher tier or consider deploying the [Community Edition](https://docs.dify.ai/getting-started/install-self-hosted/docker-compose).

### [Direct link to heading](\#improvement-annotations)    Improvement Annotations

These annotations will be used for model fine-tuning in future versions of Dify to improve model accuracy and response style. The current preview version only supports annotations.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-a953bd82f3d5b9559d6d524150fb3c26e69527b3%252Fapp-logs-ann.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=83d45205&sv=2)

Mark logs to improve your app

Clicking on a log entry will open the log details panel on the right side of the interface. In this panel, operators can annotate an interaction:

- Give a thumbs up for well-performing messages

- Give a thumbs down for poorly-performing messages

- Mark improved responses for improvement, which represents the text you expect AI to reply with


Please note that if multiple administrators in the team annotate the same log entry, the last annotation will overwrite the previous ones.

[PreviousAnnotation](/guides/annotation) [NextAnnotation Reply](/guides/annotation/annotation-reply)

Last updated 1 month ago### [Direct link to heading](\#definition)    Definition

Sequentially performs the same operations on array elements until all results are outputted, functioning as a task batch processor. Iteration nodes typically work in conjunction with array variables.

For example, when processing long text translations, inputting all content directly into an LLM node may reach the single conversation limit. To address the issue, upstream nodes first split the long text into multiple chunks, then use iteration nodes to perform batch translations, thus avoiding the message limit of a single LLM conversation.

* * *

### [Direct link to heading](\#functional-description)    Functional Description

Using iteration nodes requires input values to be formatted as list objects. The node sequentially processes all elements in the array variable from the iteration start node, applying identical processing steps to each element. Each processing cycle is called an iteration, culminating in the final output.

An iteration node consists of three core components: **Input Variables**, **Iteration Workflow**, and **Output Variables**.

**Input Variables:** Accepts only Array type data.

**Iteration Workflow:** Supports multiple workflow nodes to orchestrate task sequences within the iteration node.

**Output Variables:** Outputs only array variables ( `Array[List]`).

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2F7c94bccbb6f8dc4570c69c2bf02ec6d3.png&width=768&dpr=4&quality=100&sign=23a61719&sv=2)

Iteration Node Functional Description

### [Direct link to heading](\#scenarios)    Scenarios

#### [Direct link to heading](\#example-1-long-article-iteration-generator)    **Example 1: Long Article Iteration Generator**

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-4ff1cbe66c16e44c7168fce414085b5021bc7b9c%252Flong-article-iteration-generator.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=a6831e9a&sv=2)

Long Story Generator

1. Enter the story title and outline in the **Start Node**.

2. Use a **Generate Subtitles and Outlines Node** to use LLM to generate the complete content from user input.

3. Use a **Extract Subtitles and Outlines Node** to convert the complete content into an array format.

4. Use an **Iteration Node** to wrap an **LLM Node** and generate content for each chapter through multiple iterations.

5. Add a **Direct Answer Node** inside the iteration node to achieve streaming output after each iteration.


**Detailed Configuration Steps**

1. Configure the story title (title) and outline (outline) in the **Start Node**.


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-f9819f11ed931ee6cf74bbf85df1a22da2c04fd1%252Fworkflow-start-node.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=2a8044b0&sv=2)

Start Node Configuration

1. Use a **Generate Subtitles and Outlines Node** to convert the story title and outline into complete text.


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-390e0f88301b832fb11c8d534f18f4850bc6d211%252Fworkflow-generate-subtitles-node.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=860cae5c&sv=2)

Template Node

1. Use a **Extract Subtitles and Outlines Node** to convert the story text into an array (Array) structure. The parameter to extract is `sections`, and the parameter type is `Array[Object]`.


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-930166a9ba9041b59f6b22ef1137eaa3301d4e0b%252Fworkflow-extract-subtitles-and-outlines.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=7e0ba131&sv=2)

Parameter Extraction

The effectiveness of parameter extraction is influenced by the model's inference capability and the instructions given. Using a model with stronger inference capabilities and adding examples in the **instructions** can improve the parameter extraction results.

1. Use the array-formatted story outline as the input for the iteration node and process it within the iteration node using an **LLM Node**.


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-54a0b37ac2bdd5add56739430086b281cfe021bd%252Fworkflow-iteration-node.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=92947bf&sv=2)

Configure Iteration Node

Configure the input variables `GenerateOverallOutline/output` and `Iteration/item` in the LLM Node.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-acc87730b85cc652067e8ea7ed240952c37a985d%252Fworkflow-iteration-llm-node.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=6324fbfa&sv=2)

Configure LLM Node

Built-in variables for iteration: `items[object]` and `index[number]`.

`items[object]` represents the input item for each iteration;

`index[number]` represents the current iteration round;

1. Configure a **Direct Reply Node** inside the iteration node to achieve streaming output after each iteration.


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-b38114ca0d883bda5cc89452d730eef4a70a2b59%252Fworkflow-configure-anwer-node.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=ba8bdfe0&sv=2)

Configure Answer Node

1. Complete debugging and preview.


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-d399a244499d45f67d2121deed024466d7b8c567%252Fiteration-node-iteration-through-story-chapters.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=7fd7aa97&sv=2)

Generate by Iterating Through Story Chapters

#### [Direct link to heading](\#example-2-long-article-iteration-generator-another-arrangement)    **Example 2: Long Article Iteration Generator (Another Arrangement)**

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-3041cfafec653cadf77b204402509d578d92fcd2%252Fiteration-node-iteration-long-article-iteration-generator.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=fea99134&sv=2)

- Enter the story title and outline in the **Start Node**.

- Use an **LLM Node** to generate subheadings and corresponding content for the article.

- Use a **Code Node** to convert the complete content into an array format.

- Use an **Iteration Node** to wrap an **LLM Node** and generate content for each chapter through multiple iterations.

- Use a **Template Conversion** Node to convert the string array output from the iteration node back to a string.

- Finally, add a **Direct Reply Node** to directly output the converted string.


* * *

### [Direct link to heading](\#advanced-feature)    Advanced Feature

#### [Direct link to heading](\#parallel-mode)    Parallel Mode

The iteration node supports parallel processing, improving execution efficiency when enabled.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2F516af5e7427fce9a58fa9d9b583230d4.png&width=768&dpr=4&quality=100&sign=a008f7ff&sv=2)

Enable parallel mode

Below illustrates the comparison between parallel and sequential execution in the iteration node.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2F2656dec26d6357556a280fcd69ccd9a7.png&width=768&dpr=4&quality=100&sign=d8310675&sv=2)

Sequential and Parallel Processing Flow Diagram

Parallel mode supports up to 10 concurrent iterations. When processing more than 10 tasks, the first 10 elements execute simultaneously, with remaining tasks processed after the completion of the initial batch.

Avoid placing Direct Answer, Variable Assignment, or Tool nodes within the iteration node to prevent potential errors.

- **Error response method**


Iteration nodes process multiple tasks and may encounter errors during element processing. To prevent a single error from interrupting all tasks, configure the **Error Response Method**:

- **Terminated**: Terminates the iteration node and outputs error messages when an exception is detected.

- **Continue on error**: Ignores error messages and continues processing remaining elements. The output contains successful results with null values for errors.

- **Remove abnormal output**: Ignores error messages and continues processing remaining elements. The output contains only successful results.


Input and output variables maintain a one-to-one correspondence. For example:

- Input: \[1, 2, 3\]

- Output: \[result-1, result-2, result-3\]


Error handling examples:

- With **Continue on error**: \[result-1, null, result-3\]

- With **Remove abnormal output**: \[result-1, result-3\]


* * *

### [Direct link to heading](\#reference)    Reference

#### [Direct link to heading](\#how-to-obtain-array-formatted-content)    How to Obtain Array-Formatted Content

Array variables can be generated via the following nodes as iteration node inputs:

- [Code Node](/guides/workflow/node/code)


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-930166a9ba9041b59f6b22ef1137eaa3301d4e0b%252Fworkflow-extract-subtitles-and-outlines.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=7e0ba131&sv=2)

Parameter Extraction

- [Parameter Extraction](/guides/workflow/node/parameter-extractor)


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-aca2692b232e7b3d0217396a7a15c438c5d78131%252Fworkflow-parameter-extraction-node.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=dc7f84fb&sv=2)

Parameter Extraction

- [Knowledge Base Retrieval](/guides/workflow/node/knowledge-retrieval)

- [Iteration](/guides/workflow/node/iteration)

- [Tools](/guides/workflow/node/tools)

- [HTTP Request](/guides/workflow/node/http-request)


* * *

#### [Direct link to heading](\#how-to-convert-an-array-to-text)    How to Convert an Array to Text

The output variable of the iteration node is in array format and cannot be directly output. You can use a simple step to convert the array back to text.

**Convert Using a Code Node**

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-380d133e7e75533e799b85e77716b8471a9c8daa%252Fiteration-code-node-convert.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=fed5ec05&sv=2)

Code Node Conversion

CODE Example:

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
def main(articleSections: list):
    data = articleSections
    return {
        "result": "/n".join(data)
    }
```

**Convert Using a Template Node**

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-2eac11bc0afe09746661444a57c50b3cefdfe33d%252Fworkflow-template-node.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=ae5cd8fd&sv=2)

Template Node Conversion

CODE Example:

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
{{ articleSections | join("/n") }}
```

[PreviousVariable Assigner](/guides/workflow/node/variable-assigner) [NextParameter Extraction](/guides/workflow/node/parameter-extractor)

Last updated 1 month ago工作流应用通常包含多个节点。如果因为某个节点的异常（例如 API 请求异常或 LLM 输出异常）而造成整个流程的运行失败，会迫使应用开发者不得不花费大量的精力排查故障并修复，这在复杂的工作流应用中尤为困难。

**异常处理机制** 提供多样化的节点错误处理策略，能够在发生局部节点错误时抛出故障信息而不中断主流程。你可以设置出现异常时重新执行节点，或通过备用路径继续任务。为关键节点 **添加异常处理机制将极大地增强应用整体的灵活性与稳健性。**

> 同时开启 **错误重试** 和 **异常处理** 功能时，将优先重试运行节点。若重试后仍然失败，再启用异常处理机制。

开发者无需在节点内编排复杂的逻辑代码或额外的节点应对错误情况。异常处理机制将简化工作流的设计复杂度，以多样的预设策略编排工作流的执行逻辑。

![](https://www.gitbook.com/cdn-cgi/image/width=256,format=auto/https%3A%2F%2Ffiles.gitbook.com%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fintegrations%252Farcade%252Ficon%252F7TEQUDaaKQX5t9WlliuF%252Ficon.png%3Falt%3Dmedia)

Arcade

### [Direct link to heading](\#ying-yong-chang-jing)    应用场景

**1\. 网络异常处理**

示例：在某个工作流中需要通过三个 API 服务（例如天气服务、新闻摘要和社交媒体分析）获取数据并汇总。然而，其中一个服务因请求限制无法响应，导致数据获取失败。通过异常处理功能，主流程将继续处理其它两个成功的数据源，同时记录失败的 API 调用错误日志，供开发者稍后分析并优化服务调用策略。

**2\. 工作流备用设计**

示例：某个 LLM 节点执行生成详细文档摘要任务，但因输入的篇幅过长而触发超出 Token 限制的异常。在节点中配置异常错误机制后，出现此类错误时，可以使用备用路径中的代码节点协助将内容切分为多个小段并重新调用 LLM 节点，避免流程中断。

**3\. 异常信息预定义**

示例：运行工作流时可能会遇到某个节点返回模糊的错误信息（例如简单的“调用失败”），难以快速定位问题。开发者可以通过异常处理机制内编写预定义报错信息，为后续的应用调试提供更加清晰、准确的错误信息。

### [Direct link to heading](\#yi-chang-chu-li-ji-zhi)    异常处理机制

以下四个类型的节点新增异常处理机制，点击标题即可阅读详细文档：

- [LLM](/zh-hans/guides/workflow/node/llm)

- [HTTP](/zh-hans/guides/workflow/node/http-request)

- [代码](/zh-hans/guides/workflow/node/code)

- [工具](/zh-hans/guides/workflow/node/tools)


**异常重试**

部分异常可以通过重新运行节点解决，此时可以在节点内开启 **“异常重试”** 功能，设置尝试次数与重试间隔时间。

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2F18097e4c94b67a79150b967fc50f9f43.png&width=768&dpr=4&quality=100&sign=5bbe2be9&sv=2)

如果尝试重试运行节点后依然报错，将按照异常处理机制中的预设策略运行接下来的流程。

**异常处理**

异常处理机制提供以下三种选项：

• **无**：不处理异常，直接抛出节点的报错信息并中断整体流程。

• **默认值**：允许开发者预定义异常信息。异常发生后，使用预定义的值替代原节点内置的异常输出信息。

• **异常分支**：发生异常后，执行预编排的异常分支

如需了解各个策略的说明和配置方法，请参考 [预定义异常处理逻辑](/zh-hans/guides/workflow/error-handling/predefined-nodes-failure-logic)。

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2F6e2655949889d4d162945d840d698649.png&width=768&dpr=4&quality=100&sign=5c5b26ea&sv=2)

Error handling

### [Direct link to heading](\#kuai-su-kai-shi)    快速开始

#### [Direct link to heading](\#chang-jing-wei-gong-zuo-liu-ying-yong-tian-jia-ying-dui-cuo-wu-shu-chu-dai-ma-de-chu-li-ji-zhi)    场景：为工作流应用添加应对错误输出代码的处理机制

下文将以一个简单的示例应用，演示如何在工作流应用内增设异常处理机制，以备用分支应对节点异常。

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2F958326384d3b60a98246e9ff565c7ed3.png&width=768&dpr=4&quality=100&sign=29cf0f50&sv=2)

**应用逻辑**： LLM 节点根据输入的指令，生成正确或错误格式的 JSON 代码内容，然后通过 A 代码节点执行代码并输出结果。如果 A 代码节点接收到了错误格式的 JSON 内容，则按照预设的异常处理机制，执行备用路径而继续主流程。

#### [Direct link to heading](\#id-1.-chuang-jian-json-dai-ma-sheng-cheng-jie-dian)    1\. 创建 JSON 代码生成节点

新建 Workflow 应用，并添加 LLM 节点和代码节点。通过 Prompt 让 LLM 根据指令生成正确或错误格式的 JSON 内容，然后通过 A 代码节点验证。

**LLM 节点内的 Prompt 参考：**

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
You are a teaching assistant. According to the user's requirements, you only output a correct or incorrect sample code in json format.
```

**代码节点中的 JSON 验证代码：**

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
def main(json_str: str) -> dict:
    obj = json.loads(json_str)
    return {'result': obj}
```

#### [Direct link to heading](\#id-2.-wei-a-dai-ma-jie-dian-tian-jia-yi-chang-chu-li-ji-zhi)    2\. 为 A 代码节点添加异常处理机制

A 代码节点是验证 JSON 内容的节点，如果接收到的 JSON 内容格式错误，需要通过异常处理机制运行备用路径，让下一个 LLM 节点修复错误内容并重新验证 JSON 从而继续主流程。在 A 代码节点的“异常处理”选项卡中，选择“异常分支”并新建 LLM 节点。

![](https://www.gitbook.com/cdn-cgi/image/width=256,format=auto/https%3A%2F%2Ffiles.gitbook.com%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fintegrations%252Farcade%252Ficon%252F7TEQUDaaKQX5t9WlliuF%252Ficon.png%3Falt%3Dmedia)

Arcade

#### [Direct link to heading](\#id-3.-xiu-zheng-a-dai-ma-jie-dian-shu-chu-de-yi-chang-nei-rong)    3\. 修正 A 代码节点输出的异常内容

在新的 LLM 节点中，填写 Prompt 并通过变量引用 A 代码节点的异常输出内容，并进行修复。添加 B 代码节点对 JSON 内容进行二次验证。

#### [Direct link to heading](\#id-4.-jie-shu)    4\. 结束

添加变量聚合节点，汇总正确和错误分支的处理结果并输出至结束节点内，完成整体流程。

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2F059b5a814514cd9abe10f1f4077ed17f.png&width=768&dpr=4&quality=100&sign=98b36ab7&sv=2)

> Demo 应用 DSL 文件 [下载地址](https://assets-docs.dify.ai/2024/12/087861aa20e06bb4f8a2bef7e7ae0522.yml)。

### [Direct link to heading](\#zhuang-tai-miao-shu)    状态描述

状态指的是节点状态与流程状态。清晰的状态说明有助于开发者判断当前工作流应用的运行现状，协助进行问题排查，快速了解信息并做出对应决策。引入异常处理机制后，节点状态和流程存在以下状态：

#### [Direct link to heading](\#jie-dian-zhuang-tai)    **节点状态**

- **成功**



节点正常执行，并正确输出信息。

- **失败**



未启用异常处理，节点执行失败，输出报错信息。

- **异常**



在异常处理机制中启用了 **默认值** 或 **异常分支** 选项。节点执行时遇到了错误，但启用异常机制应对错误。


#### [Direct link to heading](\#gong-zuo-liu-zhuang-tai)    工作流状态

- **成功**



流程中的所有节点正常执行，结束节点能够正确输出信息，状态被标记为 Success。

- **失败**



因出现节点异常，整体流程被中断，状态被标记为 Failed。

- **局部成功**



节点出现异常，但启用了异常处理机制，整体流程最终运行正常。状态将会被标记为 Partial success。


### [Direct link to heading](\#chang-jian-wen-ti)    常见问题

#### [Direct link to heading](\#id-1.-qi-yong-yi-chang-chu-li-ji-zhi-qian-hou-de-qu-bie-shi-shen-me)    1\. 启用异常处理机制前后的区别是什么？

#### [Direct link to heading](\#mei-you-cuo-wu-chu-li-ji-zhi-shi)    **没有错误处理机制时：**

- **节点错误中断流程**：当 LLM 调用失败、网络出现问题或工具出错时，整个工作流程会立即中断，应用开发者需要手动查找并修复错误后重新运行流程。

- **缺乏灵活性**：开发者无法对不同错误类型或节点定义特定的处理逻辑。例如，无法在错误发生时继续后续流程或选择替代路径。

- **手动添加冗余节点**：避免错误影响全局需要额外设计大量节点来捕获和处理错误，增加了工作流程的复杂性和开发成本。

- **日志信息有限**：错误日志通常简单或不足，无法快速诊断问题。


**启用异常处理机制后：**

- **流程不中断**：即使某个节点发生错误，工作流程可以根据用户定义的规则继续运行，减少因单点失败导致的全局影响。

- **灵活自定义错误处理**：应用开发者可以为每个节点指定错误处理策略，如继续流程、记录日志，或切换到替代路径。

- **简化工作流程设计**：通用错误处理器减少了用户手动设计冗余节点的需求，流程更清晰简洁。

- **详细错误日志支持**：提供错误信息的自定义编排机制，便于开发者快速排查问题和优化流程。


* * *

#### [Direct link to heading](\#id-2.-ru-he-tiao-shi-ti-dai-lu-jing-de-zhi-hang-qing-kuang)    2\. 如何调试替代路径的执行情况？

你可以通过工作流程的运行日志检查条件判断和路径选择情况。异常分支的运行路线以黄色高亮显示，帮助开发者验证替代路径是否按预期执行。

[Previous文件上传](/zh-hans/guides/workflow/file-upload) [Next预定义异常处理逻辑](/zh-hans/guides/workflow/error-handling/predefined-nodes-failure-logic)

Last updated 15 days ago[LiteLLM Proxy](https://github.com/BerriAI/litellm) is a proxy server that allows:

- Calling 100+ LLMs (OpenAI, Azure, Vertex, Bedrock) in the OpenAI format

- Using Virtual Keys to set Budgets, Rate limits and track usage


Dify supports integrating LLM and Text Embedding capabilities models available on LiteLLM Proxy

## [Direct link to heading](\#quick-integration)    Quick Integration

### [Direct link to heading](\#step-1.-start-litellm-proxy-server)    Step 1. Start LiteLLM Proxy Server

LiteLLM Requires a config with all your models defined - we will call this file `litellm_config.yaml`

[Detailed docs on how to setup litellm config - here](https://docs.litellm.ai/docs/proxy/configs)

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
model_list:
  - model_name: gpt-4
    litellm_params:
      model: azure/chatgpt-v-2
      api_base: https://openai-gpt-4-test-v-1.openai.azure.com/
      api_version: "2023-05-15"
      api_key:
  - model_name: gpt-4
    litellm_params:
      model: azure/gpt-4
      api_key:
      api_base: https://openai-gpt-4-test-v-2.openai.azure.com/
  - model_name: gpt-4
    litellm_params:
      model: azure/gpt-4
      api_key:
      api_base: https://openai-gpt-4-test-v-2.openai.azure.com/
```

### [Direct link to heading](\#step-2.-start-litellm-proxy)    Step 2. Start LiteLLM Proxy

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
docker run \
    -v $(pwd)/litellm_config.yaml:/app/config.yaml \
    -p 4000:4000 \
    ghcr.io/berriai/litellm:main-latest \
    --config /app/config.yaml --detailed_debug
```

On success, the proxy will start running on `http://localhost:4000`

### [Direct link to heading](\#step-3.-integrate-litellm-proxy-in-dify)    Step 3. Integrate LiteLLM Proxy in Dify

In `Settings > Model Providers > OpenAI-API-compatible`, fill in:

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252F2RFMWlKKNvyIvhzPMpcY%252Fimage.png%3Falt%3Dmedia%26token%3Dbd3bb7b4-66e3-48d7-abd9-609ed5dc1bf3&width=768&dpr=4&quality=100&sign=371f7aa8&sv=2)

- Model Name: `gpt-4`

- Base URL: `http://localhost:4000`



Enter the base URL where the LiteLLM service is accessible.

- Model Type: `Chat`

- Model Context Length: `4096`



The maximum context length of the model. If unsure, use the default value of 4096.

- Maximum Token Limit: `4096`



The maximum number of tokens returned by the model. If there are no specific requirements for the model, this can be consistent with the model context length.

- Support for Vision: `Yes`



Check this option if the model supports image understanding (multimodal), like `gpt4-o`.


Click "Save" to use the model in the application after verifying that there are no errors.

The integration method for Embedding models is similar to LLM, just change the model type to Text Embedding.

## [Direct link to heading](\#more-information)    More Information

For more information on LiteLLM, please refer to:

- [LiteLLM](https://github.com/BerriAI/litellm)

- [LiteLLM Proxy Server](https://docs.litellm.ai/docs/simple_proxy)


[PreviousIntegrate Local Models Deployed by Ollama](/development/models-integration/ollama) [NextIntegrating with GPUStack for Local Model Deployment](/development/models-integration/gpustack)

Last updated 2 months agoDifyでは、製品の仕様に関する透明性の高いポリシーを採用しています。これにより、製品を十分に理解した上で意思決定を行うことができます。この透明性は、技術選定に役立つだけでなく、コミュニティのメンバーが製品をより深く理解し、積極的に貢献することを促進します。

### [Direct link to heading](\#purojekutono)    プロジェクトの基本情報

プロジェクト設立

2023年3月

オープンソースライセンス

[Apache License 2.0（商用ライセンスあり）](/ja-jp/policies/open-source)

公式開発チーム

15名以上のフルタイム従業員

コミュニティ貢献者

[290人以上(2024年Q2時点)](https://ossinsight.io/analyze/langgenius/dify)

バックエンド技術

Python / Flask / PostgreSQL

フロントエンド技術

Next.js

コードベースサイズ

13万行以上

リリース頻度

平均週1回

### [Direct link to heading](\#ji-shu-te-zhi)    技術特徴

LLM推論エンジン

Dify Runtime（v0.4以降、LangChainを除去）

商用モデル対応

**10社以上**（OpenAIとAnthropicを含む）

新しい主要モデルは通常48時間以内に対応

MaaSベンダー対応

**7社**（Hugging Face、Replicate、AWS Bedrock、NVIDIA、GroqCloud、together.ai、OpenRouter）

ローカルモデル対応

6 **社**（Xoribits\[推奨\]、OpenLLM、LocalAI、ChatGLM、Ollama、NVIDIA TIS）

OpenAIインターフェース標準モデル統合

**∞**

マルチモーダル機能

音声認識（ASR）モデル

GPT-4o水準のリッチテキストモデル

内製アプリタイプ

チャットボット、チャットフロー、テキスト生成、エージェント、ワークフロー

Prompt-as-a-Serviceオーケストレーション

高評価のビジュアルオーケストレーションインターフェース、プロンプトの編集と効果のプレビューを一箇所で実行可能

**オーケストレーションモード**

- シンプルオーケストレーション

- アシスタントオーケストレーション

- フローオーケストレーション


**プロンプト変数タイプ**

- 文字列

- ラジオボタン列挙型

- 外部API

- ファイル（2024年Q3にリリース予定）


エージェント型ワークフロー機能

業界をリードするビジュアルワークフローオーケストレーションインターフェース、ノードデバッグはライブ編集可能、モジュール式DSL、ネイティブコードランタイムを提供。より複雑で信頼性が高く安定したLLMアプリケーションの構築に対応

**利用可能なノード**

- LLM

- 知識取得

- 質問分類器

- 条件分岐

- コード実行

- テンプレート

- HTTPリクエスト

- ツール


RAG機能

ビジュアル化された画期的なナレッジベース管理インターフェースを提供。チャンクのプレビューやリコールテストをサポート

**インデックス方式**

- キーワード

- テキストベクトル

- LLMによるQ&Aセグメント化


**検索方式**

- キーワード

- テキスト類似度マッチング

- ハイブリッド検索

- N選択1（レガシー）

- マルチパス探索


**回答精度の最適化**

- ReRankモデルを使用


ETL技術

TXT、MARKDOWN、PDF、HTML、XLSX、XLS、DOCX、CSV形式の自動的クリーニングをサポート。Unstructuredのサービスによる最大限のサポートを実現

- Notionのドキュメントをナレッジベースとして同期可能


- ウェブページをナレッジベースとして同期可能


対応ベクトルデータベース

Qdrant（推奨）、Weaviate、Zilliz/Milvus、Pgvector、Pgvector-rs、Chroma、OpenSearch、TiDB、Tencent Vector、Oracle、Relyt、Analyticdb, Couchbase

エージェント技術

ReAct、Function Call

**ツールサポート**

- OpenAIプラグイン標準のツールを呼び出し可能

- OpenAPI Specification APIを直接ツールとしてロード可能


**内蔵ツール**

- 40種類以上（2024年Q2時点）


ログ機能

あり、ログに基づくアノテーション

アノテーション返答

人間がアノテーションしたQ&Aペアに基づく類似度ベースの返答
モデルのファインチューニング用データ形式としてエクスポート可能

コンテンツモデレーション

OpenAI Moderationまたは外部API

チームコラボレーション

ワークスペース、複数メンバー管理

API仕様

RESTful、ほとんどの機能をカバー

デプロイ方法

Docker、Helm

[PreviousDifyへようこそ](/ja-jp) [Nextモデルプロバイダーリスト](/ja-jp/getting-started/readme/model-providers)

Last updated 1 month ago相较于聊天文本，文档文件能够承载大量的信息，例如学术报告、法律合同。受限于 LLM 自身仅能够支持文件或图片，难以获取文件内更加丰富的上下文信息，应用的使用者不得不手动复制粘贴大量信息与 LLM 对话，增加了许多不必要的使用成本。

文件上传功能允许将文件以 File variables 的形式在工作流应用中上传、解析、引用、和下载。 **开发者现可轻松构建能理解和处理图片、音频、视频的复杂工作。**

### [Direct link to heading](https://docs.dify.ai/zh-hans/guides/workflow/file-upload\#ying-yong-chang-jing)    应用场景

1. **文档分析**: 上传学术研究报告文件，LLM 可以快速总结要点，根据文件内容回答相关问题。

2. **代码审查**: 开发者上传代码文件，获得优化建议与 bug 检测。

3. **学习辅导**: 学生上传作业或学习资料，获得个性化的解释和指导。

4. **法律援助**: 上传完整的合同文本，由 LLM 协助审查条款，指出潜在风险。


### [Direct link to heading](https://docs.dify.ai/zh-hans/guides/workflow/file-upload\#wen-jian-shang-chuan-yu-zhi-shi-ku-de-qu-bie)    文件上传与知识库的区别

文件上传和知识库都是为 LLM 提供额外上下文信息的方式，但它们在使用场景和功能上有明显区别：

1. **信息来源**：



- 文件上传：允许终端用户在对话过程中动态上传文件，提供即时的、个性化的上下文信息。

- 知识库：由应用开发者预先设置和管理，包含相对固定的信息集合。


2. **使用灵活性**：



- 文件上传：更加灵活，用户可以根据具体需求上传不同类型的文件。

- 知识库：内容相对固定，但可以被多个会话重复利用。


3. **信息处理**：



- 文件上传：需要通过文档提取器或其他工具将文件内容转换为 LLM 可理解的文本。

- 知识库：通常已经过预处理和索引，可以直接进行检索。


4. **应用场景**：



- 文件上传：适用于需要处理用户特定文档的场景，如文档分析、个性化学习辅导等。

- 知识库：适用于需要访问大量预设信息的场景，如客户服务、产品咨询等。


5. **数据持久性**：



- 文件上传：通常为临时使用，不会长期存储在系统中。

- 知识库：作为应用的一部分长期存在，可以持续更新和维护。


### [Direct link to heading](https://docs.dify.ai/zh-hans/guides/workflow/file-upload\#kuai-su-kai-shi-da-jian-ju-bei-wen-jian-shang-chuan-gong-neng-de-gong-zuo-liu-ying-yong)    快速开始：搭建具备文件上传功能的工作流应用

Dify 支持在 [ChatFlow](https://docs.dify.ai/zh-hans/guides/workflow/key-concept#chatflow-he-workflow) 和 [WorkFlow](https://docs.dify.ai/zh-hans/guides/workflow/key-concept#chatflow-he-workflow) 类型应用中上传文件，并通过 [变量](https://docs.dify.ai/zh-hans/guides/workflow/variables) 交由 LLM 处理。应用开发者可以参考以下方法为应用开启文件上传功能：

- 在 Workflow 应用中：



- 在 ["开始节点"](https://docs.dify.ai/zh-hans/guides/workflow/node/start) 添加文件变量


- 在 ChatFlow 应用中：



- 在 ["附加功能"](https://docs.dify.ai/zh-hans/guides/workflow/additional-features) 中开启文件上传，允许在聊天窗中直接上传文件

- 在 ["开始节点"](https://docs.dify.ai/zh-hans/guides/workflow/node/start) 添加文件变量

- 注意：这两种方法可以同时配置，它们是彼此独立的。附加功能中的文件上传设置（包括上传方式和数量限制）不会影响开始节点中的文件变量。例如只想通过开始节点创建文件变量，则无需开启附加功能中的文件上传功能。


这两种方法为应用提供了灵活的文件上传选项，以满足不同场景的需求。

#### [Direct link to heading](https://docs.dify.ai/zh-hans/guides/workflow/file-upload\#file-types)    File Types

file variables 和 array\[file\] variables 支持以下文件类型与格式：

文件类型

支持格式

文档

TXT, MARKDOWN, PDF, HTML, XLSX, XLS, DOCX, CSV, EML, MSG, PPTX, PPT, XML, EPUB.

图片

JPG, JPEG, PNG, GIF, WEBP, SVG.

音频

MP3, M4A, WAV, WEBM, AMR.

视频

MP4, MOV, MPEG, MPGA.

其他

自定义后缀名支持

#### [Direct link to heading](https://docs.dify.ai/zh-hans/guides/workflow/file-upload\#fang-fa-yi-shi-yong-ju-bei-shi-bie-wen-jian-de-llm)    方法一：使用具备识别文件的 LLM

部分 LLMs（例如 [Claude 3.5 Sonnet](https://docs.anthropic.com/en/docs/build-with-claude/pdf-support)）已支持直接处理并分析文件内容，因此 LLM 节点的提示词已允许输入文件变量。

> 为了避免潜在异常，应用开发者在使用该文件变量前需前往 LLM 官网确认 LLM 支持何种文件类型。

1. 点击创建 Chatflow / Workflow 应用。

2. 添加 LLM 节点，选择具备文件分析能力的 LLM。

3. 在开始节点添加文件变量

4. 在 LLM 的系统提示词内输入文件变量。

5. 完成创建。


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F11%2Fa7154e8966d979dcba13eac0a172ef89.png&width=768&dpr=4&quality=100&sign=454fcb45&sv=2)

#### [Direct link to heading](https://docs.dify.ai/zh-hans/guides/workflow/file-upload\#fang-fa-er-zai-ying-yong-liao-tian-kuang-zhong-kai-qi-wen-jian-shang-chuan-jin-shi-yong-yu-chatflow)    方法二：在应用聊天框中开启文件上传（仅适用于 Chatflow）

1. 点击 Chatflow 应用右上角的 **“功能”** 按钮即可为应用添加更多功能。



开启此功能后，应用使用者可以在应用对话的过程中随时上传并更新文件。最多支持同时上传 10 个文件，每个文件的大小上限为 15MB。


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F1288284732-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FCdDIVDY6AtAz028MFT4d%252Fuploads%252FD4Z3ehlFIWNyfCbthzqr%252Fimage.png%3Falt%3Dmedia%26token%3D23156231-93af-47db-a801-3bd10d2e6a7c&width=768&dpr=4&quality=100&sign=d3563ad6&sv=2)

文件上传功能

开启该功能并不意味着赋予 LLM 直接读取文件的能力，还需要配备 [**文档提取器**](https://docs.dify.ai/zh-hans/guides/workflow/node/doc-extractor) 将文档解析为文本供 LLM 理解。

- 对于音频文件，可以使用 `gpt-4o-audio-preview` 等支持多模态输入的模型直接处理音频，无需额外的提取器。

- 对于视频和其他文件类型，暂无对应的提取器，需要应用开发者接入 [外部工具](https://docs.dify.ai/zh-hans/guides/tools/advanced-tool-integration) 进行处理


1. 添加 [文档提取器](https://docs.dify.ai/zh-hans/guides/workflow/node/doc-extractor) 节点，在输入变量中选中 `sys.files` 变量。

2. 添加 LLM 节点，在系统提示词中选中文档提取器节点的输出变量。

3. 在末尾添加 “直接回复” 节点，填写 LLM 节点的输出变量。


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F1288284732-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FCdDIVDY6AtAz028MFT4d%252Fuploads%252FAnbtFAUiukKuXT9nHI2Z%252Fimage.png%3Falt%3Dmedia%26token%3D453f6500-2aed-44c6-a1d6-47ebda17f394&width=768&dpr=4&quality=100&sign=54f0d063&sv=2)

开启后，用户可以在对话框中上传文件并进行对话。但通过此方式， LLM 应用并不具备记忆文件内容的能力，每次对话时需要上传文件。

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F1288284732-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FCdDIVDY6AtAz028MFT4d%252Fuploads%252FJmXZnOpUGR9mT6oBMs5d%252Fimage.png%3Falt%3Dmedia%26token%3Da33759c1-d3c2-43af-aed0-94978d64ad98&width=768&dpr=4&quality=100&sign=a1ad852d&sv=2)

若希望 LLM 能够在对话中记忆文件内容，请参考下文。

#### [Direct link to heading](https://docs.dify.ai/zh-hans/guides/workflow/file-upload\#fang-fa-san-tong-guo-tian-jia-wen-jian-bian-liang-kai-qi-wen-jian-shang-chuan-gong-neng)    方法三：通过添加文件变量开启文件上传功能

#### [Direct link to heading](https://docs.dify.ai/zh-hans/guides/workflow/file-upload\#id-1.-zai-kai-shi-jie-dian-tian-jia-wen-jian-bian-liang)    1\. 在“开始”节点添加文件变量

在应用的 [“开始”](https://docs.dify.ai/zh-hans/guides/workflow/node/start) 节点内添加输入字段，选择 **“单文件”** 或 **“文件列表”** 字段类型的变量。

File Upload - CN

Start the guide

- **单文件**



仅允许应用使用者上传单个文件。

- **文件列表**



允许应用使用者单次批量上传多个文件。


> 为了便于操作，将使用单文件变量作为示例。

#### [Direct link to heading](https://docs.dify.ai/zh-hans/guides/workflow/file-upload\#wen-jian-jie-xi)    文件解析

文件变量的使用方式主要分为两种：

1. 使用工具节点转换文件内容：



- 对于文档类型的文件，可以使用"文档提取器"节点将文件内容转换为文本形式。

- 这种方法适用于需要将文件内容解析为模型可理解的格式（如 string、array\[string\] 等）的情况。


2. 直接在 LLM 节点中使用文件变量：



- 对于某些特定类型的文件（如图片），可以在 LLM 节点中直接使用文件变量。

- 例如，对于图片类型的 file variables，可以在 LLM 节点中启用 vision 功能，然后在变量选择器中直接引用对应的文件变量。


选择哪种方式取决于文件类型和你的具体需求。接下来，我们将详细介绍这两种方法的具体操作步骤。

#### [Direct link to heading](https://docs.dify.ai/zh-hans/guides/workflow/file-upload\#id-2.-tian-jia-wen-dang-ti-qu-qi-jie-dian)    2\. 添加文档提取器节点

上传文件后将存储至单文件变量内，LLM 暂不支持直接读取变量中的文件。因此需要先添加 [**“文档提取器”**](https://docs.dify.ai/zh-hans/guides/workflow/node/doc-extractor) 节点，从已上传的文档文件内提取内容并发送至 LLM 节点完成信息处理。

将“开始”节点内的文件变量作为 **“文档提取器”** 节点的输入变量。

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F1288284732-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FCdDIVDY6AtAz028MFT4d%252Fuploads%252FN5ncKDnJ5Mnj59QKRVY3%252F%25E6%2588%25AA%25E5%25B1%258F2024-10-12%252015.45.45.png%3Falt%3Dmedia%26token%3D04e342ba-79bb-4661-8e2c-0af3a8786dde&width=768&dpr=4&quality=100&sign=b143c22c&sv=2)

添加输入变量

将“文档提取器”节点的输出变量填写至 LLM 节点的系统提示词内。

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F1288284732-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FCdDIVDY6AtAz028MFT4d%252Fuploads%252FaI8qoN8DZ20cH5LOedMU%252Fimage.png%3Falt%3Dmedia%26token%3D1644e8f2-0650-45b8-ac8a-70e5a32b39b4&width=768&dpr=4&quality=100&sign=db4f80ac&sv=2)

粘贴系统提示词

完成上述设置后，应用的使用者可以在 WebApp 内粘贴文件 URL 或上传本地文件，然后就文档内容与 LLM 展开互动。应用使用者可以在对话过程中随时替换文件，LLM 将获取最新的文件内容。

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F1288284732-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FCdDIVDY6AtAz028MFT4d%252Fuploads%252FaMaRnlCM1yxxzD8DKR76%252Fimage.png%3Falt%3Dmedia%26token%3D3b31830d-b36a-4691-8da9-1a29d3dd4900&width=768&dpr=4&quality=100&sign=f85f9438&sv=2)

粘贴 URL 进行对话

**在 LLM 节点中引用文件变量**

对于某些特定类型的文件（如图片），可以在 LLM 节点中直接使用文件变量。这种方法特别适用于需要视觉分析的场景。以下是具体步骤：

1. 在 LLM 节点中，启用 vision 功能。这允许模型处理图像输入（模型需要支持 vision）。

2. 在 LLM 节点的变量选择器中，直接引用之前创建的文件变量如果是通过附加功能开启的文件上传，则选择 `sys.files` 变量。

3. 在系统提示词中，指导模型如何处理图像输入。例如，你可以要求模型描述图像内容或回答关于图像的问题。


下面是一个示例配置：

![](https://1288284732-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FCdDIVDY6AtAz028MFT4d%2Fuploads%2Fgit-blob-b1309bbb91406618a751ec5116e3e14b37cbe727%2Ffile-upload-qs-1.avif?alt=media)

在LLM节点中直接使用文件变量

需要注意的是，直接在 LLM 节点中使用文件变量时，我们需要确保文件变量仅包含图片文件，否则可能会导致错误。如果用户可能上传不同类型的文件，我们需要使用列表操作节点过滤不同类型的文件。

#### [Direct link to heading](https://docs.dify.ai/zh-hans/guides/workflow/file-upload\#wen-jian-xia-zai)    文件下载

将文件变量放置到 answer 节点或者 end 节点中，当应用运行到该节点都时候将会在会话框中提供文件下载卡片。点击卡片即可下载文件。

![](https://1288284732-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FCdDIVDY6AtAz028MFT4d%2Fuploads%2Fgit-blob-9f4c92541acda5fae950f6919545be7bfc6bd629%2Ffile-upload-qs-2.avif?alt=media)

文件下载

### [Direct link to heading](https://docs.dify.ai/zh-hans/guides/workflow/file-upload\#jin-jie-shi-yong)    进阶使用

若希望应用能够支持上传多种文件，例如允许用户同时上传文档文件、图片和音视频文件，此时需要在 “开始节点” 中添加 “文件列表” 变量，并通过“列表操作”节点针对不同的文件类型进行处理。详细说明请参考 [列表操作](https://docs.dify.ai/zh-hans/guides/workflow/node/list-operator) 节点。

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F1288284732-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FCdDIVDY6AtAz028MFT4d%252Fuploads%252FfeO2P7SbyDRoBOVwEtKG%252Fimage.png%3Falt%3Dmedia%26token%3Db8b3722b-a7a8-4516-8d44-bf551b426295&width=768&dpr=4&quality=100&sign=d16a225d&sv=2)

如需查看更多使用案例，请参考： [动手实验室 \- 使用文件上传搭建文章理解助手](https://docs.dify.ai/zh-hans/workshop/intermediate/article-reader)

[Previous编排节点](https://docs.dify.ai/zh-hans/guides/workflow/orchestrate-node) [Next异常处理](https://docs.dify.ai/zh-hans/guides/workflow/error-handling)

Last updated 8 days ago

This site uses cookies to deliver its service and to analyse traffic. By browsing this site, you accept the [privacy policy](https://dify.ai/privacy).

AcceptRejectDifyのハンドオン工房へようこそ！このチュートリアルは、Difyをゼロから学び始めたい初心者のために設計されています。プログラミングやAIに関する知識の有無にかかわらず、私たちはDifyの核心概念とその使い方を、詳細を省略することなく段階的に学べるよう、丁寧にガイドします。

私たちは、一連の実験を通じてDifyの理解を深めるお手伝いをします。各実験には、詳細な手順と説明が含まれており、簡単に追うことができ、内容をしっかりと把握することができます。実験を通じて知識を学び、実践を重ねることで、Difyに関する包括的な理解を徐々に築いていきましょう。

事前の知識は一切必要ありません！最も基本的な概念から始めて、徐々により高度なトピックへと進んでいきます。完全な初心者の方でも、ある程度のプログラミング経験がある方でも、Difyを学ぶために必要なすべてをこのチュートリアルで提供します。

一緒に探索の旅を始め、新しいDifyの可能性を探求していきましょう！

[Previousサブスクリプション管理](/ja-jp/guides/management/subscription-management) [NextゼロからAI画像生成アプリの構築方法](/ja-jp/workshop/basic/build-ai-image-generation-app)

Last updated 3 months agoDify は複数ユーザー向けのプラットフォームであり、ワークスペースはチームの基本的な協同単位です。ワークスペースのメンバーは、アプリやナレッジベースの作成・編集が可能で、 [発見](/ja-jp/guides/workspace/app) エリアで他のチームメンバーが作成した公開アプリを直接利用することもできます。

### [Direct link to heading](\#roguin)    ログイン方式

現在のところ、Dify のクラウドサービスとコミュニティ版でサポートされているログイン方式には違いがあります。以下の表を参照してください。

クラウドサービス

コミュニティ版

メールログイン

非対応

対応

GitHubアカウントログイン

対応

非対応

Googleアカウントログイン

対応

非対応

SSOログイン

対応予定

対応予定

### [Direct link to heading](\#akauntono)    アカウントの作成

クラウドサービスを利用している場合、初回ログイン時に自動的にワークスペースが作成され、あなたが管理者になります。

コミュニティ版では、インストール時に管理者のメールアドレスとパスワードの設定を求められます。コミュニティ版では複数のワークスペースの開設はサポートされていません。

[Previousコンテンツモデレーション](/ja-jp/guides/extension/code-based-extension/moderation) [Next発見](/ja-jp/guides/workspace/app)

Last updated 5 months ago[Self hosted / local deployment frequently asked questions (FAQs)](https://docs.dify.ai/learn-more/faq/install-faq)

[LLM configuration and usage frequently asked questions (FAQs)](https://docs.dify.ai/learn-more/faq/use-llms-faq)

[PreviousHow to Use JSON Schema Output in Dify?](/learn-more/extended-reading/how-to-use-json-schema-in-dify) [NextSelf-Host Related](/learn-more/faq/install-faq)

Last updated 4 months ago[Build An Article Reader Using File Upload](/workshop/intermediate/article-reader) [Building a Smart Customer Service Bot Using a Knowledge Base](/workshop/intermediate/customer-service-bot) [Generating analysis of Twitter account using Chatflow Agent](/workshop/intermediate/twitter-chatflow)

[PreviousHow to Build an AI Image Generation App](/workshop/basic/build-ai-image-generation-app) [NextBuild An Article Reader Using File Upload](/workshop/intermediate/article-reader)

This site uses cookies to deliver its service and to analyse traffic. By browsing this site, you accept the [privacy policy](https://dify.ai/privacy).

AcceptReject今後、画像ファイルのアップロード機能がより全面的な「ファイルアップロード」機能に統合されます。重複な機能を避けるため、チャットフローとワークフローの「機能」をアップグレードし、調整しました：

- チャットフローの「機能」から画像アップロードオプションを削除し、新たに「ファイルアップロード」機能を追加します。この機能は、画像ファイルタイプを選択できます。また、アプリのダイアログボックス内の画像アップロードアイコンもファイルアップロードアイコンに変更されました。


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3244742310-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FBl3K6n12AeCkG3icHwfh%252Fuploads%252Fgit-blob-f5e2974452190013c700b4c3a0f9893b198e2dc1%252Fen-bulletin-1.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=ce7ebd1e&sv=2)

- **ワークフローの機能および** `sys.files` [**変数**](/ja-jp/guides/workflow/variables) **にあった画像アップロードオプションは、将来的に廃止されます。** 両方とも `LEGACY` としてマークされ、開発者にはワークフローにファイルアップロード機能を追加するためにカスタムファイル変数の使用が推奨されています。


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3244742310-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FBl3K6n12AeCkG3icHwfh%252Fuploads%252Fgit-blob-ba7324fcef47f6e7ccf6ada87c410b6403b1d0d8%252Fen-bulletin-2.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=26c9e6e8&sv=2)

### [Direct link to heading](\#appurdowosuru)    「画像アップロード」機能を統合する理由

以前、Difyは画像ファイルのアップロードのみをサポートしていましたが、最新バージョンでは文書、画像、音声、映像、カスタムファイル形式をサポートする包括的なファイルアップロード機能が導入されました。画像アップロードは、より包括的な「ファイルアップロード」機能に統合されました。 ファイルアップロード機能を追加する際、開発者は「画像」ファイルタイプを選択するだけで画像のアップロードを有効にできます。

冗長な機能による混乱を避けるため、チャットフローにおける単独の画像アップロード機能を包括的なファイルアップロード機能に置き換え、ワークフローにおいて画像アップロードを推奨しないことに決定しました。

### [Direct link to heading](\#yorinafairuappurdo)    より全面的な機能：ファイルアップロード

アプリの情報処理能力を向上させるために、このアップデートで「ファイルアップロード」機能が導入されました。チャットテキストとは異なり、文書ファイルは学術レポートや法的契約など多くの情報を運搬することができます。

- ファイルアップロード機能により、ファイルはワークフロー内でファイル変数としてアップロード、解析、参照、ダウンロードされます。

- 開発者は、画像、音声、映像を含む複雑なタスクの理解と処理が可能なアプリを簡単に構築できます。


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3244742310-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FBl3K6n12AeCkG3icHwfh%252Fuploads%252Fgit-blob-ffd544452021bba8d511f26a9deb49b26844965a%252Fen-bulletin-3.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=c5a186e4&sv=2)

単独の「画像アップロード」機能の使用を推奨せず、アプリ体験を向上させるために包括的な「ファイルアップロード」機能への移行をお勧めします。

### [Direct link to heading](\#anatagasurubekikotoha)    あなたがするべきことは？

#### [Direct link to heading](\#dify-cloudyzno)    Dify Cloudユーザーの場合：

- **チャットフロー**


すでに「画像アップロード」機能が有効になっているチャットフローを作成した場合、LLMノードでビジョン機能を有効にすると、システムは機能を自動的に切り替え、アプリの画像アップロード機能に影響を与えません。アプリを更新して再公開する必要がある場合は、LLMノードのビジョン変数選択ボックスでファイル変数を選択し、チェックリストからアイテムをクリアしてアプリを再公開してください。

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3244742310-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FBl3K6n12AeCkG3icHwfh%252Fuploads%252Fgit-blob-179d5bc76c255b19713fce57375043a5cb33c865%252Fen-bulletin-4.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=25bf7f26&sv=2)

チャットフローに「画像アップロード」機能を追加したい場合は、機能で「ファイルアップロード」を有効にし、「画像」ファイルタイプのみを選択してください。その後、LLMノードでビジョン機能を有効にし、sys.files変数を指定してください。アップロードエントリは「ペーパークリップ」アイコンとして表示されます。詳細な手順については、追加機能を参照してください。

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3244742310-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FBl3K6n12AeCkG3icHwfh%252Fuploads%252Fgit-blob-c5e682645c002c16eab400e142ce3e7774d421d3%252Fen-bulletin-5.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=8829a2b4&sv=2)

- **ワークフロー**


すでに「画像アップロード」機能が有効になっているワークフローを作成し、LLMノードでビジョン機能を有効にした場合、この変更は直ちには影響しませんが、公式の廃止前に手動で移行を完了する必要があります。

ワークフローに「画像アップロード」機能を有効にしたい場合は、 [開始](/ja-jp/guides/workflow/node/start) ノードにファイル変数を追加してください。その後、 `sys.files` 変数を使用せずに後続ノードでこのファイル変数を参照してください。

#### [Direct link to heading](\#dify-community-editionmatahahosutonoentpuraizuyzno)    Dify Community Editionまたは自己ホストのエンタープライズユーザーの場合：

バージョンv0.10.0にアップグレードすると、「ファイルアップロード」機能が表示されます。

- チャットフロー：


「画像アップロード」機能が有効になっているチャットフローは、変更を加えることなくファイルアップロード機能に自動的に切り替わります。

チャットフローに「画像アップロード」機能を追加したい場合は、詳細な手順については追加機能セクションを参照してください。

- ワークフロー：


既存のワークフローには影響がありませんが、公式の廃止前に手動で移行を完了する必要があります。

### [Direct link to heading](\#yokuaru)    よくある質問：

#### [Direct link to heading](\#id-1-konoappudtohanoapurinishimasuka)    1\. このアップデートは既存のアプリに影響しますか？

- 既存のチャットフローは自動的に移行され、画像のアップロード機能はファイルのアップロード機能にスムーズに切り替わります。 `sys.files` 変数は引き続きデフォルトのVision入力として使用されます。アプリインターフェース内の画像アップロードエントリは、ファイルアップロードエントリに置き換えられます。

- 現時点では既存のワークフローには影響はありません。 `sys.files` 変数および画像アップロード機能は「LEGACY」としてマークされていますが、引き続き使用可能です。ただし、これらの「LEGACY」機能は将来的に廃止される予定で、その際には手動でのアップデートが必要になります。


#### [Direct link to heading](\#id-2-apuriwosuguniappudtosurugaarimasuka)    2\. アプリをすぐにアップデートする必要がありますか？

- チャットフローはシステムが自動的に移行するため、手動でのアップデートは必要ありません。

- ワークフローについては、すぐにアップデートする必要はありませんが、将来の移行に備えて新しいファイルアップロード機能に慣れておくことをお勧めします。


#### [Direct link to heading](\#id-3-shiifairuappurdotonoaruapuriwosuruha)    3\. 新しいファイルアップロード機能と互換性のあるアプリを確認する方法は？

チャットフローの場合：

• 機能構成でファイルのアップロードオプションが有効になっているか確認してください。

• Vision機能を備えたLLMを使用していることを確認し、Visionトグルをオンにしてください。

• Visionボックスで、 `sys.files` が入力アイテムとして正しく選択されていることを確認してください。

ワークフローの場合：

• 「開始」ノードでファイルタイプの変数を作成してください。

• 後続のノードでは、このファイル変数を参照し、LEGACYの `sys.files` 変数は使用しないでください。

#### [Direct link to heading](\#id-4-sareta-chatflow-apurikshondeappurdoaikongaetadousurebayoidesuka)    4\. 以前公開された Chatflow アプリケーションで画像アップロードアイコンが消えた場合、どうすればよいですか？

アプリケーションを再公開することをお勧めします。チャットボックスにファイルアップロードアイコンが表示されます。

#### [Direct link to heading](\#nofdobakkuwonishiteimasu)    皆様のフィードバックを大切にしています

Difyコミュニティの重要なメンバーとして、皆様の経験とフィードバックは私たちにとって非常に重要です。ぜひ以下の方法でご意見をお寄せください：

• 新しいファイルアップロード機能をお試しいただき、その利便性と柔軟性を体験してください。

• 次のチャンネルを通じてお考えやご提案を共有してください：

• [GitHub discussions](https://github.com/langgenius/dify)

• [Discordチャンネル](https://discord.gg/X8r5WgWzJV)

皆様のフィードバックは製品の継続的な改善と、コミュニティ全体により良い体験を提供するために役立ちます。

[Previousアプリケーション公開](/ja-jp/guides/workflow/publish) [Nextナレッジベース](/ja-jp/guides/knowledge-base)

Last updated 22 days ago### [Direct link to heading](\#code-structure)    Code Structure

The following code file structure outlines the organization of the project:

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
[cmd/]
├── server                // Server startup entry point
├── lib                   // Shared library entry point
└── test                  // Common test scripts
[build/]                  // Build scripts for different architectures and platforms
[internal/]               // Internal packages
├── controller            // HTTP request handlers
├── middleware            // Request processing middleware
├── server                // Server setup and configuration
├── service               // Controller services
├── static                // Configuration files
│   ├── nodejs_syscall    // Node.js system call whitelist
│   └── python_syscall    // Python system call whitelist
├── types                 // Entity definitions
├── core                  // Core isolation and execution logic
│   ├── lib               // Shared libraries
│   ├── runner            // Code execution
│   │   ├── nodejs        // Node.js executor
|   |   └── python        // Python executor
└── tests                 // CI/CD tests
```

### [Direct link to heading](\#principle)    Principle

The core functionality has two entry points: the `HTTP` service entry for `DifySandbox` and the `dynamic link library` entry. When the Sandbox runs code, it first generates a temporary code file. This file begins by calling the `dynamic link library` to initialize the runtime environment (the `Sandbox`). The user's code is then executed within this temporary file, ensuring that the system remains protected from potentially harmful user-submitted code.

The dynamic link library uses `Seccomp` to restrict system calls. The `static` directory contains `nodejs_syscall` and `python_syscall` files, which provide system call whitelists for both `ARM64` and `AMD64` architectures. There are four files in total. Please do not modify these files unless absolutely necessary.

### [Direct link to heading](\#how-to-contribute)    How to Contribute

For minor issues like `Typos` and `Bugs`, feel free to submit a `Pull Request`. For major changes or `Feature`-level submissions, please open an `Issue` first to facilitate discussion.

#### [Direct link to heading](\#to-do-list)    To-Do List

Here are some items we're currently considering. If you're interested, you can choose one to contribute:

- Support for additional programming languages:



- We currently support `Python` and `Node.js`. Consider adding support for new languages.

- Remember to account for both `ARM64` and `AMD64` architectures, and provide `CI` testing to ensure security for any new language.


- Node.js dependency management:



- We've implemented support for `Python` dependencies, which can be automatically installed during Sandbox initialization. However, due to the complexity of `node_modules`, we haven't yet found a good solution for `Node.js`. This is an area open for improvement.


- Image processing capabilities:



- As multimodality becomes increasingly important, supporting image processing in the `Sandbox` would be valuable.

- Consider adding support for image processing libraries like `Pillow`, and enable passing images into the `Sandbox` for processing in `Dify`.


- Enhanced `CI` testing:



- Our current `CI` testing is limited and includes only basic test cases. More comprehensive testing would be beneficial.


- Multimodal data generation:



- Explore using the `Sandbox` to generate multimodal data, such as combining text and images.


[PreviousDifySandbox](/development/backend/sandbox) [NextModels Integration](/development/models-integration)

Last updated 6 months ago[Build a Notion AI Assistant](/learn-more/use-cases/build-an-notion-ai-assistant) [Create a MidJourney Prompt Bot with Dify](/learn-more/use-cases/create-a-midjourney-prompt-bot-with-dify) [Create an AI Chatbot with Business Data in Minutes](/learn-more/use-cases/create-an-ai-chatbot-with-business-data-in-minutes) [Integrating Dify Chatbot into Your Wix Website](/learn-more/use-cases/how-to-integrate-dify-chatbot-to-your-wix-website) [How to connect with AWS Bedrock Knowledge Base？](/learn-more/use-cases/how-to-connect-aws-bedrock)

[PreviousIntegrating with GPUStack for Local Model Deployment](/development/models-integration/gpustack) [NextBuild a Notion AI Assistant](/learn-more/use-cases/build-an-notion-ai-assistant)

This site uses cookies to deliver its service and to analyse traffic. By browsing this site, you accept the [privacy policy](https://dify.ai/privacy).

AcceptRejectDifyはオープンソースのAIアプリ開発プラットフォームです。Backend as Serviceと [LLMOps](/ja-jp/learn-more/extended-reading/what-is-llmops) の理念を融合し、開発者が迅速にAIアプリケーションを構築できるようにします。同時に、プログラミングが得意でない方でも、自分のアイデアをすぐにAIアプリにできる直感的なインターフェースを提供しています。

Difyを使えば、最新のAI技術を活用して誰でも簡単にAIアプリを作ることができます。

Difyには、AIアプリ開発に必要な機能が全て揃っています：

- 数百種類のAI言語モデルに対応

- 直感的な操作でカスタムチャットボットを作成

- 高性能で柔軟なRAGエンジン

- 様々なツールを活用したAIエージェントの構築

- 自由自在なワークフロー設計


さらに、使いやすいインターフェースとAPIも提供しているので、開発者の皆さんは面倒な作業を省いて、新しいアイデアやビジネスニーズに集中できます。

## [Direct link to heading](\#nazedifywobuno)    なぜDifyを選ぶの？

Difyは、すぐに本番で使える完璧なソリューションです。他のAI開発ツール（LangChainなど）が部品の詰まった工具箱だとすれば、Difyは設計図付きの組み立て済みキットのようなものです。細部まで考え抜かれ、十分にテストされているので、安心して使い始められます。 重要なのは、Difyがオープンソースだということ。専門チームとコミュニティが力を合わせて開発しています。どんなAIモデルでも自由に使え、データの管理も自分でできるので、安全性と柔軟性を両立できます。

> ユーザーの皆さんからは、「シンプルで使いやすく、そして進化が速い」と評価いただいています。
> —— Luyu Zhang（Dify.AI CEO）

このガイドを読めば、Difyのことがもっと分かるはずです。私たちは、Difyがみなさんのお役に立てると信じています。

## [Direct link to heading](\#difydegadekiru)    Difyで何ができる？

「Dify」という名前には2つの意味があります。「Define（定義する）+ Modify（改良する）」の組み合わせで、AIアプリを作って改善し続けることを表しています。そして「Do it for you（あなたのためにやる）」という意味も込められています。

- スタートアップの方へ：アイデアを素早くカタチに。すでに多くのチームがDifyを使ってMVP（最小限のプロダクト）を作り、投資を得たり顧客を獲得しています。

- 既存ビジネスで活用したい方へ：AIで既存のアプリをパワーアップ。DifyのAPIを使えば、AIの設定とビジネスロジックを分けて管理できます。データやコスト、使用状況も簡単に把握できるので、効果を見ながら改善できます。

- 大企業の方へ：社内のAI活用を促進。銀行や大手IT企業では、Difyを社内のAIゲートウェイとして導入し、AI技術の利用促進と一元管理を実現しています。

- AI好きの方へ：最新のAI技術を気軽に試せます。すでに6万人以上の開発者がDifyで自分のアプリを作っています。


### [Direct link to heading](\#nosuteppu)    次のステップ

- [クイックスタート](/ja-jp/guides/application-orchestrate/creating-an-application) を読んで、Difyでのアプリ作成の流れを確認

- [Difyを自分の管理するサーバーに導入](/ja-jp/getting-started/install-self-hosted) する方法と [様々なAI言語モデルを使う](/ja-jp/guides/model-configuration) 方法を学ぶ

- Difyの [機能詳細](/ja-jp/getting-started/readme/features-and-specifications) とロードマップをチェック

- [GitHub](https://github.com/langgenius/dify) でスターを付け、 **コントリビューションガイド** を読む


[Next特性と技術仕様](/ja-jp/getting-started/readme/features-and-specifications)

Last updated 4 months agoThe annotated replies feature provides customizable high-quality question-and-answer responses through manual editing and annotation.

Applicable scenarios:

- **Customized Responses for Specific Fields:** In customer service or knowledge base scenarios for enterprises, government, etc., service providers may want to ensure that certain specific questions are answered with definitive results. Therefore, it is necessary to customize the output for specific questions. For example, creating "standard answers" for certain questions or marking some questions as "unanswerable."

- **Rapid Tuning for POC or DEMO Products:** When quickly building prototype products, customized responses achieved through annotated replies can efficiently enhance the expected generation of Q&A results, thereby improving customer satisfaction.


The annotated replies feature essentially provides another set of retrieval-enhanced systems, allowing you to bypass the LLM generation phase and avoid the hallucination issues of RAG.

### [Direct link to heading](\#workflow)    Workflow

1. After enabling the annotated replies feature, you can annotate the responses from LLM conversations. You can add high-quality answers from LLM responses directly as annotations or edit a high-quality answer according to your needs. These edited annotations will be saved persistently.

2. When a user asks a similar question again, the system will vectorize the question and search for similar annotated questions.

3. If a match is found, the corresponding answer from the annotation will be returned directly, bypassing the LLM or RAG process.

4. If no match is found, the question will continue through the regular process (passing to LLM or RAG).

5. Once the annotated replies feature is disabled, the system will no longer match responses from annotations.


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-090c7766acfb0ee3a498fc8eff83b825f6e678a0%252Fimage%2520%28130%29.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=9df3b185&sv=2)

Annotated Replies Workflow

### [Direct link to heading](\#enabling-annotated-replies-in-prompt-orchestration)    Enabling Annotated Replies in Prompt Orchestration

Enable the annotated replies switch by navigating to **“Orchestrate -> Add Features”**:

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-0695c6d76f7f304650f52d8f3074aeb6f23ecc04%252Fannotated-replies.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=7de1f5bd&sv=2)

Enabling Annotated Replies in Prompt Orchestration

When enabling, you need to set the parameters for annotated replies, which include: Score Threshold and Embedding Model.

**Score Threshold:** This sets the similarity threshold for matching annotated replies. Only annotations with scores above this threshold will be recalled.

**Embedding Model:** This is used to vectorize the annotated text. Changing the model will regenerate the embeddings.

Click save and enable, and the settings will take effect immediately. The system will generate embeddings for all saved annotations using the embedding model.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-6df72ab4676f9f3e8e1d3a74f09b54d7f71d9740%252Fsetting-parameters-for-annotated-replies.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=beea6f27&sv=2)

Setting Parameters for Annotated Replies

### [Direct link to heading](\#adding-annotations-in-the-conversation-debug-page)    Adding Annotations in the Conversation Debug Page

You can directly add or edit annotations on the model response information in the debug and preview pages.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-501ce9aa196f4fdb36d3e16a4329235a32d8fe60%252Fadd-annotation-reply.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=d5ba6c3d&sv=2)

Adding Annotated Replies

Edit the response to the high-quality reply you need and save it.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-ce68714f12cd18c0c62ba9b372f04516980af92b%252Fediting-annotated-replies.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=5bfe09f2&sv=2)

Editing Annotated Replies

Re-enter the same user question, and the system will use the saved annotation to reply to the user's question directly.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-90579362809825c99d3821c37c9b762af7738a98%252Fannotaiton-reply.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=f0a8336e&sv=2)

Replying to User Questions with Saved Annotations

### [Direct link to heading](\#enabling-annotated-replies-in-logs-and-annotations)    Enabling Annotated Replies in Logs and Annotations

Enable the annotated replies switch by navigating to “Logs & Ann. -> Annotations”:

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-26bc77e8c8a57ac7bc1c6bbaa9040b259c8069f0%252Flogs-annotation-switch.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=6885f1f1&sv=2)

Enabling Annotated Replies in Logs and Annotations

### [Direct link to heading](\#setting-parameters-for-annotated-replies-in-the-annotation-backend)    Setting Parameters for Annotated Replies in the Annotation Backend

The parameters that can be set for annotated replies include: Score Threshold and Embedding Model.

**Score Threshold:** This sets the similarity threshold for matching annotated replies. Only annotations with scores above this threshold will be recalled.

**Embedding Model:** This is used to vectorize the annotated text. Changing the model will regenerate the embeddings.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-d9661fc9a33a275ea046f1bac17bab6341aa4bdb%252Fannotated-replies-initial.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=345fa42e&sv=2)

Setting Parameters for Annotated Replies

### [Direct link to heading](\#bulk-import-of-annotated-q-and-a-pairs)    Bulk Import of Annotated Q&A Pairs

In the bulk import feature, you can download the annotation import template, edit the annotated Q&A pairs according to the template format, and then import them in bulk.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-19e15f2694a2a3af6eadc9028fb41ccbc51846f4%252Fbulk-import-annotated.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=bd496fcb&sv=2)

Bulk Import of Annotated Q&A Pairs

### [Direct link to heading](\#bulk-export-of-annotated-q-and-a-pairs)    Bulk Export of Annotated Q&A Pairs

Through the bulk export feature, you can export all saved annotated Q&A pairs in the system at once.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-e09b93c3a811bed2028468e6330127543a83e7a2%252Fbulk-export-annotations.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=3e601038&sv=2)

Bulk Export of Annotated Q&A Pairs

### [Direct link to heading](\#viewing-annotation-hit-history)    Viewing Annotation Hit History

In the annotation hit history feature, you can view the edit history of all hits on the annotation, the user's hit questions, the response answers, the source of the hits, the matching similarity scores, the hit time, and other information. You can use this information to continuously improve your annotated content.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-02e2b0c72ef7cb702d44b5ef44dcd30a3f4dc2a1%252Fview-annotation-hit-history.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=fcdc191c&sv=2)

Viewing Annotation Hit History

[PreviousLogs and Annotation](/guides/annotation/logs) [NextMonitoring](/guides/monitoring)

Last updated 5 months agoBoth Chatflow and Workflow applications support node orchestration through visual drag-and-drop, with two orchestration design patterns: serial and parallel.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-11ce0cc0cc900aa8d6a43bba9b89d56f074d6f89%252Forchestrate-node.jpeg%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=11db07b&sv=2)

## [Direct link to heading](\#serial-node-design-pattern)    Serial Node Design Pattern

In this pattern, nodes execute sequentially in a predefined order. Each node initiates its operation only after the preceding node has completed its task and generated output. This helps ensure tasks are executed in a logical sequence.

Consider a "Novel Generation" Workflow App implementing serial pattern: after the user inputs the novel style, rhythm, and characters, the LLM completes the novel outline, plot, and ending in sequence. Each node works based on the output of the previous node, ensuring consistency in the novel's style.

### [Direct link to heading](\#designing-serial-structure)    Designing Serial Structure

1. Click the `+` icon between two nodes to insert a new serial node.

2. Sequentially link the nodes.

3. Converge all paths to the "End" node to finalize the workflow.


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-fda8bd6213fffe2d18dbe7e9de8ee4ef765f9ff8%252Forchestrate-node-serial-design.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=fe352697&sv=2)

### [Direct link to heading](\#viewing-serial-structure-application-logs)    Viewing Serial Structure Application Logs

In a serial structure application, logs display node operations sequentially. Click "View Logs - Tracing" in the upper right corner of the dialog box to see the complete workflow process, including input/output, token consumption, and runtime for each node.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-d2f4e27205204f081490c01a6195707d498dc37a%252Fviewing-serial-structure-app-logs.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=1a71c436&sv=2)

## [Direct link to heading](\#designing-parallel-structure)    Designing Parallel Structure

This architectural pattern enables concurrent execution of multiple nodes. The preceding node can simultaneously trigger multiple nodes within the parallel structure. These parallel nodes operate independently, executing tasks concurrently and significantly enhancing overall workflow efficiency.

Consider a translation workflow application implementing parallel architecture: Once the user inputs the source text, triggering the workflow, all nodes within the parallel structure simultaneously receive instructions from the preceding node. This allows for concurrent translation into multiple languages, significantly reducing overall processing time.

### [Direct link to heading](\#parallel-structure-design-pattern)    Parallel Structure Design Pattern

The following four methods demonstrate how to create a parallel structure through node addition or visual manipulation:

**Method 1** Hover over a node to reveal the `+` button. Click it to add multiple nodes, automatically forming a parallel structure.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-376e7d2372784a358ffeb2f41d184979c469813a%252Forchestrate-node-parallel-design-method-1.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=dcae6243&sv=2)

**Method 2** Extend a connection from a node by dragging its `+` button, creating a parallel structure.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-91d674541fea5e821a3e24bafbd08660bdd7a214%252Forchestrate-node-parallel-design-method-2.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=e04ce7f4&sv=2)

**Method 3** With multiple nodes on the canvas, visually drag and link them to form a parallel structure.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-bf3f41dbd9f62c0d1ee1c5cd6715e0ed0a6a02fd%252Forchestrate-node-parallel-design-method-3.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=55034400&sv=2)

**Method 4** In addition to canvas-based methods, you can generate parallel structures by adding nodes through the "Next Step" section in a node's right-side panel. This approach automatically creates the parallel configuration.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fgithub.com%2Flanggenius%2Fdify-docs%2Fblob%2Fmain%2Fimg%2Forchestrate-node-parallel-design-method-4.jpeg&width=768&dpr=4&quality=100&sign=c74496fc&sv=2)

**Notes:**

- Any node can serve as the downstream node of a parallel structure;

- Workflow applications require a single, unique "end" node;

- Chatflow applications support multiple "answer" nodes. Each parallel structure in these applications must terminate with an "answer" node to ensure proper output of content;

- All parallel structures will run simultaneously; nodes within the parallel structure output results after completing their tasks, with no order relationship in output. The simpler the parallel structure, the faster the output of results.


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-0ceb0311c9f69671bc1a5f0256dc32808b94e3ad%252Forchestrate-node-chatflow-multi-answer.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=99a8dbb2&sv=2)

### [Direct link to heading](\#designing-parallel-structure-patterns)    Designing Parallel Structure Patterns

The following four patterns demonstrate common parallel structure designs:

#### [Direct link to heading](\#id-1.-normal-parallel)    1\. Normal Parallel

Normal parallel refers to the `Start | Parallel Nodes | End three-layer` relationship, which is also the smallest unit of parallel structure. This structure is intuitive, allowing the workflow to execute multiple tasks simultaneously after user input.

The upper limit for parallel branches is 10.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-6208ef2403ee301e15029ef431fa6d8d313c98f8%252Forchestrate-node-simple-parallel.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=39314b3d&sv=2)

#### [Direct link to heading](\#id-2.-nested-parallel)    2\. Nested Parallel

Nested parallel refers to the Start \| Multiple Parallel Structures \| End multi-layer relationship. It is suitable for more complex workflows, such as needing to request an external API within a certain node and simultaneously passing the returned results to downstream nodes for processing.

A workflow supports up to 3 layers of nesting relationships.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-a9557953334e337d3f60e9f175ab3a8a2ecb6203%252Forchestrate-node-nested-parallel.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=290298ba&sv=2)

#### [Direct link to heading](\#id-3.-conditional-branch--parallel)    3\. Conditional Branch + Parallel

Parallel structures can also be used in conjunction with conditional branches.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-0e8c67bd6442c35f9eb890a42c515e7869be2dcc%252Forchestrate-node-conditional-branch-parallel.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=44e18b23&sv=2)

#### [Direct link to heading](\#id-4.-iteration-branch--parallel)    4\. Iteration Branch + Parallel

This pattern integrates parallel structures within iteration branches, optimizing the execution efficiency of repetitive tasks.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-531f38bb22515877aefb95767c18d2f2e66aba5c%252Forchestrate-node-iteration-parallel.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=bd740461&sv=2)

### [Direct link to heading](\#viewing-parallel-structure-application-logs)    Viewing Parallel Structure Application Logs

Applications with parallel structures generate logs in a tree-like format. Collapsible parallel node groups facilitate easier viewing of individual node logs.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-d0d6c50fc22c486c96d541bd4cb2257e6ddc0931%252Forchestrate-node-parallel-logs.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=2c58fc1&sv=2)

[PreviousShortcut Key](/guides/workflow/shortcut-key) [NextFile Upload](/guides/workflow/file-upload)

Last updated 4 months ago

This site uses cookies to deliver its service and to analyse traffic. By browsing this site, you accept the [privacy policy](https://dify.ai/privacy).

AcceptReject## [Direct link to heading](\#dtasekyuriti)    データセキュリティ

Difyは使用者のデータセキュリティを非常に重視しています。Dify は SOC２タイプ1 認定を取得しており、SOC２タイプ2 の認定期間中です。さらに、当社は ISO 27001 および GDPR 認定の取得も進めています。

Difyのセキュリティ対策やプロトコルに関する詳細は、公式セキュリティポリシーをご覧ください。 [Dify Trust Center](https://security.dify.ai/) では、セキュリティに関する信頼性の高い情報を提供していますので、ぜひご参照ください。

Dify.AIのクラウドサービスは、アメリカのAWSでホストされています。認可を受けた限られた数の担当者のみがユーザーデータにアクセスできるようになっています。また、当社のコードはGitHub上でオープンソースとして公開されているため、クラウドサービスに関するセキュリティの懸念がある場合には、セルフデプロイバージョンをご利用いただくことも可能です。

Difyのセルフデプロイバージョンでは、Difyのサーバーが呼び出されるのは、現在のバージョンアップデートAPIをチェックするための1つのインスタンスのみです。このアクションは、バックエンドの管理者によってトリガーされる必要があります。他にリモートサーバーを使用する仕組みはないため、安全にご利用いただけます。

さらに疑問がある場合は、ファイアウォールやその他のセキュリティ対策を設定することで、データを保護することができます。

[Previousオープンソースライセンス](/ja-jp/policies/open-source)

Last updated 1 month ago[DifySandbox](/zh-hans/development/backend/sandbox)

[Previous为 Dify 文档做出贡献](/zh-hans/community/docs-contribution) [NextDifySandbox](/zh-hans/development/backend/sandbox)

Last updated 6 months ago

This site uses cookies to deliver its service and to analyse traffic. By browsing this site, you accept the [privacy policy](https://dify.ai/privacy).

AcceptRejectDify's community edition is open-source and licensed under an Apache 2.0-based license, with additional conditions. Please refer to the [LICENSE](https://github.com/langgenius/dify/blob/main/LICENSE) file for more details.

Any issues or questions about the license should be directed to [business@dify.ai](mailto:business@dify.ai).

[PreviousLLM Configuration and Usage](/learn-more/faq/use-llms-faq) [NextUser Agreement](/policies/agreement)

Last updated 8 days agoDify はアプリの機能を強化するために様々なツールをサポートしています。各ツールには独自の機能とパラメータがあるため、アプリのニーズに合ったツールを選択してください。 **Dify で使用する前に、ツール提供者の公式サイトから API キーを取得してください。**

> 一部のツールで資格情報を構成すると、ワークスペース内のすべてのメンバーがこのツールを使用できるようになります。対応するキーの背後にあるサービス クォータの消費量に注意してください。

## [Direct link to heading](\#tsrugaido)    ツール統合ガイド

- [StableDiffusion](/ja-jp/guides/tools/tool-configuration/stable-diffusion)：テキストプロンプトに基づいて画像を生成するツール。

- [SearXNG](/ja-jp/guides/tools/tool-configuration/searxng)：無料のインターネットメタ検索エンジンで、様々な検索サービスの結果を統合します。ユーザーは追跡されず、分析されません。


[Previous高度統合ツール](/ja-jp/guides/tools/advanced-tool-integration) [NextGoogle](/ja-jp/guides/tools/tool-configuration/google)

Last updated 4 months agoDify highly values your data security. Dify gets the SOC 2 Type 1 certified and in the window period of SOC 2 Type 2. Besides that, we are still in the process of getting ISO 27001 and GDPR certified.

For comprehensive information on Dify's security measures and protocols, please consult our official Security Policy at [Dify Trust Center](https://security.dify.ai/). Dify Trust Center should be considered the primary and authoritative source for security-related information.

Dify.AI's cloud services are hosted on AWS in the U.S. region. Only a very limited number of authorized personnel, after approval, can access user data. Additionally, our code is open-source on GitHub, so if you have security concerns about the cloud service, you can use the self-deployed version.

In the self-deployed version of Dify, there is only one instance where the Dify server is called, which is for checking the current version update API. This action must be triggered by an administrator in the backend. There are no other technologies that use remote servers, so you can use it securely.

If you still have concerns, you can protect your data by setting up firewalls and other security measures.

[PreviousOpen Source License](/policies/open-source)

Last updated 1 month agoWelcome to the Dify Workshop! These tutorials are designed for beginners who want to start learning Dify from scratch. Whether you have programming or AI-related background knowledge or not, we will guide you step by step to master the core concepts and usage of Dify without skipping any details.

We will help you understand Dify through a series of experiments. Each experiment will include detailed steps and explanations to ensure you can easily follow and grasp the content. We will interweave knowledge teaching in the experiments, allowing you to learn in practice and gradually build a comprehensive understanding of Dify.

No need to worry about any prerequisites! We will start from the most basic concepts and gradually guide you into more advanced topics. Whether you are a complete beginner or have some programming experience but want to learn AI technology, this tutorial will provide you with everything you need.

Let's embark on this learning journey together and explore the endless possibilities of Dify!

[PreviousSubscription Management](/guides/management/subscription-management) [NextHow to Build an AI Image Generation App](/workshop/basic/build-ai-image-generation-app)

Last updated 3 months agoWorkflow 和 Chatflow 类型应用由独立节点相构成。大部分节点设有输入和输出项，但每个节点的输入信息不一致，各个节点所输出的答复也不尽相同。

如何用一种固定的符号 **指代动态变化的内容？** 变量作为一种动态数据容器，能够存储和传递不固定的内容，在不同的节点内被相互引用，实现信息在节点间的灵活通信。

### [Direct link to heading](\#xi-tong-bian-liang)    **系统变量**

系统变量指的是在 Chatflow / Workflow 应用内预设的系统级参数，可以被其它节点全局读取。系统级变量均以 `sys` 开头。

#### [Direct link to heading](\#workflow)    Workflow

Workflow 类型应用提供以下系统变量：

变量名称

数据类型

说明

备注

`sys.files`

`[LEGACY]`

Array\[File\]

文件参数，存储用户初始使用应用时上传的图片

图片上传功能需在应用编排页右上角的 “功能” 处开启

`sys.user_id`

String

用户 ID，每个用户在使用工作流应用时，系统会自动向用户分配唯一标识符，用以区分不同的对话用户

`sys.app_id`

String

应用 ID，系统会向每个 Workflow 应用分配一个唯一的标识符，用以区分不同的应用，并通过此参数记录当前应用的基本信息

面向具备开发能力的用户，通过此参数区分并定位不同的 Workflow 应用

`sys.workflow_id`

String

Workflow ID，用于记录当前 Workflow 应用内所包含的所有节点信息

面向具备开发能力的用户，可以通过此参数追踪并记录 Workflow 内的包含节点信息

`sys.workflow_run_id`

String

Workflow 应用运行 ID，用于记录 Workflow 应用中的运行情况

面向具备开发能力的用户，可以通过此参数追踪应用的历次运行情况

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F1288284732-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FCdDIVDY6AtAz028MFT4d%252Fuploads%252FrN6uw5MOfjV2xsDnQsV1%252Fimage.png%3Falt%3Dmedia%26token%3D309a9336-7bd7-4ef6-8621-779538245e25&width=768&dpr=4&quality=100&sign=1d619385&sv=2)

Workflow 类型应用系统变量

#### [Direct link to heading](\#chatflow)    Chatflow

Chatflow 类型应用提供以下系统变量：

变量名称

数据类型

说明

备注

`sys.query`

String

用户在对话框中初始输入的内容

`sys.files`

Array\[File\]

用户在对话框内上传的图片

图片上传功能需在应用编排页右上角的 “功能” 处开启

`sys.dialogue_count`

Number

用户在与 Chatflow 类型应用交互时的对话轮数。每轮对话后自动计数增加 1，可以和 if-else 节点搭配出丰富的分支逻辑。

例如到第 X 轮对话时，回顾历史对话并给出分析

`sys.conversation_id`

String

对话框交互会话的唯一标识符，将所有相关的消息分组到同一个对话中，确保 LLM 针对同一个主题和上下文持续对话

`sys.user_id`

String

分配给每个应用用户的唯一标识符，用以区分不同的对话用户

`sys.app_id`

String

应用 ID，系统会向每个 Workflow 应用分配一个唯一的标识符，用以区分不同的应用，并通过此参数记录当前应用的基本信息

面向具备开发能力的用户，通过此参数区分并定位不同的 Workflow 应用

`sys.workflow_id`

String

Workflow ID，用于记录当前 Workflow 应用内所包含的所有节点信息

面向具备开发能力的用户，可以通过此参数追踪并记录 Workflow 内的包含节点信息

`sys.workflow_run_id`

String

Workflow 应用运行 ID，用于记录 Workflow 应用中的运行情况

面向具备开发能力的用户，可以通过此参数追踪应用的历次运行情况

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F1288284732-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FCdDIVDY6AtAz028MFT4d%252Fuploads%252FCaMzGwL8AfOu7lvjwLkg%252Fimage.png%3Falt%3Dmedia%26token%3Dd4f72d00-012b-49eb-acd2-9f1fca8a8b01&width=768&dpr=4&quality=100&sign=b4bbba84&sv=2)

Chatflow 类型应用系统变量

### [Direct link to heading](\#huan-jing-bian-liang)    环境变量

**环境变量用于保护工作流内所涉及的敏感信息**，例如运行工作流时所涉及的 API 密钥、数据库密码等。它们被存储在工作流程中，而不是代码中，以便在不同环境中共享。

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F1288284732-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FCdDIVDY6AtAz028MFT4d%252Fuploads%252F5NyEyTNH8sKcgyRMhbYv%252F%25E7%258E%25AF%25E5%25A2%2583%25E5%258F%2598%25E9%2587%258F.jpeg%3Falt%3Dmedia%26token%3D0b4a9003-1dbc-41a3-ac13-975611c316ed&width=768&dpr=4&quality=100&sign=28a9673e&sv=2)

环境变量

支持以下三种数据类型：

- String 字符串

- Number 数字

- Secret 密钥


环境变量拥有以下特性：

- 环境变量可在大部分节点内全局引用；

- 环境变量命名不可重复；

- 环境变量为只读变量，不可写入；


### [Direct link to heading](\#hui-hua-bian-liang)    会话变量

> 会话变量面向多轮对话场景，而 Workflow 类型应用的交互是线性而独立的，不存在多次对话交互的情况，因此会话变量仅适用于 Chatflow 类型（聊天助手 → 工作流编排）应用。

**会话变量允许应用开发者在同一个 Chatflow 会话内，指定需要被临时存储的特定信息，并确保在当前工作流内的多轮对话内都能够引用该信息**，如上下文、上传至对话框的文件（即将上线）、 用户在对话过程中所输入的偏好信息等。好比为 LLM 提供一个可以被随时查看的“备忘录”，避免因 LLM 记忆出错而导致的信息偏差。

例如你可以将用户在首轮对话时输入的语言偏好存储至会话变量中，LLM 在回答时将参考会话变量中的信息，并在后续的对话中使用指定的语言回复用户。

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F1288284732-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FCdDIVDY6AtAz028MFT4d%252Fuploads%252Fr6UT23sf1PyUmpgdbRNX%252F%25E4%25BC%259A%25E8%25AF%259D%25E5%258F%2598%25E9%2587%258F.jpeg%3Falt%3Dmedia%26token%3D01533cea-84f8-4e09-845e-d879d2b87924&width=768&dpr=4&quality=100&sign=a3a99a42&sv=2)

会话变量

**会话变量** 支持以下六种数据类型：

- String 字符串

- Number 数值

- Object 对象

- Array\[string\] 字符串数组

- Array\[number\] 数值数组

- Array\[object\] 对象数组


**会话变量** 具有以下特性：

- 会话变量可在大部分节点内全局引用；

- 会话变量的写入需要使用 [变量赋值](/zh-hans/guides/workflow/node/variable-assigner) 节点；

- 会话变量为可读写变量；


关于如何将会话变量与变量赋值节点配合使用，请参考 [变量赋值](/zh-hans/guides/workflow/node/variable-assigner) 节点说明。

如果想要查看会话变量值在应用对话时的变化情况，点击 Chatflow 应用预览页上方的会话变量 icon 进行查看。

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F11%2Fcc8067fa4c96436f037f8210ebe3f65c.png&width=768&dpr=4&quality=100&sign=eb8856a9&sv=2)

### [Direct link to heading](\#zhu-yi-shi-xiang)    注意事项

- 为避免变量名重复，节点命名不可重复

- 节点的输出变量一般为固定变量，不可编辑


[Previous关键概念](/zh-hans/guides/workflow/key-concept) [Next节点说明](/zh-hans/guides/workflow/node)

Last updated 1 month ago![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-8cd2cf1ed8043caf62e8b069330889c0cf0f5a3b%252Follama.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=c768d23&sv=2)

ollama

[Ollama](https://github.com/jmorganca/ollama) is a local inference framework client that allows one-click deployment of LLMs such as Llama 2, Mistral, Llava, etc. Dify supports integrating LLM and Text Embedding capabilities of large language models deployed with Ollama.

## [Direct link to heading](\#quick-integration)    Quick Integration

### [Direct link to heading](\#download-and-launch-ollama)    Download and Launch Ollama

1. Download Ollama



Visit [https://ollama.ai/download](https://ollama.ai/download) to download the Ollama client for your system.

2. Run Ollama and Chat with Llava







Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
ollama run llava
```





After successful launch, Ollama starts an API service on local port 11434, which can be accessed at `http://localhost:11434`.



For other models, visit [Ollama Models](https://ollama.ai/library) for more details.

3. Integrate Ollama in Dify



In `Settings > Model Providers > Ollama`, fill in:





![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-351b275c8b6420ff85c77e67bf39a11aaf899b7b%252Follama-config-en.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=956472bd&sv=2)





- Model Name: `llava`

- Base URL: `http://<your-ollama-endpoint-domain>:11434`



Enter the base URL where the Ollama service is accessible.



If Dify is deployed using Docker, consider using the local network IP address, e.g., `http://192.168.1.100:11434` or `http://host.docker.internal:11434` to access the service.



For local source code deployment, use `http://localhost:11434`.

- Model Type: `Chat`

- Model Context Length: `4096`



The maximum context length of the model. If unsure, use the default value of 4096.

- Maximum Token Limit: `4096`



The maximum number of tokens returned by the model. If there are no specific requirements for the model, this can be consistent with the model context length.

- Support for Vision: `Yes`



Check this option if the model supports image understanding (multimodal), like `llava`.


Click "Save" to use the model in the application after verifying that there are no errors.

The integration method for Embedding models is similar to LLM, just change the model type to Text Embedding.

4. Use Ollama Models





![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-e10cf6d6c2e419f349d85efb754ee22131678f4f%252Follama-use-model-en.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=9d931cef&sv=2)





Enter `Prompt Eng.` page of the App that needs to be configured, select the `llava` model under the Ollama provider, and use it after configuring the model parameters.


## [Direct link to heading](\#faq)    FAQ

### [Direct link to heading](\#if-you-are-using-docker-to-deploy-dify-and-ollama-you-may-encounter-the-following-error)    ⚠️ If you are using docker to deploy Dify and Ollama, you may encounter the following error:

Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
httpconnectionpool(host=127.0.0.1, port=11434): max retries exceeded with url:/cpi/chat (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8562812c20>: fail to establish a new connection:[Errno 111] Connection refused'))

httpconnectionpool(host=localhost, port=11434): max retries exceeded with url:/cpi/chat (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8562812c20>: fail to establish a new connection:[Errno 111] Connection refused'))
```

This error occurs because the Ollama service is not accessible from the docker container. `localhost` usually refers to the container itself, not the host machine or other containers. To resolve this issue, you need to expose the Ollama service to the network.

### [Direct link to heading](\#setting-environment-variables-on-mac)    Setting environment variables on Mac

If Ollama is run as a macOS application, environment variables should be set using `launchctl`:

1. For each environment variable, call `launchctl setenv`.







Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
launchctl setenv OLLAMA_HOST "0.0.0.0"
```

2. Restart Ollama application.

3. If the above steps are ineffective, you can use the following method:



The issue lies within Docker itself, and to access the Docker host.
you should connect to `host.docker.internal`. Therefore, replacing `localhost` with `host.docker.internal` in the service will make it work effectively.







Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
http://host.docker.internal:11434
```


### [Direct link to heading](\#setting-environment-variables-on-linux)    Setting environment variables on Linux

If Ollama is run as a systemd service, environment variables should be set using `systemctl`:

1. Edit the systemd service by calling `systemctl edit ollama.service`. This will open an editor.

2. For each environment variable, add a line `Environment` under section `[Service]`:







Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
[Service]
Environment="OLLAMA_HOST=0.0.0.0"
```

3. Save and exit.

4. Reload `systemd` and restart Ollama:







Copy

```min-w-full inline-grid [grid-template-columns:auto_1fr] py-2 px-2 [counter-reset:line]
systemctl daemon-reload
systemctl restart ollama
```


### [Direct link to heading](\#setting-environment-variables-on-windows)    Setting environment variables on Windows

On windows, Ollama inherits your user and system environment variables.

1. First Quit Ollama by clicking on it in the task bar

2. Edit system environment variables from the control panel

3. Edit or create New variable(s) for your user account for `OLLAMA_HOST`, `OLLAMA_MODELS`, etc.

4. Click OK/Apply to save

5. Run `ollama` from a new terminal window


## [Direct link to heading](\#how-can-i-expose-ollama-on-my-network)    How can I expose Ollama on my network?

Ollama binds 127.0.0.1 port 11434 by default. Change the bind address with the `OLLAMA_HOST` environment variable.

## [Direct link to heading](\#more-information)    More Information

For more information on Ollama, please refer to:

- [Ollama](https://github.com/jmorganca/ollama)

- [Ollama FAQ](https://github.com/ollama/ollama/blob/main/docs/faq.md)


[PreviousIntegrate Local Models Deployed by LocalAI](/development/models-integration/localai) [NextIntegrate Models on LiteLLM Proxy](/development/models-integration/litellm)

Last updated 1 month ago### [Direct link to heading](\#guan-yu-shu-ju-an-quan)    关于数据安全

Dify 非常重视你的数据安全，已获得 SOC 2 Type 1 认证，并且正处于 SOC 2 Type 2 的窗口期。除此之外，我们正在推进获得 ISO 27001 和 GDPR 认证。

有关 Dify 安全措施和协议的完整信息，请参考 [Dify Trust Center](https://security.dify.ai/) 上的官方安全政策。Dify Trust Center 应被视为安全相关信息的主要和权威来源。

Dify.AI 的云服务位于美国区的 AWS 上，仅极少数获得授权的人员经审批后才可访问用户的数据。另外，我们的代码均在 GitHub 开源，如果你对云服务有安全担忧可以使用自部署版本。

在 Dify 的自部署版本中，仅有一处调用 Dify 服务器，即检查当前版本更新 API 的功能。且必须由管理员在后台触发。其它没有任何使用到远程服务器的技术，因此你可以安全使用。

如果你仍有疑虑，可以通过设置防火墙等方式对数据进行保护。

[Previous开源许可证](/zh-hans/policies/open-source)

Last updated 1 month ago

This site uses cookies to deliver its service and to analyse traffic. By browsing this site, you accept the [privacy policy](https://dify.ai/privacy).

AcceptReject### [Direct link to heading](\#definition)    Definition

Invokes the capabilities of large language models to process information input by users in the "Start" node (natural language, uploaded files, or images) and provide effective response information.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-90c788ade549ecbfc4913515fccb7725bdb0b402%252Fllm-node-1.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=82414015&sv=2)

LLM Node

* * *

### [Direct link to heading](\#scenarios)    Scenarios

LLM is the core node of Chatflow/Workflow, utilizing the conversational/generative/classification/processing capabilities of large language models to handle a wide range of tasks based on given prompts and can be used in different stages of workflows.

- **Intent Recognition**: In customer service scenarios, identifying and classifying user inquiries to guide downstream processes.

- **Text Generation**: In content creation scenarios, generating relevant text based on themes and keywords.

- **Content Classification**: In email batch processing scenarios, automatically categorizing emails, such as inquiries/complaints/spam.

- **Text Conversion**: In translation scenarios, translating user-provided text into a specified language.

- **Code Generation**: In programming assistance scenarios, generating specific business code or writing test cases based on user requirements.

- **RAG**: In knowledge base Q&A scenarios, reorganizing retrieved relevant knowledge to respond to user questions.

- **Image Understanding**: Using multimodal models with vision capabilities to understand and answer questions about the information within images.

- **File Analysis**: In file processing scenarios, use LLMs to recognize and analyze the information contained within files.


By selecting the appropriate model and writing prompts, you can build powerful and reliable solutions within Chatflow/Workflow.

* * *

### [Direct link to heading](\#how-to-configure)    How to Configure

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-76d7fdbd5543e5951e14e6fc77ff1813a7839dd1%252Fllm-node-2.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=75d425fb&sv=2)

LLM Node Configuration - Model Selection

**Configuration Steps:**

1. **Select a Model**: Dify supports major global models, including OpenAI's GPT series, Anthropic's Claude series, and Google's Gemini series. Choosing a model depends on its inference capability, cost, response speed, context window, etc. You need to select a suitable model based on the scenario requirements and task type.

2. **Configure Model Parameters**: Model parameters control the generation results, such as temperature, TopP, maximum tokens, response format, etc. To facilitate selection, the system provides three preset parameter sets: Creative, Balanced, and Precise.

3. **Write Prompts**: The LLM node offers an easy-to-use prompt composition page. Selecting a chat model or completion model will display different prompt composition structures.

4. **Advanced Settings**: You can enable memory, set memory windows, and use the Jinja-2 template language for more complex prompts.


If you are using Dify for the first time, you need to complete the [model configuration](/guides/model-configuration) in **System Settings-Model Providers** before selecting a model in the LLM node.

#### [Direct link to heading](\#writing-prompts)    **Writing Prompts**

In the LLM node, you can customize the model input prompts. If you select a chat model, you can customize the System/User/Assistant sections.

**Prompt Generator**

If you're struggling to come up with effective system prompts (System), you can use the Prompt Generator to quickly create prompts suitable for your specific business scenarios, leveraging AI capabilities.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-362751a18cc505740b9f3857395cdffd8b899388%252Fen-prompt-generator.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=7504a924&sv=2)

In the prompt editor, you can call out the **variable insertion menu** by typing `/` or `{` to insert **special variable blocks** or **upstream node variables** into the prompt as context content.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-c9fcc7ff1eb34174146aa0dcdd7997614b0391b7%252Fllm-node-3.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=e88a7e69&sv=2)

Calling Out the Variable Insertion Menu

* * *

### [Direct link to heading](\#explanation-of-special-variables)    Explanation of Special Variables

**Context Variables**

Context variables are a special type of variable defined within the LLM node, used to insert externally retrieved text content into the prompt.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-837c0dca727dfb676289b27b1613087b9ff0ac61%252Fllm-node-4.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=3830d633&sv=2)

Context Variables

In common knowledge base Q&A applications, the downstream node of knowledge retrieval is typically the LLM node. The **output variable** `result` of knowledge retrieval needs to be configured in the **context variable** within the LLM node for association and assignment. After association, inserting the **context variable** at the appropriate position in the prompt can incorporate the externally retrieved knowledge into the prompt.

This variable can be used not only as external knowledge introduced into the prompt context for LLM responses but also supports the application's [**citation and attribution**](https://github.com/langgenius/dify-docs/blob/main/en/guides/knowledge-base/retrieval-test-and-citation/README.md#id-2.-citation-and-attribution) feature due to its data structure containing segment reference information.

If the context variable is associated with a common variable from an upstream node, such as a string type variable from the start node, the context variable can still be used as external knowledge, but the **citation and attribution** feature will be disabled.

**File Variables**

Some LLMs, such as [Claude 3.5 Sonnet](https://docs.anthropic.com/en/docs/build-with-claude/pdf-support), now support direct processing of file content, enabling the use of file variables in prompts. To prevent potential issues, application developers should verify the supported file types on the LLM's official website before utilizing the file variable.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F11%2F05b3d4a78038bc7afbb157078e3b2b26.png&width=768&dpr=4&quality=100&sign=7e3d3960&sv=2)

> Refer to [File Upload](https://docs.dify.ai/guides/workflow/file-upload) for guidance on building a Chatflow/Workflow application with file upload functionality.

**Conversation History**

To achieve conversational memory in text completion models (e.g., gpt-3.5-turbo-Instruct), Dify designed the conversation history variable in the original [Prompt Expert Mode (discontinued)](https://github.com/langgenius/dify-docs/blob/main/en/learn-more/extended-reading/prompt-engineering/prompt-engineering-1/README.md). This variable is carried over to the LLM node in Chatflow, used to insert chat history between the AI and the user into the prompt, helping the LLM understand the context of the conversation.

The conversation history variable is not widely used and can only be inserted when selecting text completion models in Chatflow.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252Fgit-blob-35d5a52d8128adb307889b2249c2527f415e5f89%252Fimage%2520%28204%29.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=d4b13ff0&sv=2)

Inserting Conversation History Variable

**Model Parameters**

The parameters of the model affect the output of the model. Different models have different parameters. The following figure shows the parameter list for `gpt-4`.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252F3QXrvs7fg0UNj4reYoPu%252F%25E6%2588%25AA%25E5%25B1%258F2024-10-18%252011.35.17.png%3Falt%3Dmedia%26token%3Dac5f228f-412f-4a91-9b6c-223d654dc3b6&width=768&dpr=4&quality=100&sign=ed169da5&sv=2)

The main parameter terms are explained as follows:

**Temperature**: Usually a value between 0-1, it controls randomness. The closer the temperature is to 0, the more certain and repetitive the results; the closer it is to 1, the more random the results.

**Top P**: Controls the diversity of the results. The model selects from candidate words based on probability, ensuring that the cumulative probability does not exceed the preset threshold P.

**Presence Penalty**: Used to reduce the repetitive generation of the same entity or information by imposing penalties on content that has already been generated, making the model inclined to generate new or different content. As the parameter value increases, greater penalties are applied in subsequent generations to content that has already been generated, lowering the likelihood of repeating content.

**Frequency Penalty**: Imposes penalties on words or phrases that appear too frequently by reducing their probability of generation. With an increase in parameter value, greater penalties are imposed on frequently occurring words or phrases. Higher parameter values reduce the frequency of these words, thereby increasing the lexical diversity of the text.

If you do not understand what these parameters are, you can choose to load presets and select from the three presets: Creative, Balanced, and Precise.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252FjGPHL4Q8Bnq5sVajIWPF%252F%25E6%2588%25AA%25E5%25B1%258F2024-10-18%252011.37.43.png%3Falt%3Dmedia%26token%3D71e6bc97-30df-4f33-891b-a04949becd18&width=768&dpr=4&quality=100&sign=9bcff194&sv=2)

* * *

### [Direct link to heading](\#advanced-features)    Advanced Features

**Memory**: When enabled, each input to the intent classifier will include chat history from the conversation to help the LLM understand the context and improve question comprehension in interactive dialogues.

**Memory Window**: When the memory window is closed, the system dynamically filters the amount of chat history passed based on the model's context window; when open, users can precisely control the amount of chat history passed (in terms of numbers).

**Conversation Role Name Settings**: Due to differences in model training stages, different models adhere to role name instructions differently, such as Human/Assistant, Human/AI, Human/Assistant, etc. To adapt to the prompt response effects of multiple models, the system provides conversation role name settings. Modifying the role name will change the role prefix in the conversation history.

**Jinja-2 Templates**: The LLM prompt editor supports Jinja-2 template language, allowing you to leverage this powerful Python template language for lightweight data transformation and logical processing. Refer to the [official documentation](https://jinja.palletsprojects.com/en/3.1.x/templates/).

**Retry on Failure**: For some exceptions that occur in the node, it is usually sufficient to retry the node again. When the error retry function is enabled, the node will automatically retry according to the preset strategy when an error occurs. You can adjust the maximum number of retries and the interval between each retry to set the retry strategy.

- The maximum number of retries is 10

- The maximum retry interval is 5000 ms


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2Fdfb43c1cbbf02cdd36f7d20973a5529b.png&width=768&dpr=4&quality=100&sign=e1875475&sv=2)

**Error Handling**: Provides diverse node error handling strategies that can throw error messages when the current node fails without interrupting the main process, or continue completing tasks through backup paths. For detailed information, please refer to the [Error Handling](https://docs.dify.ai/guides/workflow/error-handling).

* * *

#### [Direct link to heading](\#use-cases)    Use Cases

- **Reading Knowledge Base Content**


To enable workflow applications to read " [Knowledge Base](/guides/knowledge-base)" content, such as building an intelligent customer service application, please follow these steps:

1. Add a knowledge base retrieval node upstream of the LLM node;

2. Fill in the **output variable** `result` of the knowledge retrieval node into the **context variable** of the LLM node;

3. Insert the **context variable** into the application prompt to give the LLM the ability to read text within the knowledge base.


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252F4fQ9CMKu8ucUjA1t0V6C%252Fimage.png%3Falt%3Dmedia%26token%3D2049d7d0-a599-4a0e-9847-638ecc9929f1&width=768&dpr=4&quality=100&sign=d379a8e2&sv=2)

The `result` variable output by the Knowledge Retrieval Node also includes segmented reference information. You can view the source of information through the **Citation and Attribution** feature.

Regular variables from upstream nodes can also be filled into context variables, such as string-type variables from the start node, but the **Citation and Attribution** feature will be ineffective.

- **Reading Document Files**


To enable workflow applications to read document contents, such as building a ChatPDF application, you can follow these steps:

- Add a file variable in the "Start" node;

- Add a document extractor node upstream of the LLM node, using the file variable as an input variable;

- Fill in the **output variable** `text` of the document extractor node into the prompt of the LLM node.


For more information, please refer to [File Upload](/guides/workflow/file-upload).

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252F6AduQyKwZ8oP8l6pLhSC%252Fimage.png%3Falt%3Dmedia%26token%3D600f7cb3-40e8-46be-80a6-07fbbab78e15&width=768&dpr=4&quality=100&sign=c2568503&sv=2)

input system prompts

- **Error Handling**


When processing information, LLM nodes may encounter errors such as input text exceeding token limits or missing key parameters. Developers can follow these steps to configure exception branches, enabling contingency plans when node errors occur to avoid interrupting the entire flow:

1. Enable "Error Handling" in the LLM node

2. Select and configure an error handling strategy


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2Fassets-docs.dify.ai%2F2024%2F12%2Ff7109ce5e87c0e0a81248bb2672c7667.png&width=768&dpr=4&quality=100&sign=f5bd77b3&sv=2)

input system prompts

For more information about exception handling methods, please refer to the [Error Handling](https://docs.dify.ai/guides/workflow/error-handling).

[PreviousAnswer](/guides/workflow/node/answer) [NextKnowledge Retrieval](/guides/workflow/node/knowledge-retrieval)

Last updated 15 days ago

This site uses cookies to deliver its service and to analyse traffic. By browsing this site, you accept the [privacy policy](https://dify.ai/privacy).

AcceptRejectBoth Workflow and Chatflow applications support enabling additional features to enhance the user interaction experience. For example, adding a file upload entry, giving the LLM application a self-introduction, or using a welcome message can provide users with a richer interactive experience.

Click the **"Features"** button in the upper right corner of the application to add more functionality.

Features ChatFlow - EN

Start the guide

#### [Direct link to heading](https://docs.dify.ai/guides/workflow/additional-features\#workflow)    Workflow

> Note: This method of adding file uploads to Workflow applications is deprecated. We recommend adding custom file variables on the start node instead.

Workflow type applications only support the **"Image Upload"** feature. When enabled, an image upload entry will appear on the usage page of the Workflow application.

Features Workflow - EN

Start the guide

**Usage:**

**For application users:** Applications with image upload enabled will display an upload button on the usage page. Click the button or paste a file link to complete the image upload. You will receive the LLM's response to the image.

**For application developers:** After enabling the image upload feature, the uploaded image files will be stored in the `sys.files` variable. Next, add an LLM node, select a large model with vision capabilities, and enable the VISION feature within it. Choose the `sys.files` variable to allow the LLM to read the image file.

Finally, select the output variable of the LLM node in the END node to complete the setup.

#### [Direct link to heading](https://docs.dify.ai/guides/workflow/additional-features\#chatflow)    Chatflow

Chatflow type applications support the following features:

- **Conversation Opener**



Allow AI to proactively send a message, which can be a welcome message or AI self-introduction, to bring it closer to the user.

- **Follow-up**



Automatically add suggestions for the next question after the conversation is complete, to increase the depth and frequency of dialogue topics.

- **Text-to-Speech**



Add an audio playback button in the Q&A text box, using a TTS service (needs to be set up in Model Providers) to read out the text.

- **File Upload**



Supports the following file types: documents, images, audio, video, and other file types. After enabling this feature, application users can upload and update files at any time during the application dialogue. A maximum of 10 files can be uploaded simultaneously, with a size limit of 15MB per file.

- **Citation and Attribution**



Commonly used in conjunction with the "Knowledge Retrieval" node to display the reference source documents and attribution parts of the LLM's responses.

- **Content Moderation**



Supports using moderation APIs to maintain a sensitive word library, ensuring that the LLM can respond and output safe content. For detailed instructions, please refer to Sensitive Content Moderation.


**Usage:**

Except for the **File Upload** feature, the usage of other features in Chatflow applications is relatively simple. Once enabled, they can be intuitively used on the application interaction page.

This section will mainly introduce the specific usage of the **File Upload** feature:

**For application users:** Chatflow applications with file upload enabled will display a "paperclip" icon on the right side of the dialogue box. Click it to upload files and interact with the LLM.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252FAgQ4baomgxnjOHgxBYiy%252Fimage.png%3Falt%3Dmedia%26token%3Dc302dac7-676e-4b03-b03a-fc5c8f417915&width=768&dpr=4&quality=100&sign=faf80ade&sv=2)

Upload file

**For application developers:**

After enabling the file upload feature, the files users send will be uploaded in the `sys.files` variable. It will be updated after the user sends a new message in the same conversation turn.

Different types of files correspond to different application orchestration methods based on the uploaded file differences.

- **Document Files**


LLMs do not have the ability to directly read document files, so a Document Extractor node is needed to preprocess the files in the `sys.files` variable. The orchestration steps are as follows:

1. Enable the Features function and only check "Documents" in the file types.

2. Select the `sys.files` variable in the input variables of the Document Extractor node.

3. Add an LLM node and select the output variable of the document extractor node in the system prompt.

4. Add a "Direct Reply" node at the end, filling in the output variable of the LLM node.


Chatflow applications built using this method cannot remember the content of uploaded files. Application users need to upload document files in the chat box for each conversation. If you want the application to remember uploaded files, please refer to File Upload: Adding Variables in the Start Node.

- **Image Files**


Some LLMs support directly obtaining information from images, so no additional nodes are needed to process images.

The orchestration steps are as follows:

1. Enable the Features function and only check "Images" in the file types.

2. Add an LLM node, enable the VISION feature, and select the `sys.files` variable.

3. Add a "Answer" node at the end, filling in the output variable of the LLM node.


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252FW9f8tycoscc6WlxFGxWV%252Fimage.png%3Falt%3Dmedia%26token%3Dcfba9c1c-1038-44ec-97c0-8a2d8c3d511c&width=768&dpr=4&quality=100&sign=a19eb3eb&sv=2)

Enable vision

- **Mixed File Types**


If you want the application to have the ability to process both document files and image files simultaneously, you need to use the List Operation node to preprocess the files in the `sys.files` variable, extract more refined variables, and send them to the corresponding processing nodes. The orchestration steps are as follows:

1. Enable the Features function and check both "Images" and "Document Files" types.

2. Add two list operation nodes, extracting image and document variables in the "Filter" condition.

3. Extract document file variables and pass them to the "Document Extractor" node; extract image file variables and pass them to the "LLM" node.

4. Add a "Direct Reply" node at the end, filling in the output variable of the LLM node.


After the application user uploads both document files and images, document files are automatically diverted to the document extractor node, and image files are automatically diverted to the LLM node to achieve joint processing of files.

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F3866086014-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FRncMhlfeYTrpujwzDIqw%252Fuploads%252FXSeQTD60Fn9nNXkfne27%252Fimage.png%3Falt%3Dmedia%26token%3D6b480b12-68be-4499-8554-c24566e7fe06&width=768&dpr=4&quality=100&sign=73d3993c&sv=2)

**Mixed File Types**

- **Audio and Video Files**


LLMs do not yet support direct reading of audio and video files, and the Dify platform has not yet built-in related file processing tools. Application developers can refer to [External Data Tools](https://docs.dify.ai/guides/extension/api-based-extension/external-data-tool) to integrate tools for processing file information themselves.

[PreviousError Type](https://docs.dify.ai/guides/workflow/error-handling/error-type) [NextDebug and Preview](https://docs.dify.ai/guides/workflow/debug-and-preview)

Last updated 7 days ago

This site uses cookies to deliver its service and to analyse traffic. By browsing this site, you accept the [privacy policy](https://dify.ai/privacy).

AcceptReject[日志与标注](/zh-hans/guides/annotation/logs) [标注回复](/zh-hans/guides/annotation/annotation-reply)

[Previous基于前端组件再开发](/zh-hans/guides/application-publishing/based-on-frontend-templates) [Next日志与标注](/zh-hans/guides/annotation/logs)

Last updated 7 months agoDify 的核心理念是可声明式的定义 AI 应用，包括 Prompt、上下文和插件等等的一切都可以通过一个 YAML 文件描述（这也是为什么称之为 Dify ）。最终呈现的是单一 API 或开箱即用的 WebApp。

与此同时，Dify 提供了一个易用的 Prompt 编排界面，开发者能以 Prompt 为基础所见即所得的编排出各种应用特性。听上去是不是很简单？

无论简单或是复杂的 AI 应用，好的 Prompt 可以有效提高模型输出的质量，降低错误率，并满足特定场景的需求。Dify 已提供对话型和文本生成型两种常见的应用形态，这个章节会带你以可视化的方式完成 AI 应用的编排，

### [Direct link to heading](\#ying-yong-bian-pai-de-bu-zhou)    应用编排的步骤

1. 确定应用场景和功能需求

2. 设计并测试 Prompts 与模型参数

3. 编排 Prompts 与用户输入

4. 发布应用

5. 观测并持续迭代


### [Direct link to heading](\#liao-jie-ying-yong-lei-xing-de-qu-bie)    了解应用类型的区别

Dify 中的文本生成型应用与对话型应用在 Prompt 编排上略有差异，对话型应用需结合“对话生命周期”来满足更复杂的用户情景和上下文管理需求。

Prompt Engineering 已发展为一个潜力巨大，值得持续探索的学科。请继续往下阅读，学习两种类型应用的编排指南。

### [Direct link to heading](\#kuo-zhan-yue-du)    扩展阅读

1. [Learn Prompting](https://learnprompting.org/zh-Hans/)

2. [ChatGPT Prompt Engineering for Developers](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)

3. [Awesome ChatGPT Prompts](https://github.com/f/awesome-chatgpt-prompts)


[Previous召回模式](/zh-hans/learn-more/extended-reading/retrieval-augment/retrieval) [Next如何使用 JSON Schema 让 LLM 输出遵循结构化格式的内容？](/zh-hans/learn-more/extended-reading/how-to-use-json-schema-in-dify)

Last updated 7 months agoDify 是一个多用户平台，工作空间（Workspace）是团队的基本协作单元。工作空间的成员可创建和编辑应用、知识库，也可以直接在 [发现](/zh-hans/guides/workspace/app) 区域直接使用团队其它成员创建的公共应用。

### [Direct link to heading](\#deng-lu-fang-shi)    登录方式

需要注意，目前 Dify 的云服务与社区版支持的登录方式有所区别，参见下表。

云服务

社区版

Email 登录

不支持

支持

使用 GitHub 账号登录

支持

不支持

使用 Google 账号登录

支持

不支持

SSO 登录

计划支持

计划支持

### [Direct link to heading](\#chuang-jian-zhang-hao)    创建账号

如果你使用的是云服务，当你首次登录后将为你自动创建一个工作空间，你将成为管理员。

在社区版中，安装时将提示你设置管理员 Email 与密码。社区版不支持开通多个工作空间。

[Previous敏感内容审查](/zh-hans/guides/extension/code-based-extension/moderation) [Next发现](/zh-hans/guides/workspace/app)

Last updated 1 month ago**Nodes are the key components of a workflow**, enabling the execution of a series of operations by connecting nodes with different functionalities.

### [Direct link to heading](\#core-nodes)    Core Nodes

[**Start**](/guides/workflow/node/start)

Defines the initial parameters for starting a workflow process.

[**End**](/guides/workflow/node/end)

Defines the final output content for ending a workflow process.

[**Answer**](/guides/workflow/node/answer)

Defines the response content in a Chatflow process.

[**Large Language Model (LLM)**](/guides/workflow/node/llm)

Calls a large language model to answer questions or process natural language.

[**Knowledge Retrieval**](https://github.com/langgenius/dify-docs/blob/main/en/guides/workflow/node/knowledge_retrieval.md)

Retrieves text content related to user questions from a knowledge base, which can serve as context for downstream LLM nodes.

[**Question Classifier**](/guides/workflow/node/question-classifier)

By defining classification descriptions, the LLM can select the matching classification based on user input.

[**IF/ELSE**](/guides/workflow/node/ifelse)

Allows you to split the workflow into two branches based on if/else conditions.

[**Code Execution**](/guides/workflow/node/code)

Runs Python/NodeJS code to execute custom logic such as data transformation within the workflow.

[**Template**](/guides/workflow/node/template)

Enables flexible data transformation and text processing using Jinja2, a Python templating language.

[**Variable Aggregator**](/guides/workflow/node/variable-aggregator)

Aggregates variables from multiple branches into one variable for unified configuration of downstream nodes.

[**Variable Assigner**](/guides/workflow/node/variable-assigner)

The variable assigner node is used to assign values to writable variables.

[**Parameter Extractor**](/guides/workflow/node/parameter-extractor)

Uses LLM to infer and extract structured parameters from natural language for subsequent tool calls or HTTP requests.

[**Iteration**](/guides/workflow/node/iteration)

Executes multiple steps on list objects until all results are output.

[**HTTP Request**](/guides/workflow/node/http-request)

Allows sending server requests via the HTTP protocol, suitable for retrieving external results, webhooks, generating images, and other scenarios.

[**Tools**](/guides/workflow/node/tools)

Enables calling built-in Dify tools, custom tools, sub-workflows, and more within the workflow.

[PreviousVariables](/guides/workflow/variables) [NextStart](/guides/workflow/node/start)

Last updated 4 months agoNote: Dify is currently in the Beta testing phase. If there are inconsistencies between the documentation and the product, please refer to the actual product experience.

Dify can be used [out-of-box](https://cloud.dify.ai/apps) as a cloud service by anyone. Explore the flexible [Plans and Pricing](https://dify.ai/pricing) and select the plan that best suits your needs and requirements.

Get started now with the [Sandbox plan](http://cloud.dify.ai), which includes a free trial of 200 OpenAI calls, no credit card required. To use the Sandbox plan of the cloud version, you will need a GitHub or Google account, as well as an OpenAI API key. Here's how you can get started:

1. Sign up to [Dify Cloud](https://cloud.dify.ai) and create a new Workspace or join an existing one.

2. Configure your model provider or use our hosted model provider.

3. You can [create an application](/guides/application-orchestrate/creating-an-application) now!


### [Direct link to heading](\#faqs)    FAQs

**Q: How is my data handled and stored when using Dify Cloud?**

A: When you use Dify Cloud, your user data is securely stored on AWS servers located in the US-East region. This includes both the data you actively input and any generated data from your applications. We prioritize your data's security and integrity, ensuring that it is managed with the highest standards of cloud storage solutions.

**Q: What measures are in place to protect my API keys and other sensitive information?**

A: At Dify, we understand the importance of protecting your API keys and other secrets. These are encrypted at rest, which means Dify cannot view them and that only you, the rightful owner, have access to your secrets.

**Q: Can you explain how application data is anonymized in Dify Cloud?**

A: In Dify Cloud, we anonymize application data to ensure privacy and reduce encryption and decryption overheads. This means that the data used by applications is not directly associated with identifiable user accounts. By anonymizing the data, we enhance privacy while maintaining the performance of our cloud services.

**Q: What is the process for deleting my account and all associated data from Dify Cloud?**

A: If you decide to delete your account and remove all associated data from Dify Cloud, you can simply send a request to our support team at support@dify.ai. We are committed to respecting your privacy and data rights, and upon request, we will erase all your data from our systems, adhering to data protection regulations.

[PreviousFAQs](/getting-started/install-self-hosted/faqs) [NextDify Premium on AWS](/getting-started/dify-premium-on-aws)

Last updated 5 months ago

This site uses cookies to deliver its service and to analyse traffic. By browsing this site, you accept the [privacy policy](https://dify.ai/privacy).

AcceptReject[DifySandbox](/ja-jp/development/backend/sandbox)

[Previousドキュメントへの貢献](/ja-jp/community/docs-contribution) [NextDifySandbox](/ja-jp/development/backend/sandbox)

Last updated 6 months ago

This site uses cookies to deliver its service and to analyse traffic. By browsing this site, you accept the [privacy policy](https://dify.ai/privacy).

AcceptReject